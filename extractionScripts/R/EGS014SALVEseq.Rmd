---
title: "EGS014SALVEseq"
author: "Emanuelle Grody"
date: "2025-04-04"
output: html_document
---

```{r, echo = FALSE}
source("~/SALVEseq/packages.R")
source("~/SALVEseq/functions.R")
```

## GEX (skip)

### Previous strategy
Outputting expression matrices
```{r}
samples <- data.frame(
  samples = c(
    "JK85_D13",
    "LP29_D195",
    "LP29_D83",
    "G_ART_GEX",
    "invitro",
    "L_ART_GEX",
    "L_acute_GEX",
    "P_ART_GEX",
    "W0"
  ),
  folders = c(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/"
  )
)

# Process each sample
for (i in 1:nrow(samples)) {
  sample_name <- samples$samples[i]
  folder_path <- samples$folders[i]
  
  input.dir <- paste0(folder_path, "Mmul_10_mac239_", sample_name, "/outs/filtered_feature_bc_matrix/")
  
  cat("Reading from:", input.dir, "\n")
  
  tryCatch({
    # Process the current sample
    seurat_obj <- SeuratPipeline(input.dir, sample_name, plots = FALSE)
    
    # Generate the target expression data frame
    singlecell_df <- targetExpressionDF(seurat_obj, "mac239")
    
    # Create expressionDF directory if it doesn't exist
    output_dir <- paste0(folder_path, "expressionDF/0/")
    dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)
    
    # Write the CSV
    output_filename <- paste0(output_dir, sample_name, "_Mmulmac_mac239.csv")
    write.csv(singlecell_df, output_filename)
    
    cat("Processed sample:", sample_name, "\n")
    cat("Saved to:", output_filename, "\n\n")
  }, error = function(e) {
    cat("Error processing sample", sample_name, ":", conditionMessage(e), "\n\n")
  })
}

#nz_SingleCell_Pacute <- SingleCell_Pacute %>%
#  filter(mac239 > 0)
#hist(nz_SingleCell_Pacute$mac239,
#     xlab = "mac239 counts",
#     main = "Histogram of non-zero mac239 (log) counts in SingleCell_Pacute")
```


To load for joint analysis:
```{r}

GEX_data <- list()

for (i in 1:nrow(samples)) {
  dataset_name <- samples$datasets[i]
  sample_name <- samples$samples[i]
  folder_path <- paste0(samples$folders[i], "expressionDF/")
  
  tryCatch({
    # Read CSV
    input_filename <- paste0(folder_path, dataset_name, "_Mmulmac_mac239.csv")
    data <- read.csv(input_filename)
    data <- data %>%
      select(-X)
   
    # Store the data with the sample name
    GEX_data[[sample_name]] <- data
   
    cat("Processed sample:", dataset_name, "as", sample_name, "\n")
 }, error = function(e) {
    cat("Error processing", dataset_name, ":", conditionMessage(e), "\n")
 })
  rm(data)
}
```



### Current strategy: bamsort
```{r}
samples <- data.frame(
  datasets = c(
    "JK85_D13",
    "LP29_D195",
    "LP29_D83",
    "G_ART_GEX",
    "invitro",
    "L_ART_GEX",
    "L_acute_GEX",
    "P_ART_GEX",
    "W0"
  ),
  samples = c(
    "D13",
    "D195",
    "D83",
    "GART",
    "Invitro",
    "LART",
    "Lacute",
    "PART",
    "Uninfected"
  ),
  folders = c(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/"
  )
)

# Process
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/bamsort/alignment/newcoords"
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/bamsort/reads/newcoords"

raw_cellIDs_df <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/raw_cellIDs/all_raw_cellIDs.csv")
raw_cellIDs <- split(raw_cellIDs_df$cellID, raw_cellIDs_df$sample)

process_bamsort("GEX", samples$samples, input.dir, output.dir, raw_cellIDs)

# Minimums
input_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/bamsort/reads/newcoords"
output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/bamsort/reads/newcoords/minimum"

process_all_set_minimums("GEX", samples$samples, input_dir, output_dir, min_reads = 2, min_region_count = 2, min_umi = 2, min_cells = 2)

```


### Alternative: Read in and filter each file separately
```{r}
samples <- data.frame(
  datasets = c(
    "JK85_D13",
    "LP29_D195",
    "LP29_D83",
    "G_ART_GEX",
    "invitro",
    "L_ART_GEX",
    "L_acute_GEX",
    "P_ART_GEX",
    "W0"
  ),
  samples = c(
    "D13",
    "D195",
    "D83",
    "GART",
    "Invitro",
    "LART",
    "Lacute",
    "PART",
    "Uninfected"
  ),
  folders = c(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/"
  )
)

input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/bamsort/alignment"

# Function to identify the specific file type
is_v4bamsort_GEX <- function(filename) {
  alignment_part <- strsplit(filename, "_bamsort_alignment_")[[1]][2]
  alignment_part <- sub("\\.csv$", "", alignment_part)
  
  if (grepl("LTR_D1$", alignment_part)) return("LTR_D1")
  if (grepl("D1_A1$", alignment_part)) return("D1_A1")
  if (grepl("A1_D4$", alignment_part)) return("A1_D4")
  if (grepl("D4_A7$", alignment_part)) return("D4_A7")
  if (grepl("A7_LTR$", alignment_part)) return("A7_LTR")
  
  return("other")
}

raw_cellIDs_df <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/raw_cellIDs/all_raw_cellIDs.csv")
raw_cellIDs <- split(raw_cellIDs_df$cellID, raw_cellIDs_df$sample)

# Process each sample individually
for (i in 1:nrow(samples)) {
  sample <- samples$samples[i]
  cat("\nProcessing sample:", sample, "\n")
  
  # Get all files for current sample 
  sample_files <- list.files(input.dir, 
                           pattern = paste0("^", sample, ".*_bamsort_alignment_.*\\.csv$"), 
                           full.names = TRUE)
  
  if (length(sample_files) == 0) {
    cat("No files found for sample:", sample, "\n")
    next
  }
  
  sample_data_list <- list()
  filenames <- basename(sample_files)
  
  targets <- character(length(filenames))
  alignments <- character(length(filenames))
  keys <- character(length(filenames))
  
  # Extract components from filenames
  for (j in seq_along(filenames)) {
    parts <- strsplit(filenames[j], "_bamsort_alignment_")[[1]]
    target_part <- sub(paste0("^", sample, "_"), "", parts[1])
    alignment <- sub("\\.csv$", "", parts[2])
    targets[j] <- target_part
    alignments[j] <- alignment
    
    # Use the is_v4bamsort_GEX function to get the key
    file_type <- is_v4bamsort_GEX(filenames[j])
    keys[j] <- file_type
    
    # Skip files that don't match our patterns of interest
    if (file_type == "other") {
      cat("Skipping file that doesn't match patterns:", filenames[j], "\n")
      next
    }
    
    # Read the file, handle empty files
    tryCatch({
      file_data <- fread(sample_files[j], data.table=FALSE)
      
      # Check if file is empty
      if (nrow(file_data) == 0) {
        #cat("Warning: Empty file:", filenames[j], "\n")
        # Create an empty data frame with the required columns
        sample_data_list[[keys[j]]] <- data.frame(cellID = character(0), UMI = character(0), count = integer(0), stringsAsFactors = FALSE)
      } else {
        # Check if required columns exist
        if (all(c("cellID", "UMI") %in% colnames(file_data))) {
          # Check if count column exists, if not, add it with value 1 (assuming default)
          if (!("count" %in% colnames(file_data))) {
            cat("Warning: 'count' column missing in file:", filenames[j], ", assuming count=1\n")
            file_data$count <- 1
          }
          sample_data_list[[keys[j]]] <- file_data
          #cat("Read file", filenames[j], "with", nrow(file_data), "rows\n")
        } else {
          cat("Warning: Required columns missing in file:", filenames[j], "\n")
          # Create an empty data frame with the required columns
          sample_data_list[[keys[j]]] <- data.frame(cellID = character(0), UMI = character(0), count = integer(0), stringsAsFactors = FALSE)
        }
      }
    }, error = function(e) {
      cat("Error reading file:", filenames[j], ":", conditionMessage(e), "\n")
      # Create an empty data frame with the required columns
      sample_data_list[[keys[j]]] <- data.frame(cellID = character(0), UMI = character(0), count = integer(0), stringsAsFactors = FALSE)
    })
  }
  
  # Create file_info data.frame
  file_info <- data.frame(
    filename = filenames,
    filepath = sample_files,
    target = targets,
    alignment = alignments,
    key = keys,
    stringsAsFactors = FALSE
  )
  
  # Filter out 'other' file types
  file_info <- file_info[file_info$key != "other", ]
  
  # Check if we have any files of interest
  if (nrow(file_info) == 0) {
    cat("No files of interest found for sample:", sample, "\n")
    next
  }
  
  # Get all relevant keys
  relevant_keys <- unique(file_info$key)
  
  # Create a data frame to store combined results
  all_data <- data.frame(cellID = character(), UMI = character(), key = character(), stringsAsFactors = FALSE)
  
  # Collect data from each key
  for (key in relevant_keys) {
    if (key %in% names(sample_data_list) && 
        "cellID" %in% colnames(sample_data_list[[key]]) && 
        "UMI" %in% colnames(sample_data_list[[key]])) {
      
      key_data <- data.frame(
        cellID = sample_data_list[[key]]$cellID,
        UMI = sample_data_list[[key]]$UMI,
        key = rep(key, nrow(sample_data_list[[key]])),
        stringsAsFactors = FALSE
      )
      all_data <- rbind(all_data, key_data)
    }
  }
  
  # Check if all_data is empty
  if (nrow(all_data) == 0) {
    cat("Warning: No data found after collecting from relevant keys for sample", sample, "\n")
    cat("Skipping further processing for this sample\n")
    # Clean up to free memory
    rm(sample_data_list)
    gc()
    next
  }
  
  # Create UMI table for all cells
  umi_table <- table(all_data$cellID, all_data$key)
  combined_umi_counts <- as.data.frame.matrix(umi_table)
  
  # Check if combined_umi_counts is empty
  if (nrow(combined_umi_counts) == 0) {
    cat("Warning: No data found after creating UMI table for sample", sample, "\n")
    cat("Skipping further processing for this sample\n")
    # Clean up to free memory
    rm(sample_data_list)
    gc()
    next
  }
  
  combined_umi_counts$cellID <- rownames(combined_umi_counts)
  rownames(combined_umi_counts) <- NULL
  
  combined_umi_counts <- combined_umi_counts[, c("cellID", setdiff(colnames(combined_umi_counts), "cellID"))]
  
  # Ensure all required columns exist
  required_columns <- c("LTR_D1", "D1_A1", "A1_D4", "D4_A7", "A7_LTR")
  for (col in required_columns) {
    if (!(col %in% colnames(combined_umi_counts))) {
      combined_umi_counts[[col]] <- 0
    }
  }
  
  # Calculate total UMIs across all keys
  target_cols <- intersect(required_columns, colnames(combined_umi_counts))
  
  # Check if target_cols is empty
  if (length(target_cols) == 0) {
    cat("Warning: No target columns found for calculating total UMIs\n")
    combined_umi_counts$total_UMIs <- 0
  } else {
    # Check that the subsetting operation gives a valid result for rowSums
    subset_data <- combined_umi_counts[, target_cols, drop = FALSE]
    if (ncol(subset_data) == 0 || nrow(subset_data) == 0) {
      cat("Warning: Subset data for rowSums is empty\n")
      combined_umi_counts$total_UMIs <- 0
    } else {
      # Now safe to use rowSums
      combined_umi_counts$total_UMIs <- rowSums(subset_data, na.rm = TRUE)
    }
  }
  
  # Create output directory if it doesn't exist
  output_dir <- file.path(dirname(input.dir), "extracted")
  if (!dir.exists(output_dir)) {
    dir.create(output_dir, recursive = TRUE)
  }
  
  # Save the raw data (before any filtering)
  raw_file <- file.path(output_dir, paste0(sample, "_GEX_raw.csv"))
  write.csv(combined_umi_counts, file = raw_file, row.names = FALSE)
  
  # Filter data to keep only cells that exist in raw_cellIDs for the full dataset
  if (sample %in% names(raw_cellIDs) && !is.null(raw_cellIDs[[sample]])) {
    valid_cells <- raw_cellIDs[[sample]]
    
    # Filter raw data to create full dataset (only filtering by valid cellIDs)
    full_umi_counts <- combined_umi_counts[combined_umi_counts$cellID %in% valid_cells, ]
    
    # Safety check to ensure full_umi_counts has data
    if (nrow(full_umi_counts) > 0) {
      # Save the full data (filtered only by valid cellIDs)
      full_file <- file.path(output_dir, paste0(sample, "_GEX_full.csv"))
      write.csv(full_umi_counts, file = full_file, row.names = FALSE)
      
      # Apply filtering using original count values:
      # 1. Find cells with count > 1 in any input file
      # 2. Cell present in at least two different files
      
      # First, find cells with count > 1 in any original input file
      cells_with_min_counts <- character(0)
      
      for (key in names(sample_data_list)) {
        if (nrow(sample_data_list[[key]]) > 0 && "count" %in% colnames(sample_data_list[[key]])) {
          # Get cells with count > 1
          high_count_cells <- unique(sample_data_list[[key]]$cellID[sample_data_list[[key]]$count > 1])
          cells_with_min_counts <- unique(c(cells_with_min_counts, high_count_cells))
        }
      }
      
      # Get the key columns (exclude cellID and total_UMIs)
      key_cols <- setdiff(colnames(full_umi_counts), c("cellID", "total_UMIs"))
      
      # Second check: cells present in at least two different files
      cells_in_multiple_files <- apply(full_umi_counts[, key_cols, drop = FALSE], 1, function(row) {
        sum(row > 0) >= 2
      })
      
      # Apply both filters
      filtered_umi_counts <- full_umi_counts[
        full_umi_counts$cellID %in% cells_with_min_counts & cells_in_multiple_files, 
      ]
      
      # Save the filtered dataset
      if (nrow(filtered_umi_counts) > 0) {
        filtered_file <- file.path(output_dir, paste0(sample, "_GEX_filtered.csv"))
        write.csv(filtered_umi_counts, file = filtered_file, row.names = FALSE)
      } else {
        cat("Warning: No cells passed the filtering criteria for sample", sample, "\n")
        # Create an empty filtered file with the correct header structure
        filtered_file <- file.path(output_dir, paste0(sample, "_GEX_filtered.csv"))
        write.csv(full_umi_counts[0, ], file = filtered_file, row.names = FALSE)
      }
    } else {
      cat("Warning: No data in full_umi_counts for sample", sample, "\n")
    }
  } else {
    cat("Warning: No 10X data found for sample", sample, "- not creating full or filtered dataset\n")
  }

  # Print summary statistics with safety checks
  cat("\nSummary for sample:", sample, "\n")
  
  # Count the number of UMIs for each key
  umi_counts_by_key <- sapply(relevant_keys, function(key) {
    if (key %in% names(sample_data_list)) {
      return(nrow(sample_data_list[[key]]))
    } else {
      return(0)
    }
  })
  
  # Count cells with count > 1 in each key
  high_count_cells_by_key <- sapply(relevant_keys, function(key) {
    if (key %in% names(sample_data_list) && nrow(sample_data_list[[key]]) > 0 && "count" %in% colnames(sample_data_list[[key]])) {
      return(length(unique(sample_data_list[[key]]$cellID[sample_data_list[[key]]$count > 1])))
    } else {
      return(0)
    }
  })
  
  # Safely get counts with null checks
  combined_counts_rows <- if(exists("combined_umi_counts")) nrow(combined_umi_counts) else 0
  valid_cells_count <- if(exists("valid_cells")) length(valid_cells) else 0
  full_counts_rows <- if(exists("full_umi_counts")) nrow(full_umi_counts) else 0
  filtered_counts_rows <- if(exists("filtered_umi_counts")) nrow(filtered_umi_counts) else 0
  count_gt_1_cells <- if(exists("cells_with_min_counts")) length(cells_with_min_counts) else 0
  
  # Print UMI counts by key
  cat("UMI counts by key:\n")
  for (key in names(umi_counts_by_key)) {
    cat("  ", key, ": ", umi_counts_by_key[key], "\n", sep="")
  }
  
  # Print cells with count > 1 by key
  cat("Cells with count > 1 by key:\n")
  for (key in names(high_count_cells_by_key)) {
    cat("  ", key, ": ", high_count_cells_by_key[key], "\n", sep="")
  }
  
  cat(
    "Number of cells in raw: \t",
    combined_counts_rows,
    "\nNumber of cells with total UMI > 100: \t",
    valid_cells_count,
    "\nNumber of cells with count > 1 in any file: \t",
    count_gt_1_cells,
    "\nNumber of cells in full: \t",
    full_counts_rows,
    "\nNumber of cells in filtered: \t",
    filtered_counts_rows,
    "\n"
  )

  # Clean up to free memory
  rm(sample_data_list)
  gc()
}
```


## SALVE (skip)

Run this once first:
```{r raw_cellIDs}
# Load and save raw cell IDs from 10X data
raw_cellIDs <- list()
output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/raw_cellIDs" 

# Create output directory if it doesn't exist
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

samples <- data.frame(
  datasets = c(
    "JK85_D13",
    "LP29_D195",
    "LP29_D83",
    "G_ART_GEX",
    "invitro",
    "L_ART_GEX",
    "L_acute_GEX",
    "P_ART_GEX",
    "W0"
  ),
  samples = c(
    "D13",
    "D195",
    "D83",
    "GART",
    "Invitro",
    "LART",
    "Lacute",
    "PART",
    "Uninfected"
  ),
  folders = c(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/"
  )
)

all_cellIDs <- data.frame(cellID = character(), sample = character(), stringsAsFactors = FALSE)

for (i in 1:nrow(samples)) {
  dataset_name <- samples$datasets[i]
  sample_name <- samples$samples[i]
  rawDataFolder <- paste0(samples$folders[i], "Mmul_10_mac239_", samples$datasets[i], "/outs/raw_feature_bc_matrix/")
  
  tryCatch({
    rawdata <- Read10X(rawDataFolder)
    umi_counts <- colSums(rawdata)
    cell_ids <- names(umi_counts[umi_counts > 100]) # keep only cells with transcriptomes
    raw_cellIDs[[sample_name]] <- cell_ids
    cat("Loaded", length(cell_ids), "raw cellIDs for sample", sample_name, "\n")
    
    # Add to the combined dataframe
    sample_df <- data.frame(
      cellID = cell_ids,
      sample = rep(sample_name, length(cell_ids)),
      stringsAsFactors = FALSE
    )
    all_cellIDs <- rbind(all_cellIDs, sample_df)
    
    # Save individual sample's cell IDs to CSV
    sample_file <- file.path(output_dir, paste0(sample_name, "_raw_cellIDs.csv"))
    write.csv(data.frame(cellID = cell_ids), sample_file, row.names = FALSE)
    cat("Saved", length(cell_ids), "cell IDs to", sample_file, "\n")
    
  }, error = function(e) {
    cat("Error processing", dataset_name, ":", conditionMessage(e), "\n")
  })
  
  if (exists("rawdata")) {
    rm(rawdata)
    gc()
  }
}

# Save the combined cell IDs to a single CSV
combined_file <- file.path(output_dir, "all_raw_cellIDs.csv")
write.csv(all_cellIDs, combined_file, row.names = FALSE)
cat("Saved combined cell IDs to", combined_file, "\n")

# To easily load this data in the future:
# raw_cellIDs_df <- read.csv("path/to/output/directory/all_raw_cellIDs.csv")
# raw_cellIDs <- split(raw_cellIDs_df$cellID, raw_cellIDs_df$sample)
```

### Reads per UMI

Making raw and full lists:
```{r}
samples <- data.frame(
  datasets = c(
    "JK85_D13",
    "LP29_D195",
    "LP29_D83",
    "G_ART_GEX",
    "invitro",
    "L_ART_GEX",
    "L_acute_GEX",
    "P_ART_GEX",
    "W0"
  ),
  samples = c(
    "D13",
    "D195",
    "D83",
    "GART",
    "Invitro",
    "LART",
    "Lacute",
    "PART",
    "Uninfected"
  ),
  folders = c(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/"
  )
)

input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/alignment/newcoords"
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/reads/newcoords"

raw_cellIDs_df <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/raw_cellIDs/all_raw_cellIDs.csv")
raw_cellIDs <- split(raw_cellIDs_df$cellID, raw_cellIDs_df$sample)

process_bamsort("SALVE", samples$samples, input.dir, output.dir, raw_cellIDs)

# minimums
input_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/reads/newcoords"
output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/reads/newcoords/minimum"

process_all_set_minimums("SALVE", samples$samples, input_dir, output_dir, min_reads = 2, min_region_count = 2, min_umi = 2, min_cells = 2)

```


### Older: plotting expression distributions
Plotting: beeswarm
```{r}
library(ggbeeswarm)

create_swarm_plot_improved <- function(viz_data, sample_name = NULL) {
  if (!is.null(sample_name)) {
    viz_data <- viz_data %>% filter(sample_name == !!sample_name)
  }
  
  # Calculate UMIs per cell and reads per cell for each category
  summary_data <- viz_data %>%
    group_by(cellID, category) %>%
    summarize(
      umis_per_cell = n_distinct(UMI),
      total_reads = sum(read_count),
      .groups = 'drop'
    )
  
  # Create the swarm plot with wider distribution and less overlap
  p <- ggplot(summary_data, aes(x = category, y = umis_per_cell)) +
    # Use geom_quasirandom with increased width parameter
    geom_quasirandom(
      aes(size = total_reads, fill = total_reads), 
      color = "black", 
      shape = 21, 
      alpha = 0.8, 
      width = 0.5,     # Increase width for wider distribution
      varwidth = TRUE, # Vary width based on density
      method = "smiley", # Alternative distribution method
      bandwidth = 0.8   # Control density of points
    ) +
    scale_fill_gradient2(
      low = "blue", mid = "purple", high = "red", 
      midpoint = median(summary_data$total_reads),
      name = "Total Reads"
    ) +
    scale_size_continuous(
      range = c(1.5, 7),  # Increased size range for better visibility
      name = "Total Reads"
    ) +
    labs(
      title = paste("UMIs per Cell by Category -", sample_name),
      x = "Category",
      y = "Number of UMIs per Cell"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      panel.grid.major = element_line(color = "gray80"),
      panel.background = element_rect(fill = "gray97"),
      legend.key.size = unit(1, "cm")
    )
  
  return(p)
}

# Directory setup and file processing code remains the same
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/reads/"
plot_dir <- file.path(input.dir, "swarm_plots")
if (!dir.exists(plot_dir)) {
  dir.create(plot_dir, recursive = TRUE)
}

# Find all visualization data files
viz_files <- list.files(input.dir, pattern = "_plot_data\\.csv$", full.names = TRUE)

# Process each file
for (file in viz_files) {
  sample_name <- gsub("_plot_data\\.csv$", "", basename(file))
  cat("Processing sample:", sample_name, "\n")
  
  viz_data <- read.csv(file)
  
  cat("Categories in data:\n")
  print(table(viz_data$category))
  
  # Create the improved swarm plot
  p <- create_swarm_plot_improved(viz_data, sample_name)
  
  # Save the plot
  output_file <- file.path(plot_dir, paste0(sample_name, "_swarm_plot_improved.svg"))
  ggsave(output_file, p, width = 14, height = 10)
  
  cat("Saved improved swarm plot to:", output_file, "\n\n")
}
```

Plotting: boxplot w jitter
```{r}
create_boxplot_with_jitter <- function(viz_data, sample_name = NULL) {
  if (!is.null(sample_name)) {
    viz_data <- viz_data %>% filter(sample_name == !!sample_name)
  }
  
  # Calculate UMIs per cell and reads per cell for each category
  summary_data <- viz_data %>%
    group_by(cellID, category) %>%
    summarize(
      umis_per_cell = n_distinct(UMI),
      total_reads = sum(read_count),
      .groups = 'drop'
    )
  
  # Create boxplot with jittered points
  p <- ggplot(summary_data, aes(x = category, y = umis_per_cell)) +
    # Add boxplot
    geom_boxplot(
      outlier.shape = NA,
      alpha = 0.3,
      width = 0.5,
      color = "black",
      size = 1
    ) +
    # Add jittered points
    geom_jitter(
      aes(size = total_reads, fill = total_reads),
      shape = 21,
      color = "black",
      alpha = 0.8,
      width = 0.25,
      height = 0,
      stroke = 0.5
    ) +
    # Color and size scales
    scale_fill_gradient2(
      low = "blue", mid = "purple", high = "red", 
      midpoint = median(summary_data$total_reads),
      name = "Total Reads",
      guide = guide_colorbar(override.aes = list(size = 5, alpha = 1))
    ) +
    scale_size_continuous(
      range = c(1.5, 7),
      name = "Total Reads"
    ) +
    # Labels and theme
    labs(
      title = paste("UMIs per Cell by Category -", sample_name),
      x = "Category",
      y = "Number of UMIs per Cell"
    ) +
    theme_minimal(base_size = 16) +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1, size = 16),
      axis.text.y = element_text(size = 16),
      axis.title = element_text(size = 18, face = "bold"),
      plot.title = element_text(size = 20, face = "bold"),
      legend.title = element_text(size = 16, face = "bold"),
      legend.text = element_text(size = 14),
      panel.grid.major = element_line(color = "gray80"),
      panel.background = element_rect(fill = "gray97"),
      legend.key.size = unit(1.5, "cm")
    )
  
  return(p)
}

# Directory setup
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/reads"
plot_dir <- file.path(input.dir, "boxplot_jitter")
if (!dir.exists(plot_dir)) {
  dir.create(plot_dir, recursive = TRUE)
}

# Find all visualization data files
viz_files <- list.files(input.dir, pattern = "_plot_data\\.csv$", full.names = TRUE)

# Process each file
for (file in viz_files) {
  sample_name <- gsub("_plot_data\\.csv$", "", basename(file))
  cat("Processing sample:", sample_name, "\n")
  
  viz_data <- read.csv(file)
  
  cat("Categories in data:\n")
  print(table(viz_data$category))
  
  # Create the boxplot with jittered points
  p <- create_boxplot_with_jitter(viz_data, sample_name)
  
  # Save as PNG instead of SVG
  output_file_png <- file.path(plot_dir, paste0(sample_name, "_boxplot_jitter.png"))
  ggsave(output_file_png, p, width = 14, height = 10, dpi = 300)
  
  # Also save as PDF (more reliable for vector graphics)
  output_file_pdf <- file.path(plot_dir, paste0(sample_name, "_boxplot_jitter.pdf"))
  ggsave(output_file_pdf, p, width = 14, height = 10)
  
  cat("Saved plots to:", output_file_png, "and", output_file_pdf, "\n\n")
}
```

### Alternative approach: Read in and filter each file separately
```{r}
samples <- data.frame(
  datasets = c(
    "JK85_D13", "LP29_D195", "LP29_D83", "G_ART_GEX", "invitro",
    "L_ART_GEX", "L_acute_GEX", "P_ART_GEX", "W0"
  ),
  samples = c(
    "D13", "D195", "D83", "GART", "Invitro", 
    "LART", "Lacute", "PART", "Uninfected"
  ),
  folders = c(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/"
  ),
  stringsAsFactors = FALSE
)

input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/alignment"

# Function to extract alignment info
extract_alignment_info <- function(filename) {
  parts <- strsplit(filename, "_bamsort_alignment_")[[1]]
  if (length(parts) >= 2) {
    alignment <- sub("\\.csv$", "", parts[2])
    return(list(
      alignment = alignment,
      is_nef = alignment %in% c("nef_3", "nef_5"),
      is_ltr = alignment %in% c("LTR_3", "LTR_5")
    ))
  } else {
    return(list(alignment = NA, is_nef = FALSE, is_ltr = FALSE))
  }
}

# Create output directory
output_dir <- file.path(dirname(input.dir), "extracted/test")
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Load raw cell IDs from 10X
raw_cellIDs_df <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/raw_cellIDs/all_raw_cellIDs.csv")
raw_cellIDs <- split(raw_cellIDs_df$cellID, raw_cellIDs_df$sample)

# Process each sample individually
for (i in 1:nrow(samples)) {
  sample <- samples$samples[i]
  cat("\nProcessing sample:", sample, "\n")
  
  # Get all files for current sample 
  sample_files <- list.files(input.dir, 
                           pattern = paste0("^", sample, ".*_bamsort_alignment_.*\\.csv$"), 
                           full.names = TRUE)
  
  if (length(sample_files) == 0) {
    cat("No files found for sample:", sample, "\n")
    next
  }
  
  sample_data_list <- list()
  filenames <- basename(sample_files)
  
  # Pre-allocate vectors for file information
  file_info_list <- vector("list", length(filenames))
  
  # Extract components from filenames and read files
  for (j in seq_along(filenames)) {
    parts <- strsplit(filenames[j], "_bamsort_alignment_")[[1]]
    
    if (length(parts) >= 2) {
      target_part <- sub(paste0("^", sample, "_"), "", parts[1])
      alignment <- sub("\\.csv$", "", parts[2])

      file_info_list[[j]] <- list(
        filename = filenames[j],
        filepath = sample_files[j],
        target = target_part,
        alignment = alignment,
        is_nef = alignment %in% c("nef_3", "nef_5"),
        is_ltr = alignment %in% c("LTR_3", "LTR_5"),
        key = alignment
      )

      # Read file with error handling for empty files
      tryCatch({
        data <- fread(
          sample_files[j], 
          select = c("cellID", "UMI", "count"),
          data.table = FALSE
        )
        
        # Check if the required columns exist
        if (all(c("cellID", "UMI", "count") %in% colnames(data))) {
          sample_data_list[[alignment]] <- data
          #cat("Read file", filenames[j], "with", nrow(data), "rows\n")
        } else {
          missing_cols <- setdiff(c("cellID", "UMI", "count"), colnames(data))
          cat("Warning: Missing required columns in file", filenames[j], ":", paste(missing_cols, collapse=", "), "\n")
          sample_data_list[[alignment]] <- data.frame(cellID = character(0), UMI = character(0), count = integer(0), stringsAsFactors = FALSE)
        }
        
        if (nrow(data) == 0) {
          cat("Warning: Empty file:", filenames[j], "\n")
        }
      }, error = function(e) {
        cat("Error reading file:", filenames[j], ":", conditionMessage(e), "\n")
        sample_data_list[[alignment]] <- data.frame(cellID = character(0), UMI = character(0), count = integer(0), stringsAsFactors = FALSE)
      })
    } else {
      cat("Warning: Filename doesn't match expected pattern:", filenames[j], "\n")
    }
  }
  
  # Convert list of file info to data.frame
  file_info <- do.call(rbind.data.frame, 
                      lapply(file_info_list, function(x) {
                        if (!is.null(x)) {
                          data.frame(
                            filename = x$filename,
                            filepath = x$filepath,
                            target = x$target,
                            alignment = x$alignment,
                            is_nef = x$is_nef,
                            is_ltr = x$is_ltr,
                            key = x$key,
                            stringsAsFactors = FALSE
                          )
                        }
                      }))
  
  # Get keys for nef and LTR files
  nef_3_keys <- file_info$key[file_info$alignment == "nef_3"]
  nef_5_keys <- file_info$key[file_info$alignment == "nef_5"]
  ltr_3_keys <- file_info$key[file_info$alignment == "LTR_3"]
  ltr_5_keys <- file_info$key[file_info$alignment == "LTR_5"]
  
  # Combine nefs
  if (length(nef_3_keys) > 0 || length(nef_5_keys) > 0) {
    nef_keys <- c(nef_3_keys, nef_5_keys)
    if (length(nef_keys) == 1) {
      sample_data_list[["nef"]] <- sample_data_list[[nef_keys[1]]]
    } else {
      # Extract and combine only non-empty data frames
      nef_data_list <- lapply(nef_keys, function(key) sample_data_list[[key]])
      non_empty_nef_list <- nef_data_list[sapply(nef_data_list, function(x) !is.null(x) && nrow(x) > 0)]
      
      if (length(non_empty_nef_list) > 0) {
        sample_data_list[["nef"]] <- as.data.frame(unique(rbindlist(non_empty_nef_list)))
      } else {
        sample_data_list[["nef"]] <- data.frame(cellID = character(0), UMI = character(0), count = integer(0), stringsAsFactors = FALSE)
      }
    }
  }
  
  # Combine LTRs
  if (length(ltr_3_keys) > 0 || length(ltr_5_keys) > 0) {
    ltr_keys <- c(ltr_3_keys, ltr_5_keys)
    if (length(ltr_keys) == 1) {
      sample_data_list[["LTR"]] <- sample_data_list[[ltr_keys[1]]]
    } else {
      ltr_data_list <- lapply(ltr_keys, function(key) sample_data_list[[key]])
      non_empty_ltr_list <- ltr_data_list[sapply(ltr_data_list, function(x) !is.null(x) && nrow(x) > 0)]
      
      if (length(non_empty_ltr_list) > 0) {
        sample_data_list[["LTR"]] <- as.data.frame(unique(rbindlist(non_empty_ltr_list)))
      } else {
        sample_data_list[["LTR"]] <- data.frame(cellID = character(0), UMI = character(0), count = integer(0), stringsAsFactors = FALSE)
      }
    }
  }
  
  # Get all relevant keys (exclude individual LTR_3, LTR_5, nef_3, nef_5)
  excluded_keys <- c("LTR_3", "LTR_5", "nef_3", "nef_5")
  relevant_keys <- setdiff(names(sample_data_list), excluded_keys)
  
  # Create a data frame to store combined results
  all_data_list <- list()
  
  # Collect data from each key
  for (key in relevant_keys) {
    if (key %in% names(sample_data_list) && 
        !is.null(sample_data_list[[key]]) &&
        "cellID" %in% colnames(sample_data_list[[key]]) && 
        "UMI" %in% colnames(sample_data_list[[key]]) &&
        nrow(sample_data_list[[key]]) > 0) {
      
      key_data <- data.frame(
        cellID = sample_data_list[[key]]$cellID,
        UMI = sample_data_list[[key]]$UMI,
        key = rep(key, nrow(sample_data_list[[key]])),
        stringsAsFactors = FALSE
      )
      all_data_list[[length(all_data_list) + 1]] <- key_data
    }
  }
  
  # Combine all data
  if (length(all_data_list) == 0) {
    cat("Warning: No data found after collecting from relevant keys for sample", sample, "\n")
    cat("Skipping further processing for this sample\n")
    next
  }
  
  all_data <- do.call(rbind, all_data_list)
  
  # Check if all_data is empty
  if (nrow(all_data) == 0) {
    cat("Warning: Empty all_data for sample", sample, "\n")
    cat("Skipping further processing for this sample\n")
    next
  }
  
  # Create UMI table for all cells
  umi_table <- table(all_data$cellID, all_data$key)
  combined_umi_counts <- as.data.frame.matrix(umi_table)
  
  # Check if combined_umi_counts is empty
  if (nrow(combined_umi_counts) == 0) {
    cat("Warning: No data found after creating UMI table for sample", sample, "\n")
    cat("Skipping further processing for this sample\n")
    next
  }
  
  combined_umi_counts$cellID <- rownames(combined_umi_counts)
  rownames(combined_umi_counts) <- NULL
  
  combined_umi_counts <- combined_umi_counts[, c("cellID", setdiff(colnames(combined_umi_counts), "cellID"))]
  
  # Ensure all required columns exist
  required_columns <- c("D1_S", "D1_US", "tat_S", "tat_US", "nef", "LTR")
  for (col in required_columns) {
    if (!(col %in% colnames(combined_umi_counts))) {
      combined_umi_counts[[col]] <- 0
    }
  }
  
  # Calculate total_lessLTR
  target_cols <- intersect(c("D1_S", "D1_US", "tat_S", "tat_US", "nef"), colnames(combined_umi_counts))
  if (length(target_cols) > 0) {
    combined_umi_counts$total_lessLTR <- rowSums(combined_umi_counts[, target_cols, drop = FALSE], na.rm = TRUE)
  } else {
    combined_umi_counts$total_lessLTR <- 0
  }
  
  # Save the raw data (before any filtering)
  raw_file <- file.path(output_dir, paste0(sample, "_SALVE_raw.csv"))
  write.csv(combined_umi_counts, file = raw_file, row.names = FALSE)
  
  # Filtering
  if (sample %in% names(raw_cellIDs) && !is.null(raw_cellIDs[[sample]])) {
    valid_cells <- raw_cellIDs[[sample]]
    
    cell_index <- match(combined_umi_counts$cellID, valid_cells, nomatch = 0) > 0
    full_umi_counts <- combined_umi_counts[cell_index, ]
    
    # Save the full data (filtered only by valid cellIDs from GEX raw)
    if (nrow(full_umi_counts) > 0) {
      full_file <- file.path(output_dir, paste0(sample, "_SALVE_full.csv"))
      write.csv(full_umi_counts, file = full_file, row.names = FALSE)
      
      # Apply filtering criteria based on the original input CSVs:
      # First, find cells with count > 1 in any input file
      cells_with_min_counts <- character(0)
      
      for (key in names(sample_data_list)) {
        if (!is.null(sample_data_list[[key]]) && 
            nrow(sample_data_list[[key]]) > 0 && 
            "count" %in% colnames(sample_data_list[[key]])) {
          high_count_cells <- unique(sample_data_list[[key]]$cellID[sample_data_list[[key]]$count > 1])
          cells_with_min_counts <- unique(c(cells_with_min_counts, high_count_cells))
        }
      }
      
      # Next, detect presence in multiple regions
      region_prefixes <- c("D1", "tat", "nef", "LTR")
      
      full_umi_counts$region_count <- 0
      
      # For each region, check if the cell has any counts in columns with that prefix
      for (prefix in region_prefixes) {
        if (prefix == "nef" || prefix == "LTR") {
          if (prefix %in% colnames(full_umi_counts)) {
            full_umi_counts$region_count <- full_umi_counts$region_count + 
              as.integer(full_umi_counts[[prefix]] > 0)
          }
        } else {
          # For prefixes like "D1" or "tat"
          prefix_cols <- grep(paste0("^", prefix), colnames(full_umi_counts), value = TRUE)
          if (length(prefix_cols) > 0) {
            has_prefix <- rowSums(full_umi_counts[, prefix_cols, drop = FALSE], na.rm = TRUE) > 0
            full_umi_counts$region_count <- full_umi_counts$region_count + as.integer(has_prefix)
          }
        }
      }
      
      # Apply both filters: cells must have count > 1 AND be present in at least two regions
      cell_filter <- full_umi_counts$cellID %in% cells_with_min_counts & full_umi_counts$region_count >= 2
      filtered_umi_counts <- full_umi_counts[cell_filter, ]
      
      # Remove the helper column
      filtered_umi_counts$region_count <- NULL
      
      # Save the filtered data
      if (nrow(filtered_umi_counts) > 0) {
        filtered_file <- file.path(output_dir, paste0(sample, "_SALVE_filtered.csv"))
        write.csv(filtered_umi_counts, file = filtered_file, row.names = FALSE) 
      } else {
        cat("Warning: No cells passed the filtering criteria for sample", sample, "\n")
        # Create an empty filtered file with the correct header structure
        filtered_file <- file.path(output_dir, paste0(sample, "_SALVE_filtered.csv"))
        write.csv(full_umi_counts[0, ], file = filtered_file, row.names = FALSE)
      }
    } else {
      cat("Warning: No data in full_umi_counts for sample", sample, "\n")
    }
  } else {
    cat("Warning: No 10X data found for sample", sample, "- not creating full or filtered dataset\n")
  }
  
  # Print summary statistics with safety checks
  cat("\nSummary for sample:", sample, "\n")
  
  # Safely get counts with null checks
  combined_counts_rows <- if(exists("combined_umi_counts")) nrow(combined_umi_counts) else 0
  valid_cells_count <- if(exists("valid_cells")) length(valid_cells) else 0
  full_counts_rows <- if(exists("full_umi_counts")) nrow(full_umi_counts) else 0
  filtered_counts_rows <- if(exists("filtered_umi_counts")) nrow(filtered_umi_counts) else 0
  
  cat(
    "Number of cells in raw: \t",
    combined_counts_rows,
    "\nNumber of cells with total UMI > 100: \t",
    valid_cells_count,
    "\nNumber of cells in full: \t",
    full_counts_rows,
    "\nNumber of cells in filtered: \t",
    filtered_counts_rows,
    "\n"
  )
  
  # Clean up to free memory
  rm(sample_data_list)
  gc()
}
```



## Joint

Loading both datasets
```{r}
samples <- data.frame(
  datasets = c(
    "JK85_D13",
    "LP29_D195",
    "LP29_D83",
    "G_ART_GEX",
    "invitro",
    "L_ART_GEX",
    "L_acute_GEX",
    "P_ART_GEX",
    "W0"
  ),
  samples = c(
    "D13",
    "D195",
    "D83",
    "GART",
    "Invitro",
    "LART",
    "Lacute",
    "PART",
    "Uninfected"
  ),
  folders = c(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/"
  )
)

#sample_output.dir <- "/projects/b1042/GoyalLab/egrody/extractionScripts/submissionScripts/"
#write.csv(samples, paste0(sample_output.dir, "GEX_samples.csv"), row.names = FALSE)

# filtered input
#input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/extracted"

# filtered after join
#input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/reads/20250518/converted/min2/nocountLTR/"
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/reads/newcoords/minimum"
SALVE_data <- read_sample_files(samples$samples, input.dir)
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/bamsort/reads/newcoords/minimum"
GEX_data <- read_sample_files(samples$samples, input.dir)

GEX_UMAP <- list()

for (i in 1:nrow(samples)) {
  dataset_name <- samples$datasets[i]
  sample_name <- samples$samples[i]
  folder_path <- paste0(samples$folders[i], "expressionDF/")
  
  tryCatch({
    # Read CSV
    input_filename <- paste0(folder_path, dataset_name, "_Mmulmac_mac239.csv")
    data <- read.csv(input_filename)
    data <- data %>%
      select(-X, -mac239)
   
    # Store the data with the sample name
    GEX_UMAP[[sample_name]] <- data
   
    cat("Processed sample:", dataset_name, "as", sample_name, "\n")
 }, error = function(e) {
    cat("Error processing", dataset_name, ":", conditionMessage(e), "\n")
 })
  rm(data)
}




regions_to_isoforms <- function(mode, dataframe) {
  if (mode != "SALVE" & mode != "GEX") {
    stop("mode must be either SALVE or GEX")
  }
  if (class(dataframe != "data.frame")) {
    stop("Input data must be in data.frame format (i.e. not a list)")
  }
  if (mode == "SALVE") {
    dataframe <- dataframe %>%
      mutate(SALVE_any = (LTR + nef), SALVE_Sspliced = (D1_S + tat_US), SALVE_Mspliced = tat_S) %>% #not correct, update
      rename(SALVE_unspliced = D1_US) %>%
      select(cellID, SALVE_any, SALVE_unspliced, SALVE_Sspliced, SALVE_Mspliced) %>%
      mutate(SALVE_total = (SALVE_any + SALVE_unspliced + SALVE_Sspliced + SALVE_Mspliced))
  } else if (mode == "GEX") {
    dataframe <- dataframe %>%
      mutate(GEX_any = (LTR_D1 + A7_LTR), GEX_spliced = (A1_D4 + D4_A7)) %>%
      rename(GEX_unspliced = D1_A1) %>%
      select(cellID, GEX_any, GEX_unspliced, GEX_spliced) %>%
      mutate(GEX_total = (GEX_any + GEX_unspliced + GEX_spliced))
  }
  return(dataframe)
}
```


Making left_join dataframe
```{r}
joint_data <- list()
for (i in 1:nrow(samples)) {
  sample_name <- samples$samples[i]
  
  tryCatch({
    SALVE <- SALVE_data %>%
      filter(sample == sample_name) %>%
      select(-sample) %>%
      rename(SALVE = total)
    GEX <- GEX_data %>%
      filter(sample == sample_name) %>%
      select(-sample) %>%
      rename(GEX = total)
    GEX_UMAPs <- GEX_UMAP[[sample_name]]
    temp <- left_join(GEX_UMAPs, GEX, by = "cellID")
    joint_data[[sample_name]] <- left_join(temp, SALVE, by = "cellID")
    
    cat("Processed sample:", sample_name, "\n")
  }, error = function(e) {
    cat("Error processing", sample_name, ":", conditionMessage(e), "\n")
  })
}
# This should be outside the loop
joint_data <- lapply(joint_data, function(x) {
  x[is.na(x)] <- 0
  return(x)
})

#rm(list = setdiff(ls(), c("joint_data", "SALVE_data", "GEX_data", "GEX_UMAP", 
#                          ls()[sapply(ls(), function(x) is.function(get(x)))])))

```

To get metrics for the left_join dataframes:
```{r}
#output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/joint/filtered/"

# Create directories if they don't exist
#dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

cat("\nSample\tTotal_cells\tboth\t10X_only\tSALVE_only\n")

# Process each dataset in the joint_data list
for (sample_name in names(joint_data)) {
  # Get the current dataframe
  current_df <- joint_data[[sample_name]] #%>%
    #mutate(SALVE = (D1_US + D1_S + tat_S + tat_US + nef )) %>%
    #mutate(GEX = (LTR_D1  + D1_A1  + A1_D4 + D4_A7 + A7_LTR))
  
  # Create the subsets based on mac239 and total columns
  both <- current_df %>% filter(GEX != 0 & SALVE != 0)
  onlySingleCell <- current_df %>% 
    filter(GEX != 0) %>%
    filter(!(cellID %in% both$cellID))
  onlySALVE <- current_df %>% 
    filter(SALVE != 0) %>%
    filter(!(cellID %in% both$cellID))

  
  # Print data row for each sample
  cat(sample_name, "\t", 
      nrow(current_df), "\t", 
      nrow(both), "\t", 
      nrow(onlySingleCell), "\t", 
      nrow(onlySALVE), "\n")
  
  # Save CSVs
  #write.csv(both, paste0(output_dir, "left_", sample_name, "_both.csv"), row.names = FALSE)
  #write.csv(onlySingleCell, paste0(output_dir, "left_", sample_name, "_onlySingleCell.csv"), row.names = FALSE)
  #write.csv(onlySALVE, paste0(output_dir, "left_", sample_name, "_onlySALVE.csv"), row.names = FALSE)
  #write.csv(current_df, paste0(output_dir, "left_", sample_name, "_all.csv"), row.names = FALSE)
}

```


Plotting
```{r}
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/joint/"
plotUMAP(Pacute_paint_umap, mac239, "Pacute: mac239", output.dir, "Pacute_umap_singleCell.svg")
plotUMAP(Pacute_paint_umap, total_lessLTR, "Pacute: SALVE (total_lessLTR)", output.dir, "Pacute_umap_SALVE.svg")

plotUMAP(Pacute_paint_umap, mac239, "Pacute: mac239", output.dir, "Pacute_umap_singleCell.svg", color_max = max(Pacute_paint_umap$total_lessLTR))
plotUMAP(Pacute_paint_umap, total_lessLTR, "Pacute: SALVE (total_lessLTR)", output.dir, "Pacute_umap_SALVE_totallessLTR.svg")
plotUMAP(Pacute_paint_umap, tat_S, "Pacute: SALVE (tat S)", output.dir, "Pacute_umap_SALVE_tatS.svg")
plotUMAP(Pacute_paint_umap, tat_US, "Pacute: SALVE (tat US)", output.dir, "Pacute_umap_SALVE_tatUS.svg")
plotUMAP(Pacute_paint_umap, D1_S, "Pacute: SALVE (D1 S)", output.dir, "Pacute_umap_SALVE_D1S.svg")
plotUMAP(Pacute_paint_umap, D1_US, "Pacute: SALVE (D1 US)", output.dir, "Pacute_umap_SALVE_D1US.svg")
plotUMAP(Pacute_paint_umap, absolute, "Pacute: SALVE (absolute)", output.dir, "Pacute_umap_SALVE_absolute.svg")

cat(
  "Number of US (unspliced) cells: \t",
  sum(Pacute_paint_umap$D1_US > 0),
  "\nNumber of S (spliced) cells: \t\t",
  sum(Pacute_paint_umap$D1_S > 0 | Pacute_paint_umap$tat_S > 0),
  "\nNumber of cells with both: \t\t",
  sum(Pacute_paint_umap$D1_US > 0 & (Pacute_paint_umap$D1_S > 0 | Pacute_paint_umap$tat_S > 0))
)
```


### Counts histograms
What is the distribution of counts for SALVE?
```{r}
SALVE_data <- SALVE_data %>%
  #mutate(log1pSALVE = log1p(total_lessLTR)) %>%
  filter(!(sample == "Pacute"))
#max_value <- max(SALVE_data$log1pSALVE, na.rm = TRUE) 
max_value <- max(150) #for counts expression, update the indicated fields
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/histograms/"

library(patchwork)
plot_list <- list()

for (i in 1:nrow(samples)) {
  if (samples$samples[i] != "Pacute") {
    sample_name <- samples$samples[i]
    expression <- SALVE_data %>%
      filter(sample == sample_name)
    p <- ggplot(expression, aes(x=total_lessLTR)) + #update
      geom_histogram(binwidth=1) + 
      theme_minimal() +
      scale_x_continuous(limits = c(0, max_value)) + 
      labs(title = paste0(sample_name, " SALVE counts"),
           x = "total_lessLTR") #update
    plot_list[[i]] <- p
    #print(p)
    #output_file <- file.path(output.dir, paste0(sample_name, "_log_expression.svg")) #update
    #ggsave(filename = output_file, plot = p, device = "svg", width = 8, height = 6)
  }
}

plot_list <- plot_list[!sapply(plot_list, is.null)]

if (length(plot_list) <= 9) {
  # If 9 or fewer plots, create a clean 3x3 grid
  combined_plot <- (plot_list[[1]] | plot_list[[2]] | plot_list[[3]]) /
                   (plot_list[[4]] | plot_list[[5]] | plot_list[[6]]) /
                   (plot_list[[7]] | plot_list[[8]] | plot_list[[9]])
  
  # Handle cases with fewer than 9 plots
  combined_plot <- wrap_plots(plot_list, ncol = 3)
  
  # Add a shared title if desired
  combined_plot <- combined_plot + 
    plot_annotation(title = "SALVE Expression Across Samples",
                   theme = theme(plot.title = element_text(hjust = 0.5, size = 16)))
  
  # Print the combined plot
  print(combined_plot)
}
```

For absolute:
```{r}
SALVE_data <- SALVE_data %>%
  mutate(log1pSALVE = log1p(total_lessLTR))
max_value <- max(SALVE_data$log1pSALVE, na.rm = TRUE) 
#max_value <- max(SALVE_data$total_lessLTR, na.rm = TRUE) #for counts expression, update the indicated fields
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/histograms/"

for (i in 1:nrow(samples)) {
  sample_name <- samples$samples[i]
  expression <- SALVE_data %>%
    filter(sample == sample_name)
  p <- ggplot(expression, aes(x=log1pSALVE)) + #update
    geom_histogram() + 
    theme_minimal() +
    scale_x_continuous(limits = c(0, max_value)) + 
    labs(title = paste0(sample_name, " SALVE expression"),
         x = "log1p(total_lessLTR)") #update
  print(p)
  output_file <- file.path(output.dir, paste0(sample_name, "_log_absolute.svg")) #update
  #ggsave(filename = output_file, plot = p, device = "svg", width = 8, height = 6)
}
```

### Barcode rank plot
```{r}
for (i in 1:nrow(samples)) {
  sample_name <- samples$samples[i]
  cat("\nProcessing barcodeRankPlot for sample:", sample_name, "\n")
  
  # Filter SALVE_data to get only rows for the current sample
  sample_data <- SALVE_data %>% 
    filter(sample == sample_name)
  
  # Skip if no data for this sample
  if (nrow(sample_data) == 0) {
    cat("No data found for sample", sample_name, "in SALVE_data. Skipping.\n")
    next
  }
  
  # Construct the path to the raw data folder
  rawDataFolder <- paste0(samples$folders[i], "Mmul_10_mac239_", samples$datasets[i], "/outs/raw_feature_bc_matrix/")
  
  # Check if the raw data folder exists
  if (!dir.exists(rawDataFolder)) {
    cat("Raw data folder not found:", rawDataFolder, "\nSkipping.\n")
    next
  }
  
  # Set output directory and filename
  output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/joint/"
  saveas <- paste0("barcodeRankPlot_", sample_name, ".svg")
  
  # Make sure output directory exists
  if (!dir.exists(output_dir)) {
    dir.create(output_dir, recursive = TRUE)
    cat("Created output directory:", output_dir, "\n")
  }
  
  # Run the barcodeRankPlot function with the sample-specific data
  tryCatch({
    barcodeRankPlot(
      rawDataFolder = rawDataFolder,
      jointFullJoin = sample_data,
      plotTitle = paste0("Barcode Rank Plot: ", sample_name),
      output_dir = output_dir,
      saveas = saveas
    )
    
    cat("Successfully generated plot for", sample_name, "\n")
  }, error = function(e) {
    cat("Error generating barcodeRankPlot for", sample_name, ":", conditionMessage(e), "\n")
  })
}
```


### joint with bamsort (skip)

This section was used for troubleshooting
Run first chunk of Joint and last chunk of SALVE

```{r}
SALVE_D13 <- SALVE_data %>%
  filter(sample == "D13") %>%
  select(-sample)

#skip
cat(
  "Cells in both bamsort and SALVE: \t",
  sum(GEX_bamsort_clean$cellID %in% GEX_mkcounts_minimal$cellID),
  "\t", (sum(GEX_bamsort_clean$cellID %in% GEX_mkcounts_minimal$cellID) / length(GEX_bamsort_clean$cellID)*100),"%",
  "\nCells in bamsort in original GEX: \t",
  sum(GEX_bamsort_clean$cellID %in% GEX_mkcounts$cellID),
  "\t", (sum(GEX_bamsort_clean$cellID %in% GEX_mkcounts$cellID) / length(GEX_bamsort_clean$cellID)*100),"%")
#/skip

full_SALVE <- full_join(GEX_bamsort_clean, SALVE_D13, by = join_by(cellID)) %>%
  mutate(bamsort = log1p(UMI))
full_SALVE[is.na(full_SALVE)] <- 0

max_value <- max(max(full_SALVE$total_lessLTR, na.rm = TRUE), 
                 max(full_SALVE$bamsort, na.rm = TRUE))

ggplot(full_SALVE, aes(x = total_lessLTR, y = bamsort)) + 
  geom_point() + 
  theme_minimal() +
  coord_fixed(ratio = 1) + 
  scale_x_continuous(limits = c(0, max_value)) + 
  scale_y_continuous(limits = c(0, max_value)) +
  labs(title= "D13 SALVE vs bamsort no filters")

cat(
    "Correlation between bamsort and SALVE (read and UMI filter):",
    round(cor(full_SALVE$bamsort, full_SALVE$total_lessLTR, method="pearson"), 3))

nozeros <- full_SALVE %>%
  filter(!(total_lessLTR == 0 | bamsort == 0))

cat(
    "Correlation between bamsort and SALVE (read and UMI filter):",
    round(cor(nozeros$bamsort, nozeros$total_lessLTR, method="pearson"), 3))
```

Filtering SALVE by raw barcodes from GEX
```{r}
raw_cellIDs <- list()

for (i in 1:nrow(samples)) {
  dataset_name <- samples$datasets[i]
  sample_name <- samples$samples[i]

  rawDataFolder <- paste0(samples$folders[i], "Mmul_10_mac239_", samples$datasets[i], "/outs/raw_feature_bc_matrix/")

  tryCatch({
    rawdata <- Read10X(rawDataFolder)
    umi_counts <- colSums(rawdata)
    cell_ids <- names(umi_counts[umi_counts > 100]) # keep only cells with transcriptomes
    raw_cellIDs[[sample_name]] <- cell_ids

    
  }, error = function(e) {
    cat("Error processing", dataset_name, ":", conditionMessage(e), "\n")
  })
  
  if (exists("rawdata")) {
    rm(rawdata)
    gc()
  }
}

SALVE_brp <- SALVE_D13 %>%
  filter(cellID %in% raw_cellIDs$D13)

full_SALVE <- full_join(GEX_bamsort_clean, SALVE_brp, by = join_by(cellID)) %>%
  mutate(bamsort = log1p(UMI))
full_SALVE[is.na(full_SALVE)] <- 0

max_value <- max(max(full_SALVE$total_lessLTR, na.rm = TRUE), 
                 max(full_SALVE$bamsort, na.rm = TRUE))

ggplot(full_SALVE, aes(x = total_lessLTR, y = bamsort)) + 
  geom_point() + 
  theme_minimal() +
  coord_fixed(ratio = 1) + 
  scale_x_continuous(limits = c(0, max_value)) + 
  scale_y_continuous(limits = c(0, max_value)) +
  labs(title= "D13 SALVE vs bamsort no filters")

```

Unfiltered SALVE
SALVE_full is now prefiltered for raw barcodes with UMI > 100; use SALVE_raw for unfiltered list
```{r}
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/extracted"
SALVE_full <- read_salve_data(samples$samples, input.dir, filtered = FALSE)

SALVE_D13_full_df <- SALVE_full %>%
  filter(sample == "D13") %>%
  select(-sample)


GEX_bamsort_clean_in <- GEX_bamsort_clean %>%
  filter(cellID %in% raw_cellIDs$D13)

full_SALVE <- full_join(GEX_bamsort_clean_in, SALVE_brp_full, by = join_by(cellID)) %>%
  mutate(bamsort = log1p(UMI)) %>%
  select(-UMI)
full_SALVE[is.na(full_SALVE)] <- 0

max_value <- max(max(full_SALVE$total_lessLTR, na.rm = TRUE), 
                 max(full_SALVE$bamsort, na.rm = TRUE))

ggplot(full_SALVE, aes(x = total_lessLTR, y = bamsort)) + 
  geom_point() + 
  theme_minimal() +
  coord_fixed(ratio = 1) + 
  scale_x_continuous(limits = c(0, max_value)) + 
  scale_y_continuous(limits = c(0, max_value)) +
  labs(title= "D13 SALVE no filters vs bamsort no filter")


both <- sum(full_SALVE$total_lessLTR !=0 & full_SALVE$bamsort !=0)
onlySALVE <- sum(full_SALVE$total_lessLTR !=0 & full_SALVE$bamsort ==0)
onlybamsort <- sum(full_SALVE$total_lessLTR ==0 & full_SALVE$bamsort !=0)

whoareyou <- full_SALVE %>%
  filter(!(total_lessLTR !=0 & bamsort !=0)) %>%
  filter(!(total_lessLTR !=0 & bamsort ==0)) %>%
  filter(!(total_lessLTR ==0 & bamsort !=0))

cat(
  "total_lessLTR:\n# cells in SALVE and bamsort: \t\t",
  both,
  "\n# cells in SALVE unfiltered only: \t",
  onlySALVE,
  "\n# cells in bamsort unfiltered only: \t",
  onlybamsort
)

cat(
    "Correlation between bamsort and SALVE:",
    round(cor(full_SALVE$bamsort, full_SALVE$total_lessLTR, method="pearson"), 3))

nozeros <- full_SALVE %>%
  filter(!(total_lessLTR == 0 | bamsort == 0))

cat(
    "Correlation between bamsort and SALVE (read and UMI filter):",
    round(cor(nozeros$bamsort, nozeros$total_lessLTR, method="pearson"), 3))
```

### joint with mkcounts (skip)
```{r}
full_SALVE <- full_join(GEX_mkcounts, SALVE_D13_full_df, by = join_by(cellID)) #updated for new SALVE data format
full_SALVE[is.na(full_SALVE)] <- 0

max_value <- max(max(full_SALVE$total_lessLTR, na.rm = TRUE), 
                 max(full_SALVE$mac239, na.rm = TRUE))

ggplot(full_SALVE, aes(x = total_lessLTR, y = mac239)) + 
  geom_point() + 
  theme_minimal() +
  coord_fixed(ratio = 1) + 
  scale_x_continuous(limits = c(0, max_value)) + 
  scale_y_continuous(limits = c(0, max_value)) +
  labs(title= "D13 SALVE no filters vs mkcounts")


both <- sum(full_SALVE$total !=0 & full_SALVE$mac239 !=0)
onlySALVE <- sum(full_SALVE$total !=0 & full_SALVE$mac239 ==0)
onlymkcounts <- sum(full_SALVE$total ==0 & full_SALVE$mac239 !=0)

whoareyou <- full_SALVE %>%
  filter(!(total_lessLTR !=0 & bamsort !=0)) %>%
  filter(!(total_lessLTR !=0 & bamsort ==0)) %>%
  filter(!(total_lessLTR ==0 & bamsort !=0))

cat(
  "total:\n# cells in SALVE and bamsort: \t\t",
  both,
  "\n# cells in SALVE unfiltered only: \t",
  onlySALVE,
  "\n# cells in mkcounts only: \t\t",
  onlymkcounts
)


cat(
    "Correlation between mkcounts and SALVE:",
    round(cor(full_SALVE$mac239, full_SALVE$total_lessLTR, method="pearson"), 3))

nozeros <- full_SALVE %>%
  filter(!(total_lessLTR == 0 | mac239 == 0))

cat(
    "Correlation between bamsort and SALVE (read and UMI filter):",
    round(cor(nozeros$mac239, nozeros$total_lessLTR, method="pearson"), 3))
```


### Correlation analysis (not updated below here)
Will do it custom for now and update correlation plot function later
```{r}
cat(
  "Correlation between 10X mac239 and SALVE total_lessLTR:\n",
    "  Pearson: ", round(cor(Pacute_paint_umap$mac239, Pacute_paint_umap$total_lessLTR, method="pearson"), 3),
    "\n  Spearman: ", round(cor(Pacute_paint_umap$mac239, Pacute_paint_umap$total_lessLTR, method="spearman"), 3),
    
    "\n\nCorrelation between 10X mac239 and SALVE absolute:\n",
    "  Pearson: ", round(cor(Pacute_paint_umap$mac239, Pacute_paint_umap$absolute, method="pearson"), 3),
    "\n  Spearman: ", round(cor(Pacute_paint_umap$mac239, Pacute_paint_umap$absolute, method="spearman"), 3)
)

# plotting
plot <- ggplot(data = Pacute_paint_umap, aes(x = total_lessLTR, y = mac239)) +
      geom_point() +
      labs(
        x = "SALVE total counts: D1 + tat + nef (filter > 2)",
        y = "SingleCell mac239 counts",
        title = "Pacute joint: total count") +
      theme_minimal() + 
    coord_fixed(ratio = 1)
plot <- ggplot(data = Pacute_paint_umap, aes(x = absolute, y = mac239)) +
      geom_point() +
      labs(
        x = "SALVE absolute (5' LTR) counts (filter > 0)",
        y = "SingleCell mac239 counts",
        title = "Pacute joint: absolute count") +
      theme_minimal() +
    coord_fixed(ratio = 1)
plot + theme(aspect.ratio = 1)
```


## Subset analysis

### Making Mmul10 clusters dataframe (skip)
```{r}
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/Seurat/Mmul_10/"
Pacute <- SeuratPipeline("/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10/Mmul_10_P_acute_GEX/outs/filtered_feature_bc_matrix/", "Pacute", output.dir, plots = TRUE)

output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10/"
SingleCell_Pacute <- targetExpressionDF(Pacute, "CD4")
SingleCell_Pacute_clusters <- SingleCell_Pacute %>% select(-CD4)
write.csv(SingleCell_Pacute_clusters, paste0(output.dir, "Pacute_Mmul10_clusters.csv"))
```

### Loading
Combining the coordinates and clusters from SingleCell aligned to Mmul_10 with the mac239 expression from SingleCell aligned to Mmul_10_mac239
```{r}
SingleCell_Pacute_clusters <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10/Pacute_Mmul10_clusters.csv", row.names = "X")
SingleCell_Pacute_mac239 <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/Pacute_Mmulmac_mac239.csv", row.names = "X")
Pacute_SALVE <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS013/SALVE/bamsort/Pacute_SALVE_filtered.csv", row.names = "X")

SingleCell_Pacute_mac239 <- SingleCell_Pacute_mac239 %>% select(cellID, mac239)
SingleCell_Pacute <- left_join(SingleCell_Pacute_clusters, SingleCell_Pacute_mac239, by = "cellID")

Pacute_paint_umap = left_join(SingleCell_Pacute, Pacute_SALVE, by = "cellID")
Pacute_paint_umap[is.na(Pacute_paint_umap)] <- 0
```


```{r plotting}
# Function to create Seurat-style DimPlot
plot_clusters <- function(data, 
                         label_clusters = TRUE,
                         pt_size = 0.5,
                         label_size = 4) {
  
  # Convert the cluster column to a factor
  data$cluster <- as.factor(data$cluster)
  
  n_clusters <- length(unique(data$cluster))
  cluster_colors <- scales::hue_pal()(n_clusters)
  
  p1 <- ggplot(data, aes(x = UMAP1, y = UMAP2, color = cluster)) +
    geom_point(size = pt_size) +
    scale_color_manual(values = cluster_colors) +
    theme_bw() +
    theme(
      panel.grid = element_blank(),
      axis.title = element_text(size = 12),
      legend.title = element_blank(),
      panel.border = element_rect(colour = "black", fill = NA)
    )
  
  if (label_clusters) {
    cluster_centers <- data %>%
      group_by(cluster) %>%
      summarise(
        UMAP1 = median(UMAP1),
        UMAP2 = median(UMAP2)
      )
    
    p1 <- p1 + geom_text(data = cluster_centers,
                         aes(label = cluster),
                         size = label_size,
                         color = "black")
  }
  
  return(p1)
}

# Function to create Seurat-style FeaturePlot
plot_gene_expression <- function(data,
                               countcolumn,
                               pt_size = 0.5,
                               min_cutoff = NA,
                               max_cutoff = NA) {
  
  plot_data <- data
  if (!is.na(min_cutoff)) {
    plot_data[[countcolumn]][plot_data[[countcolumn]] < min_cutoff] <- min_cutoff
  }
  if (!is.na(max_cutoff)) {
    plot_data[[countcolumn]][plot_data[[countcolumn]] > max_cutoff] <- max_cutoff
  }
  
  p2 <- ggplot(plot_data, aes(x = UMAP1, y = UMAP2)) +
    geom_point(data = subset(plot_data, plot_data[[countcolumn]] <= 0),
               color = "gray93",
               size = pt_size) +
    geom_point(data = subset(plot_data, plot_data[[countcolumn]] > 0),
               aes_string(color = countcolumn),  # Use aes_string instead
               size = pt_size) +
    scale_color_gradient(low = "gray93", high = "darkblue",
                        name = "Expression") +
    theme_bw() +
    theme(
      panel.grid = element_blank(),
      axis.title = element_text(size = 12),
      panel.border = element_rect(colour = "black", fill = NA)
    )
  
  return(p2)
}

cluster_plot <- plot_clusters(Pacute_paint_umap)
xprn_plot_SALVE <- plot_gene_expression(Pacute_paint_umap, "total_lessLTR")
xprn_plot_SingleCell <- plot_gene_expression(Pacute_paint_umap, "mac239")
intersect_umap <- Pacute_paint_umap %>%
  mutate(total_lessLTR = ifelse(mac239 == 0, 0, total_lessLTR))
xprn_plot_intersect <- plot_gene_expression(intersect_umap, "total_lessLTR") #SALVE xprn in cells that are 10X+

output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/joint/subset/"
ggsave(cluster_plot, file = paste0(output_dir, "Pacute_umap_cluster.svg"))
ggsave(xprn_plot_SALVE, file = paste0(output_dir, "Pacute_umap_SALVE.svg"))
ggsave(xprn_plot_SingleCell, file = paste0(output_dir, "Pacute_umap_SingleCell.svg"))
ggsave(xprn_plot_intersect, file = paste0(output_dir, "Pacute_umap_intersect.svg"))

cat("SingleCell vRNA+: ", sum(invitro_paint_umap$log2SingleCell != 0, na.rm = TRUE),
    "\nSALVE vRNA+: ", sum(invitro_paint_umap$Count != 0, na.rm = TRUE),
    "\nCells in common: ", sum(intersect_umap$Count != 0, na.rm = TRUE))

write.csv(invitro_paint_umap, paste0(output_dir, "invitro_paint_umap.csv"))


```

Quick correlation plot:
```{r correlation plotting}
innerjoin <- inner_join(SingleCell_Pacute_mac239, Pacute_SALVE, by = "cellID")
Pacute_innerjoin <- left_join(SingleCell_Pacute_clusters, innerjoin, by = "cellID")
Pacute_innerjoin[is.na(Pacute_innerjoin)] <- 0

cat("Correlation of invitro between 10X and SALVE (total_lessLTR):", cor(Pacute_innerjoin$mac239, Pacute_innerjoin$total_lessLTR))
corrplot <- ggplot(data = Pacute_innerjoin, aes(x=total_lessLTR, y=mac239)) +
  geom_point() + 
  xlim(0,10) + 
  ylim(0,10) +
  theme_minimal() + 
  theme(aspect.ratio = 1) + 
  labs(title = "inner_join correlation")
corrplot
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/joint/subset/"
ggsave(corrplot, file = paste0(output.dir, "innerjoin_correlationplot.svg"))
```

### DEG analysis (break point)

```{r}
list_of_cells <- Pacute_paint_umap %>% filter(total_lessLTR != 0) #for SALVE
list_of_cells <- Pacute_paint_umap %>% filter(mac239 != 0) #for 10X
list_of_cells <- list_of_cells$cellID

Pacute <- SeuratPipeline("/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10/Mmul_10_P_acute_GEX/outs/filtered_feature_bc_matrix/", "Pacute", plots = FALSE)

#This analysis takes ~8 minutes
results <- analyze_cell_subset(Pacute, list_of_cells)
```

### Saving results
```{r}
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/joint/subset/singleCell/"
save_subset_analysis(results, output_dir = output.dir)
plot_subset_analysis(Pacute, results, list_of_cells, output_dir = paste0(output.dir, "plots/"))
```

### Interpreting results
```{r}
# Create filtered results list
filteredDEG <- lapply(results$cluster_specific, function(df) {
  if (!is.null(df) && nrow(df) > 0) {
    # Filter for significant adjusted p-value and log2FC threshold
    df[df$p_val_adj < 0.05 & abs(df$avg_log2FC) > 0.5, ]
  } else {
    NULL
  }
})

# Remove any empty results
filteredDEG <- filteredDEG[sapply(filteredDEG, function(x) !is.null(x) && nrow(x) > 0)]

# Print summary of how many genes passed filters in each cluster
for (cluster in names(filteredDEG)) {
  cat(sprintf("Cluster %s: %d genes\n", cluster, nrow(filteredDEG[[cluster]])))
}

# Saving
wb <- createWorkbook()
# Add each cluster's results as a separate worksheet
for (cluster_name in names(filteredDEG)) {
    de_results <- filteredDEG[[cluster_name]]
    if (!is.null(de_results) && nrow(de_results) > 0) {
        # Add cluster results as a worksheet
        addWorksheet(wb, cluster_name)
        # Add data with gene names as a column
        de_results$gene <- rownames(de_results)
        writeData(wb, cluster_name, de_results)
    }
}

# Save the workbook
saveWorkbook(wb, paste0(output.dir, "cluster_specific_DE_filtered.xlsx"), overwrite = TRUE)



filteredConserv <- results$conserved_markers %>%
    filter(p_val_adj < 0.05 & abs(avg_log2FC) > 0.5)

# Print summary of how many genes passed filters in each cluster
cat(sprintf("Conserved markers: %d genes\n", nrow(filteredConserv)))

# For each gene in conserved_markers, let's check which clusters show it as significant
check_gene_presence <- function(gene, cluster_results, p_val_thresh = 0.05, log2fc_thresh = 0.5) {
  # Initialize list to store results
  presence <- list()
  
  # Check each cluster
  for(cluster in names(cluster_results)) {
    de_results <- cluster_results[[cluster]]
    if(!is.null(de_results) && gene %in% rownames(de_results)) {
      # Get gene stats for this cluster
      gene_stats <- de_results[gene,]
      # Check if it meets significance criteria
      if(gene_stats$p_val_adj < p_val_thresh && abs(gene_stats$avg_log2FC) > log2fc_thresh) {
        presence[[cluster]] <- c(
          p_val_adj = gene_stats$p_val_adj,
          avg_log2FC = gene_stats$avg_log2FC
        )
      }
    }
  }
  
  # Return number of clusters and which clusters
  return(list(
    n_clusters = length(presence),
    clusters = names(presence),
    details = presence
  ))
}

# First get cluster counts for each gene
cluster_counts <- lapply(rownames(filteredConserv), function(gene) {
  result <- check_gene_presence(gene, results$cluster_specific)
  data.frame(
    gene = gene,
    num_clusters = result$n_clusters,
    clusters = paste(result$clusters, collapse=",")
  )
}) %>% bind_rows()

# Add cluster information to filtered results
filteredConserv <- filteredConserv %>%
  mutate(gene = rownames(.)) %>%
  left_join(cluster_counts, by = "gene") %>%
  arrange(desc(num_clusters), desc(abs(avg_log2FC)))

# Save to Excel
wb <- createWorkbook()
addWorksheet(wb, "filtered_conserved")
writeData(wb, "filtered_conserved", filteredConserv)
saveWorkbook(wb, paste0(output.dir, "conserved_markers_filtered.xlsx"), overwrite = TRUE)
```


## Saturation analysis

### cellID sampling without reads
This is to look at cellID sampling to ask: why don't we see those 10X only cells also in SALVE?
```{r loading}
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/SALVE/bamsort/split/"
reads_D1 <- read.csv(paste0(input.dir, "D1_up_CI_bamsort_split_inside.csv"))
reads_LTR <- read.csv(paste0(input.dir, "LTR_CI_bamsort_split_inside.csv"))
reads_nef <- read.csv(paste0(input.dir, "nef_CI_bamsort_split_inside.csv"))
reads_tat <- read.csv(paste0(input.dir, "tat_up_CI_bamsort_split_inside.csv"))

reads_total <- bind_rows(reads_D1, reads_LTR, reads_nef, reads_tat) %>%
  group_by(cellID, UMI) %>%
  summarize(reads = sum(reads), .groups = "drop")

molecules_D1 <- reads_D1 %>% select(-reads)
molecules_LTR <- reads_LTR %>% select(-reads)
molecules_nef <- reads_nef %>% select(-reads)
molecules_tat <- reads_tat %>% select(-reads)
molecules_total <- reads_total %>% select(-reads)
```

```{r sampling and plotting}
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/SALVE/saturation/sample_cellID/"
samples <- list(
  D1 = molecules_D1,
  nef = molecules_nef,
  LTR = molecules_LTR,
  tat = molecules_tat,
  total = molecules_total)

for (sample_name in names(samples)) {
  sample_data <- samples[[sample_name]]
  
  results <- sample_cellID(sample_data)
  summary <- analyze_cellID_sampling(results, title = paste0("cellID Saturation: ", sample_name))
  
  results_file <- paste0(output.dir, sample_name, "_sample_cellID_results.csv")
  summary_file <- paste0(output.dir, sample_name, "_sample_cellID_summary.csv")
  write.csv(results, results_file, row.names = FALSE)
  write.csv(summary, summary_file, row.names = FALSE)
  
  cat("Processed sample:", sample_name, "\n")
}
```

```{r model fitting}
model_results <- fit_models(results, target_coverage = 95)
model_results <- fit_models(results, target_coverage = 99)
model_results <- fit_models(results, target_coverage = 100)
model_results <- fit_models(results, target_coverage = 120)
```

### UMI sampling with reads
Now looking at UMI sampling to get full picture of read saturation
```{r}
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/SALVE/saturation/sample_UMI/"
samples <- list(
  D1 = reads_D1,
  nef = reads_nef,
  LTR = reads_LTR,
  tat = reads_tat,
  total = reads_total)

for (sample_name in names(samples)) {
  sample_data <- samples[[sample_name]]
  
  results <- sample_UMI_weighted(sample_data)
  summary <- analyze_UMI_sampling(results, title = paste0("Weighted UMI Saturation: ", sample_name))
  
  results_file <- paste0(output.dir, sample_name, "_sample_UMI_results.csv")
  summary_file <- paste0(output.dir, sample_name, "_sample_UMI_summary.csv")
  write.csv(results, results_file, row.names = FALSE)
  write.csv(summary, summary_file, row.names = FALSE)
  
  cat("Processed sample:", sample_name, "\n")
}

```

```{r}
model_results <- fit_models(results, target_coverage = 95, coverage_column = "pair_coverage")
model_results <- fit_models(results, target_coverage = 98.9, coverage_column = "pair_coverage")
model_results <- fit_models(results, target_coverage = 100, coverage_column = "pair_coverage")
model_results <- fit_models(results, target_coverage = 120)
```

### SALVE Summary: mac239 vs Mmul_10
```{r loading}
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/SALVE/bamsort/split/"
reads_summary <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS013/SALVE/bamsort/split/all_samples_summary.txt", header = TRUE)

sample_names <- reads_summary$Sample
df_numeric <- reads_summary[, -which(names(reads_summary) == "Sample")]
df_transposed <- as.data.frame(t(df_numeric))
colnames(df_transposed) <- sample_names
rownames(df_transposed) <- c("Inside_Rows", "Inside_Total_Reads", "Outside_Rows", "Outside_Total_Reads")
df_transposed <- rbind(df_transposed, Inside_Fraction = round(df_transposed["Inside_Total_Reads",] / df_transposed["Outside_Total_Reads",], 2), Avg_Inside_Reads = round(df_transposed["Inside_Total_Reads",] / df_transposed["Inside_Rows",], 2))

```
