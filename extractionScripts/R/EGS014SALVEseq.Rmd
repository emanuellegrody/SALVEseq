---
title: "EGS014SALVEseq"
author: "Emanuelle Grody"
date: "2025-04-04"
output: html_document
---

```{r, echo = FALSE}
source("~/SALVEseq/packages.R")
source("~/SALVEseq/functions.R")
```

# Individual Datasets
## GEX 

### bamsort
```{r}
samples <- data.frame(
  datasets = c(
    "JK85_D13",
    "LP29_D195",
    "LP29_D83",
    "G_ART_GEX",
    "invitro",
    "L_ART_GEX",
    "L_acute_GEX",
    "P_ART_GEX",
    "W0"
  ),
  samples = c(
    "D13",
    "D195",
    "D83",
    "GART",
    "Invitro",
    "LART",
    "Lacute",
    "PART",
    "Uninfected"
  ),
  folders = c(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/"
  )
)

# Process
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/bamsort/alignment/newcoords"
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/bamsort/reads/newcoords"

raw_cellIDs_df <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/raw_cellIDs/all_raw_cellIDs.csv")
raw_cellIDs <- split(raw_cellIDs_df$cellID, raw_cellIDs_df$sample)

process_bamsort("GEX", samples$samples, input.dir, output.dir, raw_cellIDs)

# Minimums
input_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/bamsort/reads/newcoords"
output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/bamsort/reads/newcoords/minimum"

process_all_set_minimums("GEX", samples$samples, input_dir, output_dir, min_reads_cell = 2)

```

### UMAP coords

```{r}
samples <- data.frame(
  datasets = c(
    "JK85_D13",
    "LP29_D195",
    "LP29_D83",
    "G_ART_GEX",
    "invitro",
    "L_ART_GEX",
    "L_acute_GEX",
    "P_ART_GEX",
    "W0"
  ),
  samples = c(
    "D13",
    "D195",
    "D83",
    "GART",
    "Invitro",
    "LART",
    "Lacute",
    "PART",
    "Uninfected"
  ),
  folders = c(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/"
  )
)

output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/Seurat/UMAPcoords/"
if (!dir.exists(output.dir)) {
  dir.create(output.dir, recursive = TRUE)
}

for (i in 1:nrow(samples)) {
  sample_name <- samples$samples[i]
  dataset <- samples$datasets[i]
  folder <- samples$folders[i]
  input.dir <- paste0(folder, "Mmul_10_mac239_", dataset, "/outs/filtered_feature_bc_matrix/")
  
  tryCatch({
    seurat_obj <- SeuratPipeline(input.dir, sample_name, 
                                 output_dir = "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/Seurat/plots/", 
                                 plots = TRUE, rds = TRUE)
    
    # Generate expression data frame without gene expression
    sample_df <- targetExpressionDF(seurat_obj, genes = "")

    # Add sample and target columns to the dataframe
    sample_df$sample <- sample_name

    write.csv(sample_df, paste0(output.dir, sample_name, "UMAP_coords.csv"))
    
    cat("Processed sample:", sample_name, "\n")
  }, error = function(e) {
    cat("Error processing sample", sample_name, ":", conditionMessage(e), "\n\n")
  })
}
```

### expressionDF (skip)
Outputting expression matrices
```{r}
samples <- data.frame(
  samples = c(
    "JK85_D13",
    "LP29_D195",
    "LP29_D83",
    "invitro",
    "L_acute_GEX",
    "HD88_W0"
  )
)
genes <- c(
  "D1-US",
  "D1-S",
  "tat-US",
  "tat-S",
  "nef-3",
  "nef-5",
  "LTR-3",
  "LTR-5"
)
GEX_list <- list()

input_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/counts/"
output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/expressionDF/"

# Process each sample
for (i in 1:nrow(samples)) {
  sample_name <- samples$samples[i]
  input.dir <- paste0(input_dir, "Mmul_10_mac239v4_", sample_name, "/outs/filtered_feature_bc_matrix/")
  
  tryCatch({
    # Process the current sample
    seurat_obj <- SeuratPipeline(input.dir, sample_name, plots = FALSE)
    
    # Generate the target expression data frame
    sample_df <- targetExpressionDF(seurat_obj, genes, count_type = "raw")
      
    # Add sample and target columns to the dataframe
    sample_df$sample <- sample_name
    
    GEX_list[[length(GEX_list) + 1]] <- sample_df
    
    cat("Processed sample:", sample_name, "\n")
  }, error = function(e) {
    cat("Error processing sample", sample_name, ":", conditionMessage(e), "\n\n")
  })
}


GEX_combined <- data.frame()
GEX_combined <- bind_rows(GEX_list)
rm(GEX_list)

output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/counts/expressionDF/"
write.csv(GEX_combined, paste0(output.dir, "GEX_combined.csv"))

# Calculating isoforms
GEX_isoforms <- isoforms_deconvolve(GEX_combined, "GEX")
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/counts/expressionDF/"
write.csv(GEX_isoforms, paste0(output.dir, "GEX_isoforms.csv"))
```


## SALVE 

### bamsort
Run this once first to get raw cellIDs:
```{r raw_cellIDs}
# Load and save raw cell IDs from 10X data
raw_cellIDs <- list()
output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/raw_cellIDs" 

# Create output directory if it doesn't exist
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

samples <- data.frame(
  datasets = c(
    "JK85_D13",
    "LP29_D195",
    "LP29_D83",
    "G_ART_GEX",
    "invitro",
    "L_ART_GEX",
    "L_acute_GEX",
    "P_ART_GEX",
    "W0"
  ),
  samples = c(
    "D13",
    "D195",
    "D83",
    "GART",
    "Invitro",
    "LART",
    "Lacute",
    "PART",
    "Uninfected"
  ),
  folders = c(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/"
  )
)

all_cellIDs <- data.frame(cellID = character(), sample = character(), stringsAsFactors = FALSE)

for (i in 1:nrow(samples)) {
  dataset_name <- samples$datasets[i]
  sample_name <- samples$samples[i]
  rawDataFolder <- paste0(samples$folders[i], "Mmul_10_mac239_", samples$datasets[i], "/outs/raw_feature_bc_matrix/")
  
  tryCatch({
    rawdata <- Read10X(rawDataFolder)
    umi_counts <- colSums(rawdata)
    cell_ids <- names(umi_counts[umi_counts > 100]) # keep only cells with transcriptomes
    raw_cellIDs[[sample_name]] <- cell_ids
    cat("Loaded", length(cell_ids), "raw cellIDs for sample", sample_name, "\n")
    
    # Add to the combined dataframe
    sample_df <- data.frame(
      cellID = cell_ids,
      sample = rep(sample_name, length(cell_ids)),
      stringsAsFactors = FALSE
    )
    all_cellIDs <- rbind(all_cellIDs, sample_df)
    
    # Save individual sample's cell IDs to CSV
    sample_file <- file.path(output_dir, paste0(sample_name, "_raw_cellIDs.csv"))
    write.csv(data.frame(cellID = cell_ids), sample_file, row.names = FALSE)
    cat("Saved", length(cell_ids), "cell IDs to", sample_file, "\n")
    
  }, error = function(e) {
    cat("Error processing", dataset_name, ":", conditionMessage(e), "\n")
  })
  
  if (exists("rawdata")) {
    rm(rawdata)
    gc()
  }
}

# Save the combined cell IDs to a single CSV
combined_file <- file.path(output_dir, "all_raw_cellIDs.csv")
write.csv(all_cellIDs, combined_file, row.names = FALSE)
cat("Saved combined cell IDs to", combined_file, "\n")

# To easily load this data in the future:
# raw_cellIDs_df <- read.csv("path/to/output/directory/all_raw_cellIDs.csv")
# raw_cellIDs <- split(raw_cellIDs_df$cellID, raw_cellIDs_df$sample)
```

Making raw and full lists:
```{r}
samples <- data.frame(
  datasets = c(
    "JK85_D13",
    "LP29_D195",
    "LP29_D83",
    "G_ART_GEX",
    "invitro",
    "L_ART_GEX",
    "L_acute_GEX",
    "P_ART_GEX",
    "W0"
  ),
  samples = c(
    "D13",
    "D195",
    "D83",
    "GART",
    "Invitro",
    "LART",
    "Lacute",
    "PART",
    "Uninfected"
  )
)

input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/alignment/v5/"
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/reads/v5/"

raw_cellIDs_df <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/raw_cellIDs/all_raw_cellIDs.csv")
raw_cellIDs <- split(raw_cellIDs_df$cellID, raw_cellIDs_df$sample)

#process_bamsort("SALVE", samples$samples, input.dir, output.dir, raw_cellIDs)
process_bamsortv5(samples$samples, input.dir, output.dir, raw_cellIDs)

# minimums
input_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/reads/v5/"
output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/reads/v5/minimum" 

process_all_set_minimums("SALVE", samples$samples, input_dir, output_dir, min_reads = 5, min_umi = 3)

```


### Comparing isoform assignment to old assignment
```{r}
root <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/reads/"
oldcoords.dir <- paste0(root, "20250515/")
newcoords.dir <- paste0(root, "newcoords/")

mapping <- list(
  "D1_US" = c("US"),
  "D1_S" = c("S", "MS", "SS", "spliced"),
  "LTR" = c("any"),
  "nef" = c("any", "MS"),
  "tat_S" = c("MS"),
  "tat_US" = c("SS", "spliced")
)


for (sample in samples$samples) {
    cat("\nProcessing sample:", sample, "\n")
    
    # Get all files for current sample
    old_sample_file <- list.files(oldcoords.dir, 
                               pattern = paste0("^", sample, ".*_counts_all.csv$"), 
                               full.names = TRUE)
    new_sample_file <- list.files(newcoords.dir, 
                           pattern = paste0("^", sample, ".*_raw.csv$"), 
                           full.names = TRUE)

    old_coords <- read.csv(old_sample_file, stringsAsFactors = FALSE)
    new_coords <- read.csv(new_sample_file, stringsAsFactors = FALSE)
    
    joint <- left_join(old_coords, new_coords, by = join_by(cellID, UMI))
    analyze_category_pairs(joint, mapping)
    
}


analyze_category_pairs <- function(df, mapping_list) {
  # Handle both old format (old_map, new_map vectors) and new format (mapping_list)
  if (is.list(mapping_list) && !is.data.frame(mapping_list)) {
    # New format: mapping_list is a named list
    expected_lookup <- character(0)
    for (old_cat in names(mapping_list)) {
      new_cats <- mapping_list[[old_cat]]
      pairs <- paste(old_cat, new_cats, sep = "_")
      expected_lookup <- c(expected_lookup, pairs)
    }
  } else {
    # Old format: assume mapping_list is old_map and there's a new_map parameter
    # This maintains backward compatibility
    old_map <- mapping_list
    new_map <- get("new_map", envir = parent.frame())
    expected_pairs <- data.frame(
      old_cat = old_map,
      new_cat = new_map,
      stringsAsFactors = FALSE
    )
    expected_lookup <- paste(expected_pairs$old_cat, expected_pairs$new_cat, sep = "_")
  }
  
  # Create actual pairs from the dataframe
  df$pair_key <- paste(df$category.x, df$category.y, sep = "_")
  
  # Classify as expected or unexpected
  df$is_expected <- df$pair_key %in% expected_lookup
  
  # Overall statistics
  total_rows <- nrow(df)
  expected_count <- sum(df$is_expected)
  unexpected_count <- sum(!df$is_expected)
  
  cat("=== OVERALL STATISTICS ===\n")
  cat("Total pairs:", total_rows, "\n")
  cat("Expected pairs:", expected_count, sprintf("(%.1f%%)", expected_count/total_rows*100), "\n")
  cat("Unexpected pairs:", unexpected_count, sprintf("(%.1f%%)", unexpected_count/total_rows*100), "\n\n")
  
  # Expected pairs breakdown
  cat("=== EXPECTED PAIRS BREAKDOWN ===\n")
  expected_df <- df[df$is_expected, ]
  if (nrow(expected_df) > 0) {
    expected_summary <- table(expected_df$pair_key)
    for (pair in names(expected_summary)) {
      cat(sprintf("%-20s: %6d (%.1f%%)\n", 
                  pair, expected_summary[pair], 
                  expected_summary[pair]/total_rows*100))
    }
  } else {
    cat("No expected pairs found\n")
  }
  
  cat("\n=== UNEXPECTED PAIRS BREAKDOWN ===\n")
  unexpected_df <- df[!df$is_expected, ]
  if (nrow(unexpected_df) > 0) {
    unexpected_summary <- table(unexpected_df$pair_key)
    # Sort by frequency (descending)
    unexpected_summary <- sort(unexpected_summary, decreasing = TRUE)
    
    for (pair in names(unexpected_summary)) {
      cat(sprintf("%-20s: %6d (%.1f%%)\n", 
                  pair, unexpected_summary[pair], 
                  unexpected_summary[pair]/total_rows*100))
    }
  } else {
    cat("No unexpected pairs found\n")
  }
  
  # Return summary data for further analysis
  result <- list(
    total_pairs = total_rows,
    expected_count = expected_count,
    unexpected_count = unexpected_count,
    expected_breakdown = if(nrow(expected_df) > 0) table(expected_df$pair_key) else NULL,
    unexpected_breakdown = if(nrow(unexpected_df) > 0) table(unexpected_df$pair_key) else NULL,
    df_with_classification = df
  )
  
  return(invisible(result))
}
```




### Direct splicing
Quantifying splicing from actual reads instead of inference
```{r}
# SALVE
samples <- list(
    D13 = c("D13_D1_nef", "D13_LTR_tat"),
    Invitro = c("Invitro_D1_nef", "Invitro_LTR_tat")
)
input_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/splice/mac239/"

# GEX
samples <- list(Invitro = c("invitro"))
input_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/bamsort/splice/"
samples <- list(D13= c("JK85_D13"))
input_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/bamsort/splice/"

samples <- list(InvitrocDNA= c("cDNA"))
input_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS007/longRead/bamsort/splice/"


for (sample_name in names(samples)) {
  cat("\nProcessing sample:", sample_name, "\n")
  
  # Step 1: Combine data from all files in this sample
  combined_data <- data.frame()
  
  for (file in samples[[sample_name]]) {
    cat("  Reading:", file, "\n")
    data <- read.csv(paste0(input_dir, file, "_splicesites.csv"))
    
    file_data <- data %>%
      count(Donor, Acceptor) %>%
      filter(n > 1) %>%
      mutate(file = file)
    
    combined_data <- rbind(combined_data, file_data)
  }
  
  # Step 2: Sum counts across files for same donor-acceptor pairs
  plotdata <- combined_data %>%
    group_by(Donor, Acceptor) %>%
    summarise(
      raw_count = sum(n),
      files = paste(unique(file), collapse = ", "),
      .groups = 'drop'
    ) %>%
    arrange(Donor) %>%
    mutate(
      y_position = row_number(),
      log_count = log1p(raw_count)
    )
  
  cat("  Combined junctions:", nrow(plotdata), "\n")
  cat("  Total reads:", sum(plotdata$raw_count), "\n")
  
  # Step 3: Create log-normalized plot
  p_log <- ggplot(plotdata) +
    geom_segment(aes(x = Donor, xend = Acceptor, 
                     y = y_position, yend = y_position,
                     color = log_count, size = log_count), 
                 alpha = 0.7) +
    scale_color_viridis_c(name = "log(Count+1)",
                          trans = "identity") +
    scale_size_continuous(name = "log(Count+1)", 
                         range = c(0.5, 3)) +
    xlim(0, 10279) +
    labs(title = paste0("Splice Junctions: ", sample_name, " (Log Scale)"),
         subtitle = paste0("Combined from: ", paste(samples[[sample_name]], collapse = ", ")),
         x = "Genomic Position", 
         y = "Splice Junction") +
    theme_minimal() +
    theme(axis.text.y = element_blank(),
          axis.ticks.y = element_blank(),
          legend.position = "right")
  
  print(p_log)
  ggsave(paste0(input_dir, "plots/", sample_name, "_combined_log.svg"), 
         plot = p_log, width = 15, height = 8)
  
  # Step 4: Create linear (raw count) plot
  p_linear <- ggplot(plotdata) +
    geom_segment(aes(x = Donor, xend = Acceptor, 
                     y = y_position, yend = y_position,
                     color = raw_count, size = raw_count), 
                 alpha = 0.7) +
    scale_color_viridis_c(name = "Count",
                          trans = "identity") +
    scale_size_continuous(name = "Count", 
                         range = c(0.5, 3)) +
    xlim(0, 10279) +
    labs(title = paste0("Splice Junctions: ", sample_name, " (Linear Scale)"),
         subtitle = paste0("Combined from: ", paste(samples[[sample_name]], collapse = ", ")),
         x = "Genomic Position", 
         y = "Splice Junction") +
    theme_minimal() +
    theme(axis.text.y = element_blank(),
          axis.ticks.y = element_blank(),
          legend.position = "right")
  
  ggsave(paste0(input_dir, "plots/", sample_name, "_combined_linear.svg"), 
         plot = p_linear, width = 15, height = 8)
  
  # Step 5: Create summary table for this sample
  summary_table <- plotdata %>%
    slice_max(raw_count, n = 10) %>%
    select(Donor, Acceptor, raw_count, log_count, files) %>%
    mutate(junction = paste0(Donor, "-", Acceptor))
  
  cat("  Top 10 junctions:\n")
  print(summary_table)
  
  # Save summary table
  write.csv(summary_table, 
            paste0(input_dir, "plots/", sample_name, "_top_junctions.csv"),
            row.names = FALSE)
}


```

Single cell splicing
```{r}
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/splice/mac239/"
samples <- c("D13", "Invitro")
targets <- c("D1_nef", "LTR_tat")

acceptors <- data.frame(
  Acceptor = c(4658, 5141, 5746, 5818, 5959, 8249),
  AcceptorSite = c("A1", "A2", "A3", "A4", "A5", "A7")
)
donors <- data.frame(
  Donor = c(431, 4730, 5217, 6043),
  DonorSite = c("D1", "D2", "D3", "D4")
)

comparison <- data.frame()

classify_site <- function(value, reference_values, reference_sites) {
  distances <- abs(value - reference_values)
  min_dist <- min(distances)
  closest_site <- reference_sites[which.min(distances)]
  
  if (min_dist <= 3) {
    return(as.character(closest_site))
  } else if (min_dist <= 12) {
    return("mnc")
  } else {
    return("nc")
  }
}

for (sample in samples) {
  dataset <- data.frame()
  for (target in targets) {
    file_name <- paste0(input.dir, sample, "_", target, "_splicesites.csv")
    file <- read.csv(file_name)
    dataset <- rbind(dataset, file)
  }
  dataset <- dataset %>%
    rowwise() %>%
    mutate(
      DonorSite = classify_site(Donor, donors$Donor, donors$DonorSite),
      AcceptorSite = classify_site(Acceptor, acceptors$Acceptor, acceptors$AcceptorSite)) %>%
    ungroup() %>% 
    select(-CIGAR, -Read.sequence, -Sequence.after.the.N, -Before_N_M_coords, -After_N_M_coords) %>% 
    distinct(CB, DonorSite, AcceptorSite, UB, .keep_all = TRUE)
  topsplicers <- dataset %>% count(CB) %>% rename(events = n) %>% arrange(desc(events))
  test <- dataset %>%
    filter(DonorSite == "nc" | AcceptorSite == "nc") %>%
    count(CB) %>% rename(nc = n)
  topsplicers <- left_join(topsplicers, test, by = "CB") %>%
    replace(is.na(.), 0) %>%
    mutate(sample = sample)
  
  comparison <- rbind(comparison, topsplicers)
  
  ggplot(topsplicers, aes(x = log1p(events), y = log1p(nc))) +
    geom_point(size = 2) +
    theme_minimal() +
    theme(legend.position = "none") +
    labs(title = paste0(sample, " Splicing Events"), 
         x = "Splicing events (log)", y = "Non-canonical splicing events (log)") + 
    xlim(0,6)
  
  #test <- topsplicers %>% filter(events == nc) %>% arrange(desc(events))
}


```

Searching for defective proviruses
```{r}
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/splice/defective/"
samples <- c("D13", "Invitro", "D195")
targets <- c("D1_nef", "LTR_tat")
salve.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/reads/v5/minimum/"

acceptors <- data.frame(
  Acceptor = c(4658, 5141, 5746, 5818, 5959, 8249),
  AcceptorSite = c("A1", "A2", "A3", "A4", "A5", "A7")
)
donors <- data.frame(
  Donor = c(431, 4730, 5217, 6043),
  DonorSite = c("D1", "D2", "D3", "D4")
)

classify_site <- function(value, reference_values, reference_sites) {
  distances <- abs(value - reference_values)
  min_dist <- min(distances)
  closest_site <- reference_sites[which.min(distances)]
  
  if (min_dist <= 3) {
    return(as.character(closest_site))
  } else if (min_dist <= 12) {
    return("mnc")
  } else {
    return("nc")
  }
}

for (sample in samples) {
  SALVE_data <- read.csv(paste0(salve.dir, sample, "_SALVE_filtered.csv"))
  dataset <- data.frame()
  for (target in targets) {
    file_name <- paste0(input.dir, sample, "_", target, "_splicesites.csv")
    file <- read.csv(file_name)
    dataset <- rbind(dataset, file)
  }
  dataset <- dataset %>%
    select(CB, Donor, Acceptor) %>%
    rowwise() %>%
    mutate(
      DonorSite = classify_site(Donor, donors$Donor, donors$DonorSite),
      AcceptorSite = classify_site(Acceptor, acceptors$Acceptor, acceptors$AcceptorSite)) %>%
    ungroup() %>% 
    filter(DonorSite == "nc" | AcceptorSite == "nc") %>%
    group_by(CB, Donor, Acceptor, DonorSite, AcceptorSite) %>%
    mutate(count = n()) %>%
    ungroup() %>%
    distinct(CB, Donor, Acceptor, DonorSite, AcceptorSite, .keep_all = TRUE) %>%
    filter(CB %in% SALVE_data$cellID)
  
  write.csv(dataset, paste0(input.dir, sample, "_noncanonical_either.csv"))
  dataset <- dataset %>%
    filter(DonorSite == "nc" & AcceptorSite == "nc")
  write.csv(dataset, paste0(input.dir, sample, "_noncanonical_both.csv"))

}
```


## Saturation analysis

### cellID sampling without reads
This is to look at cellID sampling to ask: why don't we see those 10X only cells also in SALVE?
```{r cellID sampling}
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/split/"
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/saturation/sample_cellID/"

# Process each sample
for (sample in samples$samples) {
  cat("Processing sample:", sample, "\n")
  
  # Read the data files for this sample
  reads_D1_nef <- read.csv(paste0(input.dir, sample, "_D1_nef_bamsort_split_inside.csv"))
  reads_LTR_tat <- read.csv(paste0(input.dir, sample, "_LTR_tat_bamsort_split_inside.csv"))
  
  # Combine all reads and calculate total
  reads_total <- bind_rows(reads_D1_nef, reads_LTR_tat) %>%
    group_by(cellID, UMI) %>%
    summarize(reads = sum(reads), .groups = "drop")
  
  # Create molecule datasets (remove reads column)
  molecules_D1_nef <- reads_D1_nef %>% select(-reads)
  molecules_LTR_tat <- reads_LTR_tat %>% select(-reads)
  molecules_total <- reads_total %>% select(-reads)
  
  # Create samples list
  sample_datasets <- list(
    D1_nef = molecules_D1_nef,
    LTR_tat = molecules_LTR_tat,
    total = molecules_total
  )
  plot_cumulative_distribution(reads_total$reads, sample)
  
  # Process each dataset type
  # for (dataset_name in names(sample_datasets)) {
  #   dataset <- sample_datasets[[dataset_name]]
  #   
  #   results <- sample_cellID(dataset)
  #   summary <- analyze_cellID_sampling(results, title = paste0("cellID Saturation: ", sample, "_", dataset_name))
  #   
  #   # Create output filenames with sample prefix
  #   results_file <- paste0(output.dir, sample, "_", dataset_name, "_sample_cellID_results.csv")
  #   summary_file <- paste0(output.dir, sample, "_", dataset_name, "_sample_cellID_summary.csv")
  #   
  #   write.csv(results, results_file, row.names = FALSE)
  #   write.csv(summary, summary_file, row.names = FALSE)
  # 
  # }
}





plot_cumulative_distribution <- function(data_vector, sample_name) {
    df_plot <- data.frame(values = data_vector)
    
    # Plot 2: Cumulative distribution
    df_sorted <- data.frame(
      rank = 1:length(data_vector),
      value = sort(data_vector),
      cumulative_pct = (1:length(data_vector)) / length(data_vector) * 100
    )
    
    # Calculate percentage above 3
    pct_above_3 <- sum(data_vector >= 3) / length(data_vector) * 100
    
    p <- ggplot(df_sorted, aes(x = value, y = cumulative_pct)) +
      geom_line(color = "red", linewidth = 1) +
      geom_vline(xintercept = 3, color = "blue", linetype = "dashed", linewidth = 1) +
      annotate("text", x = 3, y = 50, 
               label = paste0(round(pct_above_3, 1), "% ≥ 3 reads"), 
               color = "blue", hjust = -0.1, vjust = 0.5, size = 10) +
      labs(title = paste0("Reads/UMI Distribution:", sample_name),
           x = "Reads/UMI", y = "Cumulative Percentage") +
      theme_minimal() +
      theme(
        plot.title = element_text(size = 18),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 14),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 16)
      ) +
      scale_x_log10(
        breaks = c(1, 10, 100, 1000, 10000),
        labels = c("1", "10", "100", "1,000", "10,000")
      )
    
    print(p)
  
  return(p)
}


plot_cumulative_distribution <- function(data_vector, sample_name) {
    df_plot <- data.frame(values = data_vector)
    
    # Plot 2: Cumulative distribution
    df_sorted <- data.frame(
      rank = 1:length(data_vector),
      value = sort(data_vector),
      cumulative_pct = (1:length(data_vector)) / length(data_vector) * 100
    )
    
    # Calculate percentage and count above 3
    count_above_3 <- sum(data_vector >= 3)
    pct_above_3 <- count_above_3 / length(data_vector) * 100
    
    p <- ggplot(df_sorted, aes(x = value, y = cumulative_pct)) +
      geom_line(color = "red", linewidth = 1) +
      geom_vline(xintercept = 3, color = "blue", linetype = "dashed", linewidth = 1) +
      annotate("text", x = 3, y = 50, 
               label = paste0(round(pct_above_3, 1), "% ≥ 3 reads\n(", format(count_above_3, big.mark = ","), " UMIs)"), 
               color = "blue", hjust = -0.1, vjust = 0.5, size = 8) +
      labs(title = paste0("Reads/UMI Distribution:", sample_name),
           x = "Reads/UMI", y = "Cumulative Percentage") +
      theme_minimal() +
      theme(
        plot.title = element_text(size = 18),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 14),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 16)
      ) +
      scale_x_log10(
        breaks = c(1, 10, 100, 1000, 10000),
        labels = c("1", "10", "100", "1,000", "10,000")
      )
  
    print (p)
  return(p)
}

# Example usage:
# freq_results <- plot_cumulative_distribution(reads_total$reads, "Uninfected")
```

```{r model fitting}
model_results <- fit_models(results, target_coverage = 95)
model_results <- fit_models(results, target_coverage = 99)
model_results <- fit_models(results, target_coverage = 100)
model_results <- fit_models(results, target_coverage = 120)
```

### UMI sampling with reads
Now looking at UMI sampling to get full picture of read saturation
```{r}
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/split/"
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/saturation/sample_UMI/"

# Process each sample
for (sample in samples$samples) {
  cat("Processing sample:", sample, "\n")
  
  # Read the data files for this sample
  reads_D1_nef <- read.csv(paste0(input.dir, sample, "_D1_nef_bamsort_split_inside.csv"))
  reads_LTR_tat <- read.csv(paste0(input.dir, sample, "_LTR_tat_bamsort_split_inside.csv"))
  
  # Combine all reads and calculate total
  reads_total <- bind_rows(reads_D1_nef, reads_LTR_tat) %>%
    group_by(cellID, UMI) %>%
    summarize(reads = sum(reads), .groups = "drop")
  
  # Create samples list
  sample_datasets <- list(
    D1_nef = reads_D1_nef,
    LTR_tat = reads_LTR_tat,
    total = reads_total
  )
  
  # Process each dataset type for this sample
  for (dataset_name in names(sample_datasets)) {
    dataset <- sample_datasets[[dataset_name]]
    
    results <- sample_UMI_weighted(dataset)
    summary <- analyze_UMI_sampling(results, title = paste0("Weighted UMI Saturation: ", sample))
  
    results_file <- paste0(output.dir, sample, "_sample_UMI_results.csv")
    summary_file <- paste0(output.dir, sample, "_sample_UMI_summary.csv")
    write.csv(results, results_file, row.names = FALSE)
    write.csv(summary, summary_file, row.names = FALSE)

  }
}
```

```{r}
model_results <- fit_models(results, target_coverage = 95, coverage_column = "pair_coverage")
model_results <- fit_models(results, target_coverage = 98.9, coverage_column = "pair_coverage")
model_results <- fit_models(results, target_coverage = 100, coverage_column = "pair_coverage")
model_results <- fit_models(results, target_coverage = 120)
```

### bamsort split: mac239 vs Mmul_10 reads
```{r loading}
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/SALVE/bamsort/split/"
reads_summary <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS013/SALVE/bamsort/split/all_samples_summary.txt", header = TRUE)

sample_names <- reads_summary$Sample
df_numeric <- reads_summary[, -which(names(reads_summary) == "Sample")]
df_transposed <- as.data.frame(t(df_numeric))
colnames(df_transposed) <- sample_names
rownames(df_transposed) <- c("Inside_Rows", "Inside_Total_Reads", "Outside_Rows", "Outside_Total_Reads")
df_transposed <- rbind(df_transposed, Inside_Fraction = round(df_transposed["Inside_Total_Reads",] / df_transposed["Outside_Total_Reads",], 2), Avg_Inside_Reads = round(df_transposed["Inside_Total_Reads",] / df_transposed["Inside_Rows",], 2))

```

# Joint Dataset

## Joining
Loading both datasets and making left_join dataframe
```{r}
samples <- c(
  "D13",
  "D195",
  "D83",
  "GART",
  "Invitro",
  "LART",
  "Lacute",
  "PART",
  "Uninfected"
)


SALVE.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/reads/v5/minimum/"
GEX.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/bamsort/reads/newcoords/minimum/"

joint_data <- list()

for (i in 1:length(samples)) {
  sample_name <- samples[i]
  
  # Read all data files
  salve_file <- paste0(SALVE.dir, sample_name, "_SALVE_filtered.csv")
  gex_file <- paste0(GEX.dir, sample_name, "_GEX_filtered.csv")
  umap_file <- paste0("/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/Seurat/UMAPcoords/", 
                      sample_name, "UMAP_coords.csv")
  
  salve_data <- if(file.exists(salve_file)) read.csv(salve_file) else NULL
  gex_data <- if(file.exists(gex_file)) read.csv(gex_file) else NULL
  umap_data <- if(file.exists(umap_file)) read.csv(umap_file, row.names = "X") else NULL
  
  # Skip if no data at all
  if (is.null(umap_data)) {
    cat("Skipping", sample_name, ": no GEX data\n")
    next
  }
  
  # Get cellIDs from GEX
  all_cells <- as.character(umap_data$cellID)
  all_cells <- unique(all_cells)
  
  # Skip if no valid cells
  if (length(all_cells) == 0) {
    cat("Skipping", sample_name, ": no valid cell IDs in UMAP data\n")
    next
  }
  
  # Create base dataframe
  result <- data.frame(cellID = all_cells)
  
  # Add UMAP data
  if (!is.null(umap_data)) {
    umap_processed <- umap_data %>%
      select(-V2, -sample)
    result <- left_join(result, umap_processed, by = "cellID")
  }
  
  # Add GEX data
  if (!is.null(gex_data)) {
    gex_processed <- gex_data %>%
      mutate(GEX = log1p(rowSums(across(c(US, spliced, any))))) %>%
      mutate(cellID = as.character(cellID)) %>%
      select(cellID, GEX)
    result <- left_join(result, gex_processed, by = "cellID")
  } else {
    result$GEX <- 0
  }
  
  # Add SALVE data
  if (!is.null(salve_data)) {
    salve_processed <- salve_data %>%
      #group_by(cellID) %>%
      rename(SALVE = total) %>%
      mutate(spliced = rowSums(across(c(spliced, S, SS, MS)))) %>%
      mutate(across(c(SALVE, US, spliced), log1p)) %>%
      mutate(cellID = as.character(cellID)) %>%
      select(cellID, SALVE, US, spliced)
    result <- left_join(result, salve_processed, by = "cellID")
  } else {
    result$SALVE <- 0
  }
  
  # Replace NAs with 0
  result[is.na(result)] <- 0
  
  # Skipping CD4 filtering
  # CD8/CD4 double positive already removed
  
  joint_data[[sample_name]] <- result
  cat("Processed", sample_name, "\n")
}
```

To get metrics for the left_join dataframes:
```{r}
#output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/joint/"
#dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

cat("\nSample\tTotal_cells\tboth\t10X_only\tSALVE_only\n")

# Process each dataset in the joint_data list
for (sample_name in names(joint_data)) {
  # Get the current dataframe
  current_df <- joint_data[[sample_name]] #%>%
    #mutate(SALVE = (D1_US + D1_S + tat_S + tat_US + nef )) %>%
    #mutate(GEX = (LTR_D1  + D1_A1  + A1_D4 + D4_A7 + A7_LTR))
  
  # Create the subsets based on mac239 and total columns
  both <- current_df %>% filter(GEX != 0 & SALVE != 0)
  onlySingleCell <- current_df %>% 
    filter(GEX != 0) %>%
    filter(!(cellID %in% both$cellID))
  onlySALVE <- current_df %>% 
    filter(SALVE != 0) %>%
    filter(!(cellID %in% both$cellID))

  
  # Print data row for each sample
  cat(sample_name, "\t", 
      nrow(current_df), "\t", 
      nrow(both), "\t", 
      nrow(onlySingleCell), "\t", 
      nrow(onlySALVE), "\n")
  
  # Save CSVs
  #write.csv(both, paste0(output_dir, "left_", sample_name, "_both.csv"), row.names = FALSE)
  #write.csv(onlySingleCell, paste0(output_dir, "left_", sample_name, "_onlySingleCell.csv"), row.names = FALSE)
  #write.csv(onlySALVE, paste0(output_dir, "left_", sample_name, "_onlySALVE.csv"), row.names = FALSE)
  #write.csv(current_df, paste0(output_dir, "left_", sample_name, "_all.csv"), row.names = FALSE)
}

```

Plotting
```{r}
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/joint/"
plotUMAP(Pacute_paint_umap, mac239, "Pacute: mac239", output.dir, "Pacute_umap_singleCell.svg")
plotUMAP(Pacute_paint_umap, total_lessLTR, "Pacute: SALVE (total_lessLTR)", output.dir, "Pacute_umap_SALVE.svg")

plotUMAP(Pacute_paint_umap, mac239, "Pacute: mac239", output.dir, "Pacute_umap_singleCell.svg", color_max = max(Pacute_paint_umap$total_lessLTR))
plotUMAP(Pacute_paint_umap, total_lessLTR, "Pacute: SALVE (total_lessLTR)", output.dir, "Pacute_umap_SALVE_totallessLTR.svg")
plotUMAP(Pacute_paint_umap, tat_S, "Pacute: SALVE (tat S)", output.dir, "Pacute_umap_SALVE_tatS.svg")
plotUMAP(Pacute_paint_umap, tat_US, "Pacute: SALVE (tat US)", output.dir, "Pacute_umap_SALVE_tatUS.svg")
plotUMAP(Pacute_paint_umap, D1_S, "Pacute: SALVE (D1 S)", output.dir, "Pacute_umap_SALVE_D1S.svg")
plotUMAP(Pacute_paint_umap, D1_US, "Pacute: SALVE (D1 US)", output.dir, "Pacute_umap_SALVE_D1US.svg")
plotUMAP(Pacute_paint_umap, absolute, "Pacute: SALVE (absolute)", output.dir, "Pacute_umap_SALVE_absolute.svg")

cat(
  "Number of US (unspliced) cells: \t",
  sum(Pacute_paint_umap$D1_US > 0),
  "\nNumber of S (spliced) cells: \t\t",
  sum(Pacute_paint_umap$D1_S > 0 | Pacute_paint_umap$tat_S > 0),
  "\nNumber of cells with both: \t\t",
  sum(Pacute_paint_umap$D1_US > 0 & (Pacute_paint_umap$D1_S > 0 | Pacute_paint_umap$tat_S > 0))
)
```

## Joint Metrics
### Counts histograms
What is the distribution of counts for SALVE?
```{r}
SALVE_data <- SALVE_data %>%
  #mutate(log1pSALVE = log1p(total_lessLTR)) %>%
  filter(!(sample == "Pacute"))
#max_value <- max(SALVE_data$log1pSALVE, na.rm = TRUE) 
max_value <- max(150) #for counts expression, update the indicated fields
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/histograms/"

library(patchwork)
plot_list <- list()

for (i in 1:nrow(samples)) {
  if (samples$samples[i] != "Pacute") {
    sample_name <- samples$samples[i]
    expression <- SALVE_data %>%
      filter(sample == sample_name)
    p <- ggplot(expression, aes(x=total_lessLTR)) + #update
      geom_histogram(binwidth=1) + 
      theme_minimal() +
      scale_x_continuous(limits = c(0, max_value)) + 
      labs(title = paste0(sample_name, " SALVE counts"),
           x = "total_lessLTR") #update
    plot_list[[i]] <- p
    #print(p)
    #output_file <- file.path(output.dir, paste0(sample_name, "_log_expression.svg")) #update
    #ggsave(filename = output_file, plot = p, device = "svg", width = 8, height = 6)
  }
}

plot_list <- plot_list[!sapply(plot_list, is.null)]

if (length(plot_list) <= 9) {
  # If 9 or fewer plots, create a clean 3x3 grid
  combined_plot <- (plot_list[[1]] | plot_list[[2]] | plot_list[[3]]) /
                   (plot_list[[4]] | plot_list[[5]] | plot_list[[6]]) /
                   (plot_list[[7]] | plot_list[[8]] | plot_list[[9]])
  
  # Handle cases with fewer than 9 plots
  combined_plot <- wrap_plots(plot_list, ncol = 3)
  
  # Add a shared title if desired
  combined_plot <- combined_plot + 
    plot_annotation(title = "SALVE Expression Across Samples",
                   theme = theme(plot.title = element_text(hjust = 0.5, size = 16)))
  
  # Print the combined plot
  print(combined_plot)
}
```

For absolute:
```{r}
SALVE_data <- SALVE_data %>%
  mutate(log1pSALVE = log1p(total_lessLTR))
max_value <- max(SALVE_data$log1pSALVE, na.rm = TRUE) 
#max_value <- max(SALVE_data$total_lessLTR, na.rm = TRUE) #for counts expression, update the indicated fields
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/histograms/"

for (i in 1:nrow(samples)) {
  sample_name <- samples$samples[i]
  expression <- SALVE_data %>%
    filter(sample == sample_name)
  p <- ggplot(expression, aes(x=log1pSALVE)) + #update
    geom_histogram() + 
    theme_minimal() +
    scale_x_continuous(limits = c(0, max_value)) + 
    labs(title = paste0(sample_name, " SALVE expression"),
         x = "log1p(total_lessLTR)") #update
  print(p)
  output_file <- file.path(output.dir, paste0(sample_name, "_log_absolute.svg")) #update
  #ggsave(filename = output_file, plot = p, device = "svg", width = 8, height = 6)
}
```

### Barcode rank plot (skip)
```{r}
for (i in 1:nrow(samples)) {
  sample_name <- samples$samples[i]
  cat("\nProcessing barcodeRankPlot for sample:", sample_name, "\n")
  
  # Filter SALVE_data to get only rows for the current sample
  sample_data <- SALVE_data %>% 
    filter(sample == sample_name)
  
  # Skip if no data for this sample
  if (nrow(sample_data) == 0) {
    cat("No data found for sample", sample_name, "in SALVE_data. Skipping.\n")
    next
  }
  
  # Construct the path to the raw data folder
  rawDataFolder <- paste0(samples$folders[i], "Mmul_10_mac239_", samples$datasets[i], "/outs/raw_feature_bc_matrix/")
  
  # Check if the raw data folder exists
  if (!dir.exists(rawDataFolder)) {
    cat("Raw data folder not found:", rawDataFolder, "\nSkipping.\n")
    next
  }
  
  # Set output directory and filename
  output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/joint/"
  saveas <- paste0("barcodeRankPlot_", sample_name, ".svg")
  
  # Make sure output directory exists
  if (!dir.exists(output_dir)) {
    dir.create(output_dir, recursive = TRUE)
    cat("Created output directory:", output_dir, "\n")
  }
  
  # Run the barcodeRankPlot function with the sample-specific data
  tryCatch({
    barcodeRankPlot(
      rawDataFolder = rawDataFolder,
      jointFullJoin = sample_data,
      plotTitle = paste0("Barcode Rank Plot: ", sample_name),
      output_dir = output_dir,
      saveas = saveas
    )
    
    cat("Successfully generated plot for", sample_name, "\n")
  }, error = function(e) {
    cat("Error generating barcodeRankPlot for", sample_name, ":", conditionMessage(e), "\n")
  })
}
```


### Correlation analysis (not updated)
Will do it custom for now and update correlation plot function later
```{r}
cat(
  "Correlation between 10X mac239 and SALVE total_lessLTR:\n",
    "  Pearson: ", round(cor(Pacute_paint_umap$mac239, Pacute_paint_umap$total_lessLTR, method="pearson"), 3),
    "\n  Spearman: ", round(cor(Pacute_paint_umap$mac239, Pacute_paint_umap$total_lessLTR, method="spearman"), 3),
    
    "\n\nCorrelation between 10X mac239 and SALVE absolute:\n",
    "  Pearson: ", round(cor(Pacute_paint_umap$mac239, Pacute_paint_umap$absolute, method="pearson"), 3),
    "\n  Spearman: ", round(cor(Pacute_paint_umap$mac239, Pacute_paint_umap$absolute, method="spearman"), 3)
)

# plotting
plot <- ggplot(data = Pacute_paint_umap, aes(x = total_lessLTR, y = mac239)) +
      geom_point() +
      labs(
        x = "SALVE total counts: D1 + tat + nef (filter > 2)",
        y = "SingleCell mac239 counts",
        title = "Pacute joint: total count") +
      theme_minimal() + 
    coord_fixed(ratio = 1)
plot <- ggplot(data = Pacute_paint_umap, aes(x = absolute, y = mac239)) +
      geom_point() +
      labs(
        x = "SALVE absolute (5' LTR) counts (filter > 0)",
        y = "SingleCell mac239 counts",
        title = "Pacute joint: absolute count") +
      theme_minimal() +
    coord_fixed(ratio = 1)
plot + theme(aspect.ratio = 1)
```


## Subset analysis (not updated)

### Loading

```{r}
SingleCell_Pacute_clusters <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10/Pacute_Mmul10_clusters.csv", row.names = "X")
SingleCell_Pacute_mac239 <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/Pacute_Mmulmac_mac239.csv", row.names = "X")
Pacute_SALVE <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS013/SALVE/bamsort/Pacute_SALVE_filtered.csv", row.names = "X")

SingleCell_Pacute_mac239 <- SingleCell_Pacute_mac239 %>% select(cellID, mac239)
SingleCell_Pacute <- left_join(SingleCell_Pacute_clusters, SingleCell_Pacute_mac239, by = "cellID")

Pacute_paint_umap = left_join(SingleCell_Pacute, Pacute_SALVE, by = "cellID")
Pacute_paint_umap[is.na(Pacute_paint_umap)] <- 0
```


```{r plotting}
# Function to create Seurat-style DimPlot
plot_clusters <- function(data, 
                         label_clusters = TRUE,
                         pt_size = 0.5,
                         label_size = 4) {
  
  # Convert the cluster column to a factor
  data$cluster <- as.factor(data$cluster)
  
  n_clusters <- length(unique(data$cluster))
  cluster_colors <- scales::hue_pal()(n_clusters)
  
  p1 <- ggplot(data, aes(x = UMAP1, y = UMAP2, color = cluster)) +
    geom_point(size = pt_size) +
    scale_color_manual(values = cluster_colors) +
    theme_bw() +
    theme(
      panel.grid = element_blank(),
      axis.title = element_text(size = 12),
      legend.title = element_blank(),
      panel.border = element_rect(colour = "black", fill = NA)
    )
  
  if (label_clusters) {
    cluster_centers <- data %>%
      group_by(cluster) %>%
      summarise(
        UMAP1 = median(UMAP1),
        UMAP2 = median(UMAP2)
      )
    
    p1 <- p1 + geom_text(data = cluster_centers,
                         aes(label = cluster),
                         size = label_size,
                         color = "black")
  }
  
  return(p1)
}

# Function to create Seurat-style FeaturePlot
plot_gene_expression <- function(data,
                               countcolumn,
                               pt_size = 0.5,
                               min_cutoff = NA,
                               max_cutoff = NA) {
  
  plot_data <- data
  if (!is.na(min_cutoff)) {
    plot_data[[countcolumn]][plot_data[[countcolumn]] < min_cutoff] <- min_cutoff
  }
  if (!is.na(max_cutoff)) {
    plot_data[[countcolumn]][plot_data[[countcolumn]] > max_cutoff] <- max_cutoff
  }
  
  p2 <- ggplot(plot_data, aes(x = UMAP1, y = UMAP2)) +
    geom_point(data = subset(plot_data, plot_data[[countcolumn]] <= 0),
               color = "gray93",
               size = pt_size) +
    geom_point(data = subset(plot_data, plot_data[[countcolumn]] > 0),
               aes_string(color = countcolumn),  # Use aes_string instead
               size = pt_size) +
    scale_color_gradient(low = "gray93", high = "darkblue",
                        name = "Expression") +
    theme_bw() +
    theme(
      panel.grid = element_blank(),
      axis.title = element_text(size = 12),
      panel.border = element_rect(colour = "black", fill = NA)
    )
  
  return(p2)
}

cluster_plot <- plot_clusters(Pacute_paint_umap)
xprn_plot_SALVE <- plot_gene_expression(Pacute_paint_umap, "total_lessLTR")
xprn_plot_SingleCell <- plot_gene_expression(Pacute_paint_umap, "mac239")
intersect_umap <- Pacute_paint_umap %>%
  mutate(total_lessLTR = ifelse(mac239 == 0, 0, total_lessLTR))
xprn_plot_intersect <- plot_gene_expression(intersect_umap, "total_lessLTR") #SALVE xprn in cells that are 10X+

output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/joint/subset/"
ggsave(cluster_plot, file = paste0(output_dir, "Pacute_umap_cluster.svg"))
ggsave(xprn_plot_SALVE, file = paste0(output_dir, "Pacute_umap_SALVE.svg"))
ggsave(xprn_plot_SingleCell, file = paste0(output_dir, "Pacute_umap_SingleCell.svg"))
ggsave(xprn_plot_intersect, file = paste0(output_dir, "Pacute_umap_intersect.svg"))

cat("SingleCell vRNA+: ", sum(invitro_paint_umap$log2SingleCell != 0, na.rm = TRUE),
    "\nSALVE vRNA+: ", sum(invitro_paint_umap$Count != 0, na.rm = TRUE),
    "\nCells in common: ", sum(intersect_umap$Count != 0, na.rm = TRUE))

write.csv(invitro_paint_umap, paste0(output_dir, "invitro_paint_umap.csv"))


```

Quick correlation plot:
```{r correlation plotting}
innerjoin <- inner_join(SingleCell_Pacute_mac239, Pacute_SALVE, by = "cellID")
Pacute_innerjoin <- left_join(SingleCell_Pacute_clusters, innerjoin, by = "cellID")
Pacute_innerjoin[is.na(Pacute_innerjoin)] <- 0

cat("Correlation of invitro between 10X and SALVE (total_lessLTR):", cor(Pacute_innerjoin$mac239, Pacute_innerjoin$total_lessLTR))
corrplot <- ggplot(data = Pacute_innerjoin, aes(x=total_lessLTR, y=mac239)) +
  geom_point() + 
  xlim(0,10) + 
  ylim(0,10) +
  theme_minimal() + 
  theme(aspect.ratio = 1) + 
  labs(title = "inner_join correlation")
corrplot
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/joint/subset/"
ggsave(corrplot, file = paste0(output.dir, "innerjoin_correlationplot.svg"))
```

### DEG analysis

```{r}
#D13
D13_Seurat <- SeuratPipeline("/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10/cellranger_count_D13/outs/filtered_feature_bc_matrix/", "D13", plots = FALSE)

D13 <- joint_data[["D13"]]
list_of_cells <- D13 %>% filter(SALVE != 0) #for SALVE
list_of_cells <- D13 %>% filter(GEX != 0) #for 10X
list_of_cells <- list_of_cells$cellID


results <- analyze_cell_subset(D13_Seurat, list_of_cells)
```

### Saving results
```{r}
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/joint/subset/singleCell/"
save_subset_analysis(results, output_dir = output.dir)
plot_subset_analysis(Pacute, results, list_of_cells, output_dir = paste0(output.dir, "plots/"))
```

### Interpreting results
```{r}
# Create filtered results list
filteredDEG <- lapply(results$cluster_specific, function(df) {
  if (!is.null(df) && nrow(df) > 0) {
    # Filter for significant adjusted p-value and log2FC threshold
    df[df$p_val_adj < 0.05 & abs(df$avg_log2FC) > 0.5, ]
  } else {
    NULL
  }
})

# Remove any empty results
filteredDEG <- filteredDEG[sapply(filteredDEG, function(x) !is.null(x) && nrow(x) > 0)]

# Print summary of how many genes passed filters in each cluster
for (cluster in names(filteredDEG)) {
  cat(sprintf("Cluster %s: %d genes\n", cluster, nrow(filteredDEG[[cluster]])))
}

# Saving
wb <- createWorkbook()
# Add each cluster's results as a separate worksheet
for (cluster_name in names(filteredDEG)) {
    de_results <- filteredDEG[[cluster_name]]
    if (!is.null(de_results) && nrow(de_results) > 0) {
        # Add cluster results as a worksheet
        addWorksheet(wb, cluster_name)
        # Add data with gene names as a column
        de_results$gene <- rownames(de_results)
        writeData(wb, cluster_name, de_results)
    }
}

# Save the workbook
saveWorkbook(wb, paste0(output.dir, "cluster_specific_DE_filtered.xlsx"), overwrite = TRUE)



filteredConserv <- results$conserved_markers %>%
    filter(p_val_adj < 0.05 & abs(avg_log2FC) > 0.5)

# Print summary of how many genes passed filters in each cluster
cat(sprintf("Conserved markers: %d genes\n", nrow(filteredConserv)))

# For each gene in conserved_markers, let's check which clusters show it as significant
check_gene_presence <- function(gene, cluster_results, p_val_thresh = 0.05, log2fc_thresh = 0.5) {
  # Initialize list to store results
  presence <- list()
  
  # Check each cluster
  for(cluster in names(cluster_results)) {
    de_results <- cluster_results[[cluster]]
    if(!is.null(de_results) && gene %in% rownames(de_results)) {
      # Get gene stats for this cluster
      gene_stats <- de_results[gene,]
      # Check if it meets significance criteria
      if(gene_stats$p_val_adj < p_val_thresh && abs(gene_stats$avg_log2FC) > log2fc_thresh) {
        presence[[cluster]] <- c(
          p_val_adj = gene_stats$p_val_adj,
          avg_log2FC = gene_stats$avg_log2FC
        )
      }
    }
  }
  
  # Return number of clusters and which clusters
  return(list(
    n_clusters = length(presence),
    clusters = names(presence),
    details = presence
  ))
}

# First get cluster counts for each gene
cluster_counts <- lapply(rownames(filteredConserv), function(gene) {
  result <- check_gene_presence(gene, results$cluster_specific)
  data.frame(
    gene = gene,
    num_clusters = result$n_clusters,
    clusters = paste(result$clusters, collapse=",")
  )
}) %>% bind_rows()

# Add cluster information to filtered results
filteredConserv <- filteredConserv %>%
  mutate(gene = rownames(.)) %>%
  left_join(cluster_counts, by = "gene") %>%
  arrange(desc(num_clusters), desc(abs(avg_log2FC)))

# Save to Excel
wb <- createWorkbook()
addWorksheet(wb, "filtered_conserved")
writeData(wb, "filtered_conserved", filteredConserv)
saveWorkbook(wb, paste0(output.dir, "conserved_markers_filtered.xlsx"), overwrite = TRUE)
```







