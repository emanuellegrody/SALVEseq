---
title: "EGS002VISER"
=======
title: "EGS002scRNAseq"
author: "Emanuelle Grody"
date: "2024-01-30"
output: html_document
---

This file has been split from EGS002.Rmd


```{r, echo = FALSE}
source("~/SALVEseq/packages.R")
source("~/SALVEseq/functions.R")
```

# Intro Analysis
## Previous analysis
```{r, eval = FALSE}
#update the file in this chunk and two chunks down
input.dir = "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/"
output.dir = "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/forBLAST/"
readsdirectory <- paste0(input.dir, "W2/") #let's start with just one for now; we will try separately for each sample

# Get list of CSV files in the directory
file_name <- list.files(readsdirectory, pattern = "*_shavedReads.txt", full.names = TRUE)

# let's read in these reads for now
temp_data <- read.csv(file_name, header = TRUE) %>% select(target) %>% unique()

```
### Pairwise LV Dist Histogram
The first step is to see what the pairwise LV histogram looks like to see if we have more similar or dissimilar sequences.
```{r}
set.seed(2059)
subsample1 = sample(temp_data$target,10000) #can lower to 5k to reduce run time
subsample2 = sample(temp_data$target,10000)
subsample3 = sample(temp_data$target,10000)
BarcodesLv1 = as.integer(stringdistmatrix(subsample1, method = "lv"))
BarcodesLv2 = as.integer(stringdistmatrix(subsample2, method = "lv"))
BarcodesLv3 = as.integer(stringdistmatrix(subsample3, method = "lv"))
lBarcodesLv = length(BarcodesLv1)

BarcodesLv = tibble(
  lvdist = c(BarcodesLv1, BarcodesLv2, BarcodesLv3),
  subsamNum = c(rep("subsamping1", lBarcodesLv), rep("subsamping2", lBarcodesLv), rep("subsamping3", lBarcodesLv)))

BarcodesLvHist <- BarcodesLv %>% group_by(subsamNum, lvdist) %>% summarise(length(lvdist)) %>%
  group_by(subsamNum) %>% mutate(totalNum = sum(`length(lvdist)`), fracLvDist = `length(lvdist)`/totalNum)

BarcodesLvHistPlot <- ggplot(BarcodesLvHist, aes(lvdist, fracLvDist)) +
  geom_bar(width = 0.5, stat = 'identity') +
  facet_wrap(facets = vars(subsamNum)) +
  theme_classic()
BarcodesLvHistPlot
#ggsave(plot = BarcodesLvHistPlot, file = paste0(readsdirectory, 'invitro_LVhist.svg'))
```

### BLAST
This is to extract non-redundant and relevant (commented-out) sequences from a subsample to submit for BLAST.
```{r}
# Custom function to compute Levenshtein distance and save the strings being compared
custom_lv_distance <- function(x, y) {
  lv_distance <- stringdistmatrix(x, y, method = "lv")
  row_names <- rep(x, each = length(y))
  col_names <- rep(y, length(x))
  df <- data.frame(dist = as.vector(lv_distance), string1 = row_names, string2 = col_names)
  return(df)
}

pairwise1 <- custom_lv_distance(subsample1, subsample1)
pairwise2 <- custom_lv_distance(subsample2, subsample2)
pairwise3 <- custom_lv_distance(subsample3, subsample3)

# taking the most similar sequences
#subLVdist1 <- pairwise1 %>% filter(dist <= 8 & dist > 0) %>% select(string1) %>% unique()
#subLVdist2 <- pairwise2 %>% filter(dist <= 8 & dist > 0) %>% select(string1) %>% unique()
#subLVdist3 <- pairwise3 %>% filter(dist <= 8 & dist > 0) %>% select(string1) %>% unique()

# triangularizing my matrix

library(reshape2)

pairwise1_long <- melt(pairwise1, varnames = c("string1", "string2"), value.name = "dist")
pairwise1_long <- pairwise1_long[pairwise1_long$string1 != pairwise1_long$string2, ]
pairwise1_triangular <- dcast(pairwise1_long, string1 ~ string2, value.var = "dist")
pairwise1_triangular[upper.tri(pairwise1_triangular, diag = FALSE)] <- NA

pairwise2_long <- melt(pairwise2, varnames = c("string1", "string2"), value.name = "dist")
pairwise2_long <- pairwise2_long[pairwise2_long$string1 != pairwise2_long$string2, ]
pairwise2_triangular <- dcast(pairwise2_long, string1 ~ string2, value.var = "dist")
pairwise2_triangular[upper.tri(pairwise2_triangular, diag = FALSE)] <- NA

pairwise3_long <- melt(pairwise3, varnames = c("string1", "string2"), value.name = "dist")
pairwise3_long <- pairwise3_long[pairwise3_long$string1 != pairwise3_long$string2, ]
pairwise3_triangular <- dcast(pairwise3_long, string1 ~ string2, value.var = "dist")
pairwise3_triangular[upper.tri(pairwise3_triangular, diag = FALSE)] <- NA

# Converting it back
pairwise1_clean <- melt(pairwise1_triangular, varnames = c("string2", "string1"), value.name = "dist")
pairwise2_clean <- melt(pairwise2_triangular, varnames = c("string2", "string1"), value.name = "dist")
pairwise3_clean <- melt(pairwise3_triangular, varnames = c("string2", "string1"), value.name = "dist")

colnames(pairwise1_clean) <- c("string1", "string2", "dist")
colnames(pairwise2_clean) <- c("string1", "string2", "dist")
colnames(pairwise3_clean) <- c("string1", "string2", "dist")

# taking the most similar sequences again
subLVdist1_clean <- pairwise1_clean %>% filter(dist <= 6 & dist > 0) %>% select(string1) %>% unique()
subLVdist2_clean <- pairwise2_clean %>% filter(dist <= 6 & dist > 0) %>% select(string1) %>% unique()
subLVdist3_clean <- pairwise3_clean %>% filter(dist <= 6 & dist > 0) %>% select(string1) %>% unique()
allinone <- rbind(subLVdist1_clean, subLVdist2_clean, subLVdist3_clean)

file_conn <- file(paste0(output.dir, "W2forBLAST.fsa"), "w")
sequences <- unlist(allinone)
#envprimer = "CCAGCAGACCCATATCCAACAGG"

# Loop through each sequence and write it to the file with a custom header
for (i in seq_along(sequences)) {
  header <- sprintf(">sequence_%05d", i)  # Generate the header line
  cat(header, "\n", paste0(sequences[i]), "\n", file = file_conn)  # Write header and sequence to file; paste0 to add envprimer before the sequence
}

# Close the file connection
close(file_conn)
```

### starcode
```{r}
#update the file in this chunk and two chunks down
input.dir = "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/"
output.dir = "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/forBLAST/"
readsdirectory <- paste0(input.dir, "W2/") #let's start with just one for now; we will try separately for each sample

# Get list of CSV files in the directory
file_name <- list.files(readsdirectory, pattern = "*_shavedReads.txt", full.names = TRUE)

# output for starcode
#manually looped through each of the file output combinations
VISER_out <- read.csv(file_name, header = TRUE) %>% select(target)
VISER_out$target <- substr(VISER_out$target, 1, 18)
VISER_out <- VISER_out %>% unique()
write.table(VISER_out$target, paste0(readsdirectory, "W2_shavedReadsList_18.txt"), sep = ",", quote = FALSE, row.names = FALSE, col.names = FALSE)
```
I saved three different lengths of target sequences: 18bp, 24bp, and 30bp ("full length"), because starcode has a maximum LV dist of 8. I ran starcode in Quest using the starcodeRun.py script over these files. From that analysis, I got a list of the most popular consensus sequences for each sample for each target length. I used those consensus sequences to identify a cutoff for target reads instead of using the reference.

### UTR Read1
```{r, eval = FALSE}
#update the file in this chunk and two chunks down
input.dir = "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/dualRead/"
output.dir = "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/forBLAST/"
readsdirectory <- paste0(input.dir, "W2/") #let's start with just one for now; we will try separately for each sample

# Get list of CSV files in the directory
file_name <- list.files(readsdirectory, pattern = "*_shavedUtrReads.txt", full.names = TRUE)

# let's read in these reads for now
temp_data <- read.csv(file_name, header = TRUE) %>% select(target) %>% unique()

```
### Pairwise LV Dist Histogram
The first step is to see what the pairwise LV histogram looks like to see if we have more similar or dissimilar sequences.
```{r}
set.seed(2059)
subsample1 = sample(temp_data$target,10000) #can lower to 5k to reduce run time
subsample2 = sample(temp_data$target,10000)
subsample3 = sample(temp_data$target,10000)
BarcodesLv1 = as.integer(stringdistmatrix(subsample1, method = "lv"))
BarcodesLv2 = as.integer(stringdistmatrix(subsample2, method = "lv"))
BarcodesLv3 = as.integer(stringdistmatrix(subsample3, method = "lv"))
lBarcodesLv = length(BarcodesLv1)

BarcodesLv = tibble(
  lvdist = c(BarcodesLv1, BarcodesLv2, BarcodesLv3),
  subsamNum = c(rep("subsamping1", lBarcodesLv), rep("subsamping2", lBarcodesLv), rep("subsamping3", lBarcodesLv)))

BarcodesLvHist <- BarcodesLv %>% group_by(subsamNum, lvdist) %>% summarise(length(lvdist)) %>%
  group_by(subsamNum) %>% mutate(totalNum = sum(`length(lvdist)`), fracLvDist = `length(lvdist)`/totalNum)

BarcodesLvHistPlot <- ggplot(BarcodesLvHist, aes(lvdist, fracLvDist)) +
  geom_bar(width = 0.5, stat = 'identity') +
  facet_wrap(facets = vars(subsamNum)) +
  theme_classic()
BarcodesLvHistPlot
#ggsave(plot = BarcodesLvHistPlot, file = paste0(readsdirectory, 'invitro_LVhist.svg'))
```


### starcode
```{r}
#update the file in this chunk and two chunks down
input.dir = "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/"
output.dir = "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/forBLAST/"
readsdirectory <- paste0(input.dir, "W2/") #let's start with just one for now; we will try separately for each sample

# Get list of CSV files in the directory
file_name <- list.files(readsdirectory, pattern = "*_shavedReads.txt", full.names = TRUE)

# output for starcode
#manually looped through each of the file output combinations
VISER_out <- read.csv(file_name, header = TRUE) %>% select(target)
VISER_out$target <- substr(VISER_out$target, 1, 18)
VISER_out <- VISER_out %>% unique()
write.table(VISER_out$target, paste0(readsdirectory, "W2_shavedReadsList_18.txt"), sep = ",", quote = FALSE, row.names = FALSE, col.names = FALSE)
```

### Target cutoff
```{r, eval = FALSE}
#update the file in this chunk and two chunks down
input.dir = "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/"
readsdirectory <- paste0(input.dir, "W2/") #let's start with just one for now

# Get list of CSV files in the directory
file_name <- list.files(readsdirectory, pattern = "*_shavedReads.txt", full.names = TRUE)

# let's read in these reads for now
VISER_w2_env <- read.csv(file_name, header = TRUE) #%>% select(target) %>% unique()

```

These are the reference sequences:
```{r}
envprimer = "CCAGCAGACCCATATCCAACAGG"
referenceTarget = "ACCCGGCACTGCCAACCAGAGAAGGCAAAG"
```

Cutoff by LV:
```{r, eval = FALSE}
referenceTarget = "ACCCGGCACTGCCAACCAGAGAAGGCAAAG" 
VISER_w2_env$dist <- NA
for (i in 1:nrow(VISER_w2_env)) {
  # Calculate the Levenshtein distance between the current string and the constant
  dist <- adist(VISER_w2_env$target[i], referencearget)
  # Assign the distance to the 'dist' column
  VISER_w2_env$dist[i] <- dist
}

hist(VISER_w2_env$dist, breaks = 50, xlab = "Levenshtein Distance: recovered to expected")
```
This histogram has two peaks: one centered at 9 and one centered at 18.

What are these more dissimilar sequences? Are they divergent or are they similar to each other?
```{r}
dissimilar_env <- VISER_w2_env %>% filter(dist > 15)
similar_env <- VISER_w2_env %>% filter(dist < 16)
VISER_w2_env_30 <- VISER_w2_env
VISER_w2_env_30$target <- substr(VISER_w2_env_30$target, 1, 18)

set.seed(2059)
subsample1 = sample(VISER_w2_env_30$target,5000)
subsample2 = sample(VISER_w2_env_30$target,5000)
subsample3 = sample(VISER_w2_env_30$target,5000)
BarcodesLv1 = as.integer(stringdistmatrix(subsample1, method = "lv"))
BarcodesLv2 = as.integer(stringdistmatrix(subsample2, method = "lv"))
BarcodesLv3 = as.integer(stringdistmatrix(subsample3, method = "lv"))
lBarcodesLv = length(BarcodesLv1)

BarcodesLv = tibble(
  lvdist = c(BarcodesLv1, BarcodesLv2, BarcodesLv3),
  subsamNum = c(rep("subsamping1", lBarcodesLv), rep("subsamping2", lBarcodesLv), rep("subsamping3", lBarcodesLv)))

BarcodesLvHist <- BarcodesLv %>% group_by(subsamNum, lvdist) %>% summarise(length(lvdist)) %>%
  group_by(subsamNum) %>% mutate(totalNum = sum(`length(lvdist)`), fracLvDist = `length(lvdist)`/totalNum)

BarcodesLvHistPlot <- ggplot(BarcodesLvHist, aes(lvdist, fracLvDist)) +
  geom_bar(width = 0.5, stat = 'identity') +
  facet_wrap(facets = vars(subsamNum)) +
  theme_classic()
BarcodesLvHistPlot
```
Even when just looking at the more dissimilar sequences, we see that they have some sequences that are more similar and some that are divergent. So just setting a cutoff based on the reference genome sequence is not helping us distinguish between real target sequences and PCR/sequencing error.

I ran starcode on all the sequences. Read in all starcode consensus sequences:
```{r}
main_folder <- "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/starcode"
lengths = c("18", "24", "30")
samples = c("invitro", "W0", "W2")
subfolders <- file.path(main_folder, samples)

starcodeTarget <- matrix(NA, nrow = length(samples), ncol = length(lengths))
rownames(starcodeTarget) <- samples
colnames(starcodeTarget) <- lengths


# Loop through the subfolders and files
for (folder_path in subfolders) {
  for (bp in lengths) {
    # List all files in the subfolder with a specific file name structure
    file_list <- list.files(path = folder_path, pattern = paste0("*",bp,"_d8.txt"), full.names = TRUE)
    # Check if any files were found
    if (length(file_list) > 0) {
      # Read the first entry from each file and add it to the dataframe
      first_entry_data <- lapply(file_list, function(file) {
        first_entry <- read.table(file, header = FALSE, sep = "\t", stringsAsFactors = FALSE, nrows = 1) %>% select(V1)  # Change nrows if you need more than one row
        return(first_entry)
      })
  
      # Add the data to the combined dataframe with a unique name
      split <- unlist(strsplit(folder_path, "/"))
      sample <- split[length(split)]
      starcodeTarget[sample, bp] <- do.call(rbind, first_entry_data)[[1]]
      
    }
  }
}

# let's look at the distance of these things to the reference. Just looking at the full length sequences here
for (row in c(7,8,9)) {
  print(starcodeTarget[row])
  print(adist(starcodeTarget[row], referenceTarget))
}

```
Note that we can ignore W0 since we know it's not going to have any actual targets. But we'll leave it here for now.

Now, let's compare the LV dist of all the reads to these target sequences. This next chunk will take a good amount of time to run, about 10 minutes
```{r, eval = FALSE}
# reading in the data
main_folder <- "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis"
lengths = c("18", "24", "30")
samples = c("invitro", "W0", "W2")
subfolders <- file.path(main_folder, samples)

allVISER <- list()


# Loop through the subfolders and files
for (folder_path in subfolders) {
  # List all files in the subfolder with a specific file name structure
  file_list <- list.files(path = folder_path, pattern = paste0("*shavedReads.txt"), full.names = TRUE)
  # Check if any files were found
  if (length(file_list) > 0) {
    # Read the first entry from each file and add it to the dataframe
    entry_data <- lapply(file_list, function(file) {
      entry <- read.table(file, header = TRUE, sep = ",") %>% unique() #%>% select(target) %>% unique()
      return(entry)
    })

    # Add the data to the combined dataframe with a unique name
    split <- unlist(strsplit(folder_path, "/"))
    sample <- split[length(split)]
    allVISER[[sample]] <- entry_data
  }
}

# to index just one column, do this: allVISER$invitro[[1]]$cellID


# comparing to our starcode results
allVISER_dist <- list()
# Loop through each data frame in allVISER
for (sample in names(allVISER)) {
  VISER_w2_env <- allVISER[[sample]][[1]]
  VISER_w2_env$dist <- NA
  consensusTarget <- starcodeTarget[sample, "30"]
  for (i in 1:nrow(VISER_w2_env)) {
    dist <- adist(VISER_w2_env$target[i], consensusTarget)
    VISER_w2_env$dist[i] <- dist
  }
  allVISER_dist[[sample]] <- VISER_w2_env

  # Plot the histogram for each data frame (optional)
  #hist(VISER_w2_env$dist, breaks = 50, xlab = "Levenshtein Distance: recovered to expected", main = sample)
}

for (sample in names(allVISER_dist)) {
  plotme <- allVISER_dist[[sample]]$dist
  hist(plotme, breaks = 50, xlab = "Levenshtein Distance: recovered to consensus", main = sample)
}
```

Based on the histograms, I will filter all sequences that have LV dist greater than 9 from the consensus sequence. I will also save the resulting dataframes to make loading easier.
```{r}
for (sample in names(allVISER_dist)) {
  allVISER_dist[[sample]] <- allVISER_dist[[sample]] %>% filter(dist < 10)
  write.csv(allVISER_dist[[sample]], paste0(main_folder, "/R/", sample, "_shavedReadsFiltered.csv"), row.names=FALSE)
}
```

### Linking to 10X
Read back in VISER sequences.
```{r}
output.dir <- "/projects/b1042/GoyalLab/egrody/20231017_EGS002/scViralQuant/"
SingleCell_invitro_umap <- read.csv(paste0(output.dir, "invitro_SingleCellumap_env.csv")) #%>% filter(SingleCellcount > 0)
SingleCell_w2_umap <- read.csv(paste0(output.dir, "w2_SingleCellumap_env.csv")) #%>% filter(SingleCellcount > 0)
SingleCell_invitro_umap <- SingleCell_invitro_umap %>% mutate(log1pSingleCell = log1p(SingleCellcount))
SingleCell_w2_umap <- SingleCell_w2_umap %>% mutate(log1pSingleCell = log1p(SingleCellcount))
```

Updated the variables to be the preclustered 10X UMAP coordinates
```{r}
VISER_invitro <- allVISER_dist[["invitro"]] %>% select(-dist, -target) %>% unique() %>% count(cellID)
VISER_w2 <- allVISER_dist[["W2"]] %>% select(-dist, -target) %>% unique() %>% count(cellID)

invitro_paint_umap = full_join(SingleCell_invitro_umap, VISER_invitro, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(log1pSALVE = log1p(VISERcount))
invitro_paint_umap[is.na(invitro_paint_umap)] <- 0
w2_paint_umap = full_join(SingleCell_w2_umap, VISER_w2, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(log1pSALVE = log1p(VISERcount))
w2_paint_umap[is.na(w2_paint_umap)] <- 0

# how many cells from each method?
totalvirus_10X <- sum(invitro_paint_umap$log1pSingleCell != 0, na.rm = TRUE)
totalvirus_10X <- sum(w2_paint_umap$log1pSingleCell != 0, na.rm = TRUE)
#totalvirus_VISER <- invitro_paint_umap %>% select(log2SingleCell) %>% filter(log2SingleCell > 0) %>% nrow()
totalvirus_VISER <- sum(invitro_paint_umap$log1pSALVE != 0, na.rm = TRUE)
totalvirus_VISER <- sum(w2_paint_umap$log1pSALVE != 0, na.rm = TRUE)
#totalvirus_VISER <- invitro_paint_umap %>% select(log1pSALVE) %>% filter(log1pSALVE > 0) %>% nrow()
# did it two different ways because I was surprised that this was the outcome; 10X seems low and VISER seems high
```

Not sure why I started using full join here instead of left join (which retains the UMAP'ed cells) or inner join (which keeps only cells in common). Let me see if it makes a difference.
```{r}
inner_invitro_paint_umap = left_join(SingleCell_invitro_umap, VISER_invitro, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(log1pSALVE = log1p(VISERcount))
inner_invitro_paint_umap[is.na(inner_invitro_paint_umap)] <- 0
inner_w2_paint_umap = left_join(SingleCell_w2_umap, VISER_w2, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(log1pSALVE = log1p(VISERcount))
inner_w2_paint_umap[is.na(inner_w2_paint_umap)] <- 0


inner_invitro_paint_umap = left_join(SingleCell_invitro_umap, VISER_invitro, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(log1pSALVE = log1p(VISERcount))
inner_invitro_paint_umap[is.na(inner_invitro_paint_umap)] <- 0
inner_w2_paint_umap = left_join(SingleCell_w2_umap, VISER_w2, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(log1pSALVE = log1p(VISERcount))
inner_w2_paint_umap[is.na(inner_w2_paint_umap)] <- 0

totalvirus_10X <- sum(inner_invitro_paint_umap$log1pSingleCell != 0, na.rm = TRUE)
totalvirus_10X <- sum(inner_w2_paint_umap$log1pSingleCell != 0, na.rm = TRUE)
#totalvirus_VISER <- invitro_paint_umap %>% select(log2SingleCell) %>% filter(log2SingleCell > 0) %>% nrow()
totalvirus_VISER <- sum(inner_invitro_paint_umap$log1pSALVE != 0, na.rm = TRUE)
totalvirus_VISER <- sum(inner_w2_paint_umap$log1pSALVE != 0, na.rm = TRUE)
#totalvirus_VISER <- invitro_paint_umap %>% select(log1pSALVE) %>% filter(log1pSALVE > 0) %>% nrow()

create_identity_umap(inner_invitro_paint_umap, 
                     title = "invitro env",
                     output_file_name = "UMAP_identities_invitro_env", 
                     output_dir = "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/joint/")
```


```{r}
output.dir <- "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/joint/"

paintUMAP(invitro_paint_umap, log1pSALVE, "mac239 from VISER, log counts", output.dir, "paintUMAP_invitro_mac239_VISER.svg")
paintUMAP(w2_paint_umap, log1pSALVE, "mac239 from VISER, log counts", output.dir, "paintUMAP_w2_mac239_VISER.svg")

paintUMAP(invitro_paint_umap, log2SingleCell, "mac239 from 10X, log counts", output.dir, "paintUMAP_invitro_mac239_10X.svg")
paintUMAP(w2_paint_umap, log2SingleCell, "mac239 from 10X, log counts", output.dir, "paintUMAP_w2_mac239_10X.svg")
```

Where are the shared ones? Where are the not shared ones?
```{r}
#invitro
invitro_paint_umap = left_join(SingleCell_KLRB1, VISER_KLRB1_clean, by = "cellID") %>% rename(SALVEcount = n, SingleCellcount = Count) %>% 
    mutate(log1pSALVE = log1p(SALVEcount))
left_paint_umap[is.na(left_paint_umap)] <- 0

create_identity_umap(invitro_paint_umap, 
                     tite = "invitro ev", "UMAP_identities_invitro.svg", output.dir)

create_identity_umap(w2_paint_umap, 
                     title = "w2 env",
                     output_file_name = "UMAP_identities_w2_env", 
                     output_dir = "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/joint/")
```

### Correlation plots
```{r}
corVISER_invitro <- allVISER_dist[["invitro"]] %>% select(cellID, UMI)
corVISER_w2 <- allVISER_dist[["W2"]] %>% select(cellID, UMI)

corVISER_invitro %>% select(-UMI) %>% unique() %>% nrow() #10k unique cellIDs
corVISER_invitro %>% select(-cellID) %>% unique() %>% nrow() #15k unique UMIs
corVISER_w2 %>% select(-UMI) %>% unique() %>% nrow() #7.5k unique cellIDs
corVISER_w2 %>% select(-cellID) %>% unique() %>% nrow() #10k unique UMIs

corUMIcount <- corVISER_invitro %>% group_by(cellID,UMI) %>% count(name = "count") %>% filter(count > 1) #10k UMIs that are > 1
corUMIcount_cellID <- corUMIcount$cellID %>% unique() #3k cellIDs with UMI=1 filtered

corUMIcount_cellID_noN <- corUMIcount_cellID[!(grepl("N", corUMIcount_cellID))] %>% unique() #only 9 cellIDs have N's
corV <- data.frame(cellID = corUMIcount_cellID_noN)

# N correction... why does this need to happen?? why isn't corV enough?
VISER_invitro_noN <- corVISER_invitro %>% filter(!grepl("N", UMI)) %>% filter(!grepl("N", cellID))
VISER_invitro_noN <- VISER_invitro_noN %>% unique() %>% group_by(cellID) %>% summarise(count = length(UMI))
VISER_w2_noN <- corVISER_w2 %>% filter(!grepl("N", UMI)) %>% filter(!grepl("N", cellID))
VISER_w2_noN <- VISER_w2_noN %>% unique() %>% group_by(cellID) %>% summarise(count = length(UMI))

#  now let's repeat the correlation analysis above
VISER_w2_filter <- inner_join(VISER_w2_noN, corV, by = "cellID")
results_invitro <- correlation_plots(VISER_invitro_filter, SingleCell_w2)
ggsave(corrplot, file = paste0(output.dir, "w2_correlationplot.svg"))


VISER_invitro_filter <- inner_join(VISER_invitro_noN, corV, by = "cellID")
results_invitro <- correlation_plots(VISER_invitro_filter, SingleCell_invitro)


ggsave(corrplot, file = paste0(output.dir, "invitro_correlationplot.svg"))
```


### Exploring the filtered cells

The objective was to figure out what was the origin of all the additional cellIDs we were seeing in VISER versus 10X. I didn't find any evidence for dead cells accounting for these cellIDs.

Reading raw counts matrices and no QC filters. Reading in scViserQuant output.
```{r scViralQuant thru Seurat}
w2 <- SeuratPipeline("/projects/b1042/GoyalLab/egrody/20231017_EGS002/counts/Mmul_10_only/run_count_W2/outs/raw_feature_bc_matrix_bbmap/", 
               "w2", output_dir = "/projects/b1042/GoyalLab/egrody/20231017_EGS002/analysis/Seurat/W2/",
               plots = FALSE, rds = FALSE)

w0 <- SeuratPipeline("/projects/b1042/GoyalLab/egrody/20231017_EGS002/counts/Mmul_10_only/run_count_W0/outs/raw_feature_bc_matrix_bbmap/", 
               "w2", output_dir = "/projects/b1042/GoyalLab/egrody/20231017_EGS002/analysis/Seurat/W0/",
               plots = FALSE, rds = FALSE)

invitro <- SeuratPipeline("/projects/b1042/GoyalLab/egrody/20231017_EGS002/counts/Mmul_10_only/run_count_invitro/outs/raw_feature_bc_matrix_bbmap/", 
               "w2", output_dir = "/projects/b1042/GoyalLab/egrody/20231017_EGS002/analysis/Seurat/invitro/",
               plots = FALSE, rds = FALSE)
```

Code to look at the scViralQuant counts: raw, not normalized. W0 did not have any viral reads.
```{r outputs}
# scViralQuant raw counts
SingleCell_invitro <- targetExpressionDF(invitro, "env", count_type = "raw")
SingleCell_w2 <- targetExpressionDF(w2, "env", count_type = "raw")

output.dir <- "/projects/b1042/GoyalLab/egrody/20231017_EGS002/noQC/"
write.csv(SingleCell_w2, paste0(output.dir, "w2_SingleCellumap_env.csv"))
write.csv(SingleCell_invitro, paste0(output.dir, "invitro_SingleCellumap_env.csv"))
```

How many UMIs in the cells that are env+ but got filtered by QC? Consider setting a minimum UMI threshold of 3.
```{r}
noQC_w2_nozero <- SingleCell_w2 %>% filter(Count > 0)
noQC_invitro_nozero <- SingleCell_invitro %>% filter(Count > 0)

lowquality_invitro <- anti_join(noQC_invitro_nozero, QC_invitro_nozero, by = "cellID") %>% mutate(cells = paste0(cellID, "-1"))
lowquality_w2 <- anti_join(noQC_w2_nozero, QC_w2_nozero, by = "cellID") %>% mutate(cells = paste0(cellID, "-1"))
env_i <- QC_invitro_nozero %>% mutate(cells = paste0(cellID, "-1"))
env_2 <- QC_w2_nozero %>% mutate(cells = paste0(cellID, "-1"))
lowQ_invitro <- subset(invitro, cells = lowquality_invitro$cells)
lowQ_w2 <- subset(w2, cells = lowquality_w2$cells)
env_invitro <- subset(invitro, cells = env_i$cells)
env_w2 <- subset(w2, cells = env_2$cells)

# total UMIs
hist(lowQ_invitro$nCount_RNA, breaks = 50)
hist(invitro$nCount_RNA, breaks = 50)
hist(lowQ_w2$nCount_RNA, breaks = 50)
hist(w2$nCount_RNA, breaks = 50)

#viral UMIs
mean(lowQ_invitro@assays$RNA@counts["env",])
mean(lowQ_w2@assays$RNA@counts["env",])
mean(env_invitro@assays$RNA@counts["env",])
mean(env_w2@assays$RNA@counts["env",])
hist(lowQ_invitro@assays$RNA@counts["env",], breaks = 50, main = "env expression in QC filtered out env+ cells", xlab = "env counts")
hist(env_invitro@assays$RNA@counts["env",], breaks = 50, main = "env expression in all env+ cells", xlab = "env counts")
```

How about the cells that are sVQ+ but VISER-?
```{r}
VQonly_invitro <- left_join(SingleCell_invitro_umap, VISER_invitro_full, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(logViserCount = log2(VISERcount))
VQonly_invitro[is.na(VQonly_invitro)] <- 0
VQonly_invitro <- VQonly_invitro %>% filter(logViserCount == 0) %>% filter(log1pSingleCell > 0)

VQonly_w2 <- left_join(SingleCell_w2_umap, VISER_W2_full, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(logViserCount = log2(VISERcount))
VQonly_w2[is.na(VQonly_w2)] <- 0
VQonly_w2 <- VQonly_w2 %>% filter(logViserCount == 0) %>% filter(log1pSingleCell > 0)
compare_invitro <- SingleCell_invitro_umap %>% filter(log1pSingleCell > 0)
compare_w2 <- SingleCell_w2_umap %>% filter(log1pSingleCell > 0)

cat(
  "Mean scViralQuant expression\nInvitro  VQonly: ", mean(VQonly_invitro$log1pSingleCell),
  "   All: ", mean(compare_invitro$log1pSingleCell),
  "\nW2       VQonly: ", mean(VQonly_w2$log1pSingleCell), "   All: ", mean(compare_w2$log1pSingleCell)
)
```


You can just run this chunk now to reload all the variables needed:
```{r}
output.dir <- "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/postSeqIO/"
VISER_invitro_full <- read.csv(paste0(output.dir, "invitro_fullVISER_uniqued.csv"))
VISER_W2_full <- read.csv(paste0(output.dir, "w2_fullVISER_uniqued.csv"))

output.dir <- "/projects/b1042/GoyalLab/egrody/20231017_EGS002/noQC/"
SingleCell_invitro_umap <- read.csv(paste0(output.dir, "invitro_SingleCellumap_env.csv"))
SingleCell_w2_umap <- read.csv(paste0(output.dir, "w2_SingleCellumap_env.csv"))

SingleCell_invitro_umap <- SingleCell_invitro_umap %>% mutate(log1pSingleCell = log1p(SingleCellcount))
SingleCell_w2_umap <- SingleCell_w2_umap %>% mutate(log1pSingleCell = log1p(SingleCellcount))

#joint UMAP
inner_invitro_paint_umap = left_join(SingleCell_invitro_umap, VISER_invitro_full, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(log1pSALVE = log1p(VISERcount))
inner_invitro_paint_umap[is.na(inner_invitro_paint_umap)] <- 0
inner_w2_paint_umap = left_join(SingleCell_w2_umap, VISER_W2_full, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(log1pSALVE = log1p(VISERcount))
inner_w2_paint_umap[is.na(inner_w2_paint_umap)] <- 0

cat(
  "Invitro  scViralQuant: ", sum(inner_invitro_paint_umap$log1pSingleCell != 0, na.rm = TRUE), "   VISER: ", 
  sum(inner_invitro_paint_umap$log1pSALVE != 0, na.rm = TRUE),
  "\nW2       scViralQuant: ", sum(inner_w2_paint_umap$log1pSingleCell != 0, na.rm = TRUE), "   VISER: ", 
  sum(inner_w2_paint_umap$log1pSALVE != 0, na.rm = TRUE)
)

```


How about the mitochondrial content? Is it higher than usual?
```{r}
Idents(lowQ_invitro) <- "orig.ident"
vplot <- VlnPlot(lowQ_invitro, features = c("nFeature_RNA", "nCount_RNA", "percent_mito"), ncol = 3)
Idents(lowQ_w2) <- "orig.ident"
vplot <- VlnPlot(lowQ_w2, features = c("nFeature_RNA", "nCount_RNA", "percent_mito"), ncol = 3)
vplot
```
So the low quality cells in W2 do have high mitochondrial reads (but not the invitro). Let's isolate them and look at their viral reads.

```{r}
lowQ_w2_highmito <- subset(lowQ_w2, subset = percent_mito > 5)
cat(
  "Of the", ncol(lowQ_w2), "cells that have low quality,", ncol(lowQ_w2_highmito), "of them have a mitochondrial percentage > 5"
)

lowQ_w2_highmito_env = GetAssayData(object = lowQ_w2_highmito, assay = "RNA", slot = "counts")["env",]
lowQ_w2_highmito_env
mean(lowQ_w2_highmito@assays$RNA@counts["env",])
mean(lowQ_w2@assays$RNA@counts["env",])

lowQ_w2_env = GetAssayData(object = lowQ_w2, assay = "RNA", slot = "counts")["env",]
lowQ_w2_env

mito_vs_env <- data.frame(cells = names(GetAssayData(object = lowQ_w2, assay = "RNA", slot = "counts")["env",]),
                env = unname(GetAssayData(object = lowQ_w2, assay = "RNA", slot = "counts")["env",]),
                mito = lowQ_w2@meta.data$percent_mito)
mito_vs_env_UMI <- mito_vs_env %>% filter(env > 2)
ggplot(mito_vs_env, aes(x = mito, y = env)) + 
  geom_point() + 
  theme_classic() + 
  labs(x = "% mitochondrial reads", y = "env expression", title = "W2 filtered out cells")
ggplot(mito_vs_env_UMI, aes(x = mito, y = env)) + 
  geom_point(size = 3) + 
  theme_classic() + 
  labs(x = "% mitochondrial reads", y = "env expression", title = "W2 filtered out cells, for env > 2")
```



### Filter gag only
Looking at the possible sources of gag reads, we realized that gag transcripts could be read with an erroneous cellID sequence. To avoid this from adding more scViralQuant+ cells to our data, I will filter these cells out (alternatively, I could have only added env to the reference genome instead of the whole SIV genome). The easiest way to do this is to only look at env reads.
```{r}
#How many cells have 5pUTR or gag or pol expression?
fivePrime <- SingleCell_allviralgenes_w2_filtered %>% filter("5pUTR" != 0 | gag != 0 | pol != 0) #564
#How many cells have env or nef expression?
threePrime <- SingleCell_allviralgenes_w2_filtered%>% filter(env != 0 | nef != 0) #277
#How many have only env or nef and not 5pUTR or gag or pol?
threePrimeOnly <- SingleCell_allviralgenes_w2_filtered%>% filter(env != 0 | nef != 0 & "5pUTR" == 0 & gag == 0 & pol == 0) #265
```

# Core Analysis
## Previous Analysis

### Loading

After running seqIO and postSeqIO Python scripts, load in the clean data here.

```{r}
input_dir <- "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/postSeqIO/"

VISER_invitro_whitelist <- read.csv(paste0(input_dir, "invitro/VISER_invitro_clean_target.csv")) %>%
  mutate(cellID = paste0(cellID, "-1"))
VISER_W2_whitelist <- read.csv(paste0(input_dir, "W2/VISER_W2_clean_target.csv")) %>%
  mutate(cellID = paste0(cellID, "-1")) 
VISER_W0_whitelist <- read.csv(paste0(input_dir, "W0/VISER_W0_clean_target.csv")) %>%
  mutate(cellID = paste0(cellID, "-1")) 

```

### Target filter
We load in UMI- and cellID-corrected reads and filter divergent env sequences. We start by loading in the most populous sequences from our starcode analysis. For reference, these sequences are as follows:
invitro: ACACTGCACTGCGAACCAGAGAAGGCAAA
W2: ACACTGCACTGCCACCCAGAGAGGGCAAAG
W0: CTGAAGATCGGAAGAGCGTCGTGTAGG
```{r}
# filter by distance to starcode results

main_folder <- "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/starcode"
subfolders <- file.path(main_folder, samples)

starcodeTarget <- matrix(nrow = length(samples), ncol = 1)
rownames(starcodeTarget) <- samples
colnames(starcodeTarget) <- "30"


# Loop through the subfolders and files
for (folder_path in subfolders) {
    # List all files in the subfolder with a specific file name structure
    file_list <- list.files(path = folder_path, pattern = paste0("*30_d8.txt"), full.names = TRUE)
    # Check if any files were found
    if (length(file_list) > 0) {
      # Read the first entry from each file and add it to the dataframe
      first_entry_data <- lapply(file_list, function(file) {
        first_entry <- read.table(file, header = FALSE, sep = "\t", stringsAsFactors = FALSE, nrows = 1) %>% select(V1)  # Change nrows if you need more than one row
        return(first_entry)
      })
  
      # Add the data to the combined dataframe with a unique name
      split <- unlist(strsplit(folder_path, "/"))
      sample <- split[length(split)]
      starcodeTarget[sample] <- do.call(rbind, first_entry_data)[[1]]
  }
}
starcodeTarget <- na.omit(starcodeTarget)

# Add LV dist column

VISER_invitro_whitelist$dist <- adist(VISER_invitro_whitelist$target, starcodeTarget["invitro"])
VISER_W2_whitelist$dist <- adist(VISER_W2_whitelist$target, starcodeTarget["W2"])
VISER_W0_whitelist$dist <- adist(VISER_W0_whitelist$target, starcodeTarget["W0"])

# Plotting
plotme <- VISER_W2_whitelist$dist
hist(plotme, breaks = 50, xlab = "Levenshtein Distance: recovered to consensus", main = "W2")
plotme <- VISER_W0_whitelist$dist
hist(plotme, breaks = 50, xlab = "Levenshtein Distance: recovered to consensus", main = "W0")
plotme <- VISER_invitro_whitelist$dist
hist(plotme, breaks = 50, xlab = "Levenshtein Distance: recovered to consensus", main = "invitro")


# Trimming at 10
VISER_invitro_whitelist <- VISER_invitro_whitelist %>% filter(dist < 10) %>% select(cellID, UMI) %>% unique() %>% count(cellID)
VISER_W2_whitelist <- VISER_W2_whitelist %>% filter(dist < 10) %>% select(cellID, UMI) %>% unique() %>% count(cellID)
VISER_W0_whitelist <- VISER_W0_whitelist %>% filter(dist < 10) %>% select(cellID, UMI) %>% unique() %>% count(cellID)

output.dir <- "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/postSeqIO/"

write.csv(VISER_invitro_whitelist, paste0(output.dir, "invitro_VISER_whitelist_uniqued.csv"))
write.csv(VISER_W2_whitelist, paste0(output.dir, "w2_VISER_whitelist_uniqued.csv"))
write.csv(VISER_W0_whitelist, paste0(output.dir, "w0_VISER_whitelist_uniqued.csv"))
```


### Side analysis: subsampling
How much can we subsample our reads and still get the same signal?
```{r}
main_folder <- "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/seqIOdualRead/splits"
samples = "invitro"
subfolders <- file.path(main_folder, samples)

VISER_invitro_totalreads <- data.frame()

# Loop through the subfolders and files
for (folder_path in subfolders) {
  # List all files in the subfolder with a specific file name structure
  file_list <- list.files(path = folder_path, pattern = paste0("*shavedReads.txt"), full.names = TRUE)
  # Check if any files were found
  if (length(file_list) > 0) {
    # Read the first entry from each file and add it to the dataframe
    entry_data <- lapply(file_list, function(file) {
      entry <- read.table(file, header = TRUE, sep = ",")
      return(entry)
    })
    
    combined_data <- do.call(rbind, entry_data)

    # Add the data to the combined dataframe with a unique name
    split <- unlist(strsplit(folder_path, "/"))
    sample <- split[length(split)]
    if (sample == "invitro") {
      VISER_invitro_totalreads <- combined_data
    }
  }
}

VISER_invitro_totalreads_withtarget <- VISER_invitro_totalreads
VISER_invitro_totalreads <- VISER_invitro_totalreads %>% select(-target)
VISER_invitro_totalinfo <- VISER_invitro_totalreads %>% count(cellID) %>% filter(n > 1)

```

From Claude
```{r}
library(parallel)
library(doParallel)
library(foreach)

VISER_invitro_totalinfo_expanded <- VISER_invitro_totalreads %>%
  distinct(cellID) %>%
  left_join(VISER_invitro_totalinfo, by = "cellID") %>%
  mutate(n = coalesce(n, 0))

# Update the calculate_info_content function
calculate_info_content <- function(sampled_data, total_info) {
  sampled_info <- sampled_data %>% 
    group_by(cellID) %>% 
    summarise(n = n()) %>%
    ungroup()
  
  info_captured <- sum(pmin(sampled_info$n, total_info$n[match(sampled_info$cellID, total_info$cellID)]))
  return(info_captured / sum(total_info$n))
}

# Set up the analysis
total_sequences <- nrow(VISER_invitro_totalreads)
total_info <- sum(VISER_invitro_totalinfo_expanded$n)
percentages <- seq(1, 100, by = 1)  # Test from 1% to 100% in 1% increments

# Set up parallel processing
num_cores <- detectCores() - 1
registerDoParallel(cores=num_cores)

# Perform the analysis with parallel processing
results <- foreach(percent = percentages, .combine=rbind, .packages=c("dplyr")) %dopar% {
  sample_size <- round(total_sequences * (percent / 100))
  iterations <- max(10, round(100 - percent))  # Adaptive iterations
  replicate(iterations, {
    sampled_data <- VISER_invitro_totalreads %>% sample_n(sample_size, replace = FALSE)
    info_content <- calculate_info_content(sampled_data, VISER_invitro_totalinfo)
    data.frame(Percentage = percent, InfoContent = info_content)
  }, simplify = FALSE) %>% 
    bind_rows()
}

stopImplicitCluster()

# Calculate average information content for each percentage
avg_results <- results %>%
  group_by(Percentage) %>%
  summarize(AvgInfoContent = mean(InfoContent))

# Find the percentage where information content reaches 95% (or your desired threshold)
threshold <- 0.95
min_percentage <- avg_results %>%
  filter(AvgInfoContent >= threshold) %>%
  slice(1) %>%
  pull(Percentage)

# Print results
print(paste("Total sequences after filtering:", total_sequences))
print(paste("Total information content:", total_info))
print(paste("Minimum sampling percentage to maintain", threshold * 100, 
            "% of information:", min_percentage, "%"))

```

```{r}
# Plot the results
p <- ggplot(avg_results, aes(x = Percentage, y = AvgInfoContent)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = threshold, linetype = "dashed", color = "red") +
  geom_vline(xintercept = min_percentage, linetype = "dashed", color = "blue") +
  labs(title = "Information Content vs. Sampling Percentage",
       subtitle = paste("Threshold:", threshold, "Minimum Percentage:", min_percentage),
       x = "Sampling Percentage",
       y = "Proportion of Unique Sequences Captured") +
  theme_minimal()

print(p)

# Test the result
test_sample_size <- round(total_sequences * (min_percentage / 100))
test_results <- replicate(100, {
  sampled_data <- VISER_invitro_totalreads %>% sample_n(test_sample_size, replace = FALSE)
  unique_count <- sampled_data %>% distinct() %>% nrow()
  unique_count / total_unique
})

print(paste("Average proportion of unique sequences captured in test:", 
            round(mean(test_results), 4)))
print(paste("Standard deviation:", round(sd(test_results), 4)))
```

Strange. I guess it's because there are a lot of one-count UMIs
```{r}
sequence_counts <- VISER_invitro_totalreads %>%
  count(sequence_column_name) %>%
  arrange(desc(n))

print(head(sequence_counts, 20))
print(tail(sequence_counts, 20))

# Plot frequency distribution
ggplot(sequence_counts, aes(x = n)) +
  geom_histogram(binwidth = 1) +
  scale_x_log10() +
  labs(title = "Sequence Frequency Distribution",
       x = "Frequency (log scale)", y = "Count")
```


Predicting saturation point
```{r}
library(nls2)

# Apply loess smoothing
loess_fit <- loess(AvgInfoContent ~ Percentage, data = avg_results, span = 0.75)

# Predict values
new_percentages <- seq(min(avg_results$Percentage), max(avg_results$Percentage), length.out = 200)
predicted <- predict(loess_fit, newdata = data.frame(Percentage = new_percentages))

# Calculate slopes
slopes <- diff(predicted) / diff(new_percentages)

# Find saturation point (where slope < 0.001 or minimum slope if all slopes > 0.001)
saturation_point <- if(any(slopes < 0.001)) {
  new_percentages[which(slopes < 0.001)[1]]
} else {
  new_percentages[which.min(slopes)]
}

# Calculate 60% of max predicted value
max_predicted <- max(predicted)
saturation_60 <- 0.6 * max_predicted

# Find the percentage at which we reach 60% saturation
percent_60 <- new_percentages[which.min(abs(predicted - saturation_60))]

# Plot results
ggplot(avg_results, aes(x = Percentage, y = AvgInfoContent)) +
  geom_point() +
  geom_line(data = data.frame(Percentage = new_percentages, AvgInfoContent = predicted), color = "blue") +
  geom_vline(xintercept = saturation_point, linetype = "dashed", color = "red") +
  geom_vline(xintercept = percent_60, linetype = "dashed", color = "green") +
  labs(title = "Predicted Saturation Curve",
       x = "Percentage of Total Sequences",
       y = "Average Information Content",
       caption = paste("Red: Predicted Saturation Point:", round(saturation_point, 1), "%\n",
                       "Green: 60% of Max:", round(percent_60, 1), "%")) +
  theme_minimal()

# Print results
print(paste("Predicted Saturation Point:", round(saturation_point, 1), "%"))
print(paste("Percentage at 60% of Max:", round(percent_60, 1), "%"))
print(paste("Max predicted information content:", round(max_predicted, 3)))

# Calculate R-squared to assess goodness of fit
ss_total <- sum((avg_results$AvgInfoContent - mean(avg_results$AvgInfoContent))^2)
ss_residual <- sum((avg_results$AvgInfoContent - predict(loess_fit, newdata = avg_results))^2)
r_squared <- 1 - (ss_residual / ss_total)
print(paste("R-squared of the fit:", round(r_squared, 3)))

```



## Current analysis

### Reading in data
```{r}
output.dir <- "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/seqIOdualRead/splits/cleaned/"

VISER_invitro_whitelist <- read.csv(paste0(output.dir, "invitro_VISER_whitelist_uniqued.csv")) %>% select(-X)
VISER_W2_whitelist <- read.csv(paste0(output.dir, "w2_VISER_whitelist_uniqued.csv")) %>% select(-X)
VISER_W0_whitelist <- read.csv(paste0(output.dir, "w0_VISER_whitelist_uniqued.csv")) %>% select(-X)
```

Optional to filter out cellIDs with UMIs = 1, since these will become 0 when log transformed:
```{r}
VISER_invitro_whitelist <- VISER_invitro_whitelist %>% filter(n > 1)
VISER_W2_whitelist <- VISER_W2_whitelist %>% filter(n > 1)
VISER_W0_whitelist <- VISER_W0_whitelist %>% filter(n > 1)
```



### Linking to 10X
Read back in 10X data with env counts and UMAP coordinates. See EGS002scRNAseq.Rm for the analysis that generated these datasets.
```{r}
#output.dir <- "/projects/b1042/GoyalLab/egrody/20231017_EGS002/analysis/scViralQuant/outputs/"
output.dir <- "/projects/b1042/GoyalLab/egrody/20231017_EGS002/analysis/"
SingleCell_invitro_umap <- read.csv(paste0(output.dir, "invitro_SingleCellumap_env.csv")) #%>% filter(SingleCellcount > 0)
SingleCell_w2_umap <- read.csv(paste0(output.dir, "w2_SingleCellumap_env.csv")) #%>% filter(SingleCellcount > 0)
SingleCell_invitro_umap <- SingleCell_invitro_umap %>% mutate(log1pSingleCell = log1p(SingleCellcount))
SingleCell_w2_umap <- SingleCell_w2_umap %>% mutate(log1pSingleCell = log1p(SingleCellcount))

```

Updated the variables to be the preclustered 10X UMAP coordinates.
```{r}
invitro_paint_umap = full_join(SingleCell_invitro_umap, VISER_invitro_whitelist, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(log1pSALVE = log1p(VISERcount))
invitro_paint_umap[is.na(invitro_paint_umap)] <- 0
w2_paint_umap = full_join(SingleCell_w2_umap, VISER_W2_whitelist, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(log1pSALVE = log1p(VISERcount))
w2_paint_umap[is.na(w2_paint_umap)] <- 0

# how many env+ cells from each method?
totalvirus_10X <- sum(invitro_paint_umap$log1pSingleCell != 0, na.rm = TRUE)
totalvirus_10X <- sum(w2_paint_umap$log1pSingleCell != 0, na.rm = TRUE)
#totalvirus_VISER <- invitro_paint_umap %>% select(log2SingleCell) %>% filter(log2SingleCell > 0) %>% nrow()
totalvirus_VISER <- sum(invitro_paint_umap$log1pSALVE != 0, na.rm = TRUE)
totalvirus_VISER <- sum(w2_paint_umap$log1pSALVE != 0, na.rm = TRUE)
#totalvirus_VISER <- invitro_paint_umap %>% select(log1pSALVE) %>% filter(log1pSALVE > 0) %>% nrow()
# did it two different ways because I was surprised that this was the outcome; 10X seems low and VISER seems high
```

To see what are in common, now we use left_join to look at only the cells with 10X anchors:
```{r}
inner_invitro_paint_umap = left_join(SingleCell_invitro_umap, VISER_invitro_whitelist, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(log1pSALVE = log1p(VISERcount))
inner_invitro_paint_umap[is.na(inner_invitro_paint_umap)] <- 0
inner_w2_paint_umap = left_join(SingleCell_w2_umap, VISER_W2_whitelist, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(log1pSALVE = log1p(VISERcount))
inner_w2_paint_umap[is.na(inner_w2_paint_umap)] <- 0


totalvirus_10X <- sum(inner_invitro_paint_umap$log1pSingleCell != 0, na.rm = TRUE)
totalvirus_10X <- sum(inner_w2_paint_umap$log1pSingleCell != 0, na.rm = TRUE)
#totalvirus_VISER <- invitro_paint_umap %>% select(log2SingleCell) %>% filter(log2SingleCell > 0) %>% nrow()
totalvirus_VISER <- sum(inner_invitro_paint_umap$log1pSALVE != 0, na.rm = TRUE)
totalvirus_VISER <- sum(inner_w2_paint_umap$log1pSALVE != 0, na.rm = TRUE)
#totalvirus_VISER <- invitro_paint_umap %>% select(log1pSALVE) %>% filter(log1pSALVE > 0) %>% nrow()

```

I'm not seeing a marked increase in the number of joint cells, which shouldn't be a surprise given that these are extensively PCR'ed, well-mixed samples.
^Later: Not sure what this comment means

### Correlation plots
```{r}
corVISER_invitro <- VISER_invitro_whitelist
corVISER_w2 <- VISER_W2_whitelist

corVISER_invitro %>% select(-UMI) %>% unique() %>% nrow() #10k unique cellIDs
corVISER_invitro %>% select(-cellID) %>% unique() %>% nrow() #15k unique UMIs
corVISER_w2 %>% select(-UMI) %>% unique() %>% nrow() #7.5k unique cellIDs
corVISER_w2 %>% select(-cellID) %>% unique() %>% nrow() #10k unique UMIs

corUMIcount <- corVISER_invitro %>% group_by(cellID,UMI) %>% count(name = "count") %>% filter(count > 1) #10k UMIs that are > 1
corUMIcount_cellID <- corUMIcount$cellID %>% unique() #3k cellIDs with UMI=1 filtered

corUMIcount_cellID_noN <- corUMIcount_cellID[!(grepl("N", corUMIcount_cellID))] %>% unique() #only 9 cellIDs have N's
corV <- data.frame(cellID = corUMIcount_cellID_noN)

# N correction... why does this need to happen?? why isn't corV enough?
VISER_invitro_noN <- corVISER_invitro %>% filter(!grepl("N", UMI)) %>% filter(!grepl("N", cellID))
VISER_invitro_noN <- VISER_invitro_noN %>% unique() %>% group_by(cellID) %>% summarise(count = length(UMI))
VISER_w2_noN <- corVISER_w2 %>% filter(!grepl("N", UMI)) %>% filter(!grepl("N", cellID))
VISER_w2_noN <- VISER_w2_noN %>% unique() %>% group_by(cellID) %>% summarise(count = length(UMI))

#  now let's repeat the correlation analysis above
VISER_w2_filter <- inner_join(VISER_w2_noN, corV, by = "cellID")
jointTableFilter = inner_join(VISER_w2_filter, SingleCell_w2, by = "cellID") %>% rename(VISERcount = count, SingleCellcount = Count) %>% 
  mutate(log1pViserCount = log1p(VISERcount), log2Viser = log2(VISERcount), lnViserCount = log(VISERcount), normalizedViserCount = 1000*VISERcount/sum(VISERcount), logNormViser = log1p(normalizedViserCount), log1pSingleCell = log1p(SingleCellcount))

result_w2 <- correlation_plots(VISER_w2_filter, SingleCell_w2, join = "inner")
result_invitro <- correlation_plots(VISER_invitro_filter, SingleCell_w2, join = "inner")

output.dir <- "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/joint/"
ggsave(filename = paste0(output.dir, "correlation_w2_countsvscounts.svg"), results_w2$plots$SALVEcount, 
       width = 7, height = 6)
ggsave(filename = paste0(output.dir, "correlation_w2_countsvslog2SALVE.svg"), results_w2$plots$log2SalveCount, 
       width = 7, height = 6)
ggsave(filename = paste0(output.dir, "correlation_invitro_countsvscounts.svg"), results_invitro$plots$SALVEcount, 
       width = 7, height = 6)
ggsave(filename = paste0(output.dir, "correlation_invitro_countsvslog2SALVE.svg"), results_invitro$plots$log2SalveCount, 
       width = 7, height = 6)
```



### LV dist of cellIDs
I want to look at the cellsIDs that are...
1. VISER+ and scViralQuant-
2. scViralQuant+ and first VISER+ and then VISER-.
```{r}
#VISER+ and scViralQuant-
VISERonly_invitro <- VISER_invitro_whitelist %>% filter(!(cellID %in% inner_invitro_paint_umap$cellID))
VISERonly_W2 <- VISER_W2_whitelist %>% filter(!(cellID %in% inner_w2_paint_umap$cellID))
VISERonly_invitro_cellIDLv = as.integer(stringdistmatrix(VISERonly_invitro$cellID, method = "lv"))
VISERonly_W2_cellIDLv = as.integer(stringdistmatrix(VISERonly_W2$cellID, method = "lv"))

hist(VISERonly_invitro_cellIDLv, breaks = 50,
     main = "Histogram of pairwise LV dist between cellIDs: invitro",
    xlab = "cellIDs env+ in VISER only")
hist(VISERonly_W2_cellIDLv, breaks = 50,
     main = "Histogram of pairwise LV dist between cellIDs: W2",
    xlab = "cellIDs env+ in VISER only")


#VISER+ and scViralQuant+
VISER10X_invitro <- VISER_invitro_whitelist %>% filter(cellID %in% inner_invitro_paint_umap$cellID)
VISER10X_W2 <- VISER_W2_whitelist %>% filter(cellID %in% inner_w2_paint_umap$cellID)
VISER10X_invitro_cellIDLv = as.integer(stringdistmatrix(VISER10X_invitro$cellID, method = "lv"))
VISER10X_W2_cellIDLv = as.integer(stringdistmatrix(VISER10X_W2$cellID, method = "lv"))

hist(VISER10X_invitro_cellIDLv, breaks = 50,
     main = "Histogram of pairwise LV dist between cellIDs: invitro",
    xlab = "cellIDs env+ in VISER and 10X")
hist(VISER10X_W2_cellIDLv, breaks = 50,
     main = "Histogram of pairwise LV dist between cellIDs: W2",
    xlab = "cellIDs env+ in VISER and 10X")

#ggsave(plot = BarcodesLvHistPlot, file = paste0(readsdirectory, 'invitro_LVhist.svg'))

```


### UMI cutoff >2
Let's take a quick peek at a UMI cutoff of 3
```{r}
VISER_invitro_UMI3 <- VISER_invitro_whitelist %>% filter(n > 2)
VISER_W2_UMI3 <- VISER_W2_whitelist %>% filter(n > 2)
VISER_W0_UMI3 <- VISER_W0_whitelist %>% filter(n > 2)
```

To see what are in common, now we use left_join to look at only the cells with 10X anchors:
```{r}
UMI3_invitro_paint_umap = left_join(SingleCell_invitro_umap, VISER_invitro_UMI3, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(log1pSALVE = log1p(VISERcount))
UMI3_invitro_paint_umap[is.na(inner_invitro_paint_umap)] <- 0
UMI3_w2_paint_umap = left_join(SingleCell_w2_umap, VISER_W2_UMI3, by = "cellID") %>% rename(VISERcount = n) %>% 
                    mutate(log1pSALVE = log1p(VISERcount))
UMI3_w2_paint_umap[is.na(inner_w2_paint_umap)] <- 0


totalvirus_10X <- sum(UMI3_invitro_paint_umap$log1pSingleCell != 0, na.rm = TRUE)
totalvirus_10X <- sum(UMI3_w2_paint_umap$log1pSingleCell != 0, na.rm = TRUE)
#totalvirus_VISER <- invitro_paint_umap %>% select(log2SingleCell) %>% filter(log2SingleCell > 0) %>% nrow()
totalvirus_VISER <- sum(UMI3_invitro_paint_umap$log1pSALVE != 0, na.rm = TRUE)
totalvirus_VISER <- sum(UMI3_w2_paint_umap$log1pSALVE != 0, na.rm = TRUE)
#totalvirus_VISER <- invitro_paint_umap %>% select(log1pSALVE) %>% filter(log1pSALVE > 0) %>% nrow()

```

### Barcode rank plot

With all of the unanchored cellIDs, we want to know: where are the SALVEseq (VISER) cells with respect to the 10X total (unfiltered raw) cells?
```{r}
# Reading in raw feature matrices
raw_location = "/projects/b1042/GoyalLab/egrody/20231017_EGS002/analysis/counts/Mmul_10_only/run_count_invitro/outs/raw_feature_bc_matrix_bbmap/"

output.dir <- "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/seqIOdualRead/splits/cleaned/"
VISER_invitro_full <- read.csv(paste0(output.dir, "invitro_VISER_whitelist_uniqued.csv")) %>%
  select(cellID) #make log1pSALVE

barcodeRankPlot(raw_location, VISER_invitro_full, 
                plotTitle = "Barcode Rank Plot", 
                output_dir = "/projects/b1042/GoyalLab/egrody/20230929_EGS002/analysis/joint/", 
                saveas = "barcodeRankPlot.svg")
```

### 10X-only env+ cells
Is the reason why we see so many env+ cells in 10X and not in SALVE due to alignment?
Run bamsort before this analysis.

```{r}
input_dir <- "/projects/b1042/GoyalLab/egrody/20231017_EGS002/analysis/bamsort/"
upstream <- read.csv(paste0(input_dir, "invitro_bamsort_env_upstream.csv")) %>% 
  filter(Read_Count > 1) %>%
  rename(cellID = Cell_ID) %>%
  mutate(cellID = str_sub(cellID, end=-3))
downstream <- read.csv(paste0(input_dir, "invitro_bamsort_env_downstream.csv")) %>% 
  filter(Read_Count > 1) %>%
  rename(cellID = Cell_ID) %>%
  mutate(cellID = str_sub(cellID, end=-3))
downstream_any <- read.csv(paste0(input_dir, "invitro_bam_dedup_subset_env.csv")) %>% 
  filter(Read_Count > 1) %>%
  rename(cellID = Cell_ID) %>%
  mutate(cellID = str_sub(cellID, end=-3))

upstream_valid <- upstream %>%
  filter(cellID %in% SingleCell_invitro_umap$cellID)
downstream_valid <- downstream %>%
  filter(cellID %in% SingleCell_invitro_umap$cellID)
downstream_any_valid <- downstream_any %>%
  filter(cellID %in% SingleCell_invitro_umap$cellID)

cat(
  "# cells from bamsort?",
  "\nupstream: \t\t", nrow(upstream_valid),
  "\ndownstream_valid: \t\t", nrow(downstream_valid),
  "\ndownstream_any_valid: \t", nrow(downstream_any_valid),
  "\n\n# cells from bamsort in SALVE?",
  "\nupstream_valid: \t\t", nrow(inner_join(upstream_valid, VISER_invitro_whitelist, by = "cellID")),
  "\t", round(nrow(inner_join(upstream_valid, VISER_invitro_whitelist, by = "cellID"))/nrow(upstream_valid), 2),
  "\ndownstream_valid: \t\t", nrow(inner_join(downstream_valid, VISER_invitro_whitelist, by = "cellID")),
  "\t", round(nrow(inner_join(downstream_valid, VISER_invitro_whitelist, by = "cellID"))/nrow(downstream_valid), 2),
  "\ndownstream_any_valid: \t\t", nrow(inner_join(downstream_any_valid, VISER_invitro_whitelist, by = "cellID")),
  "\t", round(nrow(inner_join(downstream_any_valid, VISER_invitro_whitelist, by = "cellID"))/nrow(downstream_any_valid), 2),
  "\n\n# cells from bamsort in 10X?",
  "\nupstream_valid: \t\t", nrow(inner_join(upstream_valid, SingleCell_invitro_umap, by = "cellID")),
  "\t", round(nrow(inner_join(upstream_valid, SingleCell_invitro_umap, by = "cellID"))/nrow(upstream_valid), 2),
  "\ndownstream_valid: \t\t", nrow(inner_join(downstream_valid, SingleCell_invitro_umap, by = "cellID")),
  "\t", round(nrow(inner_join(downstream_valid, SingleCell_invitro_umap, by = "cellID"))/nrow(downstream_valid), 2),
  "\ndownstream_any_valid: \t", nrow(inner_join(downstream_any_valid, SingleCell_invitro_umap, by = "cellID")),
  "\t", round(nrow(inner_join(downstream_any_valid, SingleCell_invitro_umap, by = "cellID"))/nrow(downstream_any_valid), 2),
  "\n\n# cells from bamsort not in full_join?",
  "\nupstream_valid: \t\t", (nrow(full_join(upstream_valid, invitro_paint_umap, by = "cellID"))-nrow(invitro_paint_umap)),
  "\t", round((nrow(full_join(upstream_valid, invitro_paint_umap, by = "cellID"))-nrow(invitro_paint_umap))/nrow(upstream_valid), 2),
  "\ndownstream_valid: \t\t", (nrow(full_join(downstream_valid, invitro_paint_umap, by = "cellID"))-nrow(invitro_paint_umap)),
  "\t", round((nrow(full_join(downstream_valid, invitro_paint_umap, by = "cellID"))-nrow(invitro_paint_umap))/nrow(downstream_valid), 2),
  "\ndownstream_any_valid: \t\t", (nrow(full_join(downstream_any_valid, invitro_paint_umap, by = "cellID"))-nrow(invitro_paint_umap)),
  "\t", round((nrow(full_join(downstream_any_valid, invitro_paint_umap, by = "cellID"))-nrow(invitro_paint_umap))/nrow(downstream_any_valid), 2),
  "\n\n# cells from bamsort not in inner_join?",
  "\nupstream_valid: \t\t", (nrow(full_join(upstream_valid, inner_invitro_paint_umap, by = "cellID"))-nrow(inner_invitro_paint_umap)),
  "\t", round((nrow(full_join(upstream_valid, inner_invitro_paint_umap, by = "cellID"))-nrow(inner_invitro_paint_umap))/nrow(upstream_valid), 2),
  "\ndownstream_valid: \t\t", (nrow(full_join(downstream_valid, inner_invitro_paint_umap, by = "cellID"))-nrow(inner_invitro_paint_umap)),
  "\t", round((nrow(full_join(downstream_valid, inner_invitro_paint_umap, by = "cellID"))-nrow(inner_invitro_paint_umap))/nrow(downstream_valid), 2),
  "\ndownstream_any_valid: \t", (nrow(full_join(downstream_any_valid, inner_invitro_paint_umap, by = "cellID"))-nrow(inner_invitro_paint_umap)),
  "\t", round((nrow(full_join(downstream_any_valid, inner_invitro_paint_umap, by = "cellID"))-nrow(inner_invitro_paint_umap))/nrow(downstream_any_valid), 2)
)

```

