---
title: "EGS016SALVEseq"
author: "Emanuelle Grody"
date: "2025-07-21"
output: html_document
---

```{r, echo = FALSE}
source("~/SALVEseq/packages.R")
source("~/SALVEseq/functions.R")
```

# Individual Datasets
## KLRB1

GEX: making expressionDF
```{r GEX expressionDF}
# making expressionDF
samples <- data.frame(
  samples = c(
    "W2",
    "W0"
  ),
  folders = c(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_only/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_only/"
  )
)

# Process each sample
for (i in 1:nrow(samples)) {
  sample_name <- samples$samples[i]
  folder_path <- samples$folders[i]
  
  input.dir <- paste0(folder_path, "run_count_", sample_name, "/outs/filtered_feature_bc_matrix/")
  
  cat("Reading from:", input.dir, "\n")
  
  tryCatch({
    # Process the current sample
    seurat_obj <- SeuratPipeline(input.dir, sample_name, plots = FALSE)
    
    # Generate the target expression data frame
    singlecell_df <- targetExpressionDF(seurat_obj, "KLRB1", count_type = "raw")
    
    # Create expressionDF directory if it doesn't exist
    output_dir <- paste0(folder_path, "expressionDF/")
    dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)
    
    # Write the CSV
    output_filename <- paste0(output_dir, sample_name, "_KLRB1_raw.csv")
    write.csv(singlecell_df, output_filename)
    
    cat("Processed sample:", sample_name, "\n")
    cat("Saved to:", output_filename, "\n\n")
  }, error = function(e) {
    cat("Error processing sample", sample_name, ":", conditionMessage(e), "\n\n")
  })
}
```

GEX: bamsort
```{r GEX bamsort}
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/bamsort/alignment/"
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/bamsort/reads/KLRB1"

raw_cellIDs <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/raw_cellIDs/Uninfected_raw_cellIDs.csv")
#raw_cellIDs <- split(raw_cellIDs_df$cellID, raw_cellIDs_df$sample)

# processing
#process_bamsort("SALVE", samples$samples, input.dir, output.dir, raw_cellIDs)


filename <- "W0_GEX_bamsort_alignment_KLRB1.csv"
sample_files <- paste0(input.dir, filename)

extracted_data <- NULL  # Initialize as NULL for each file
all_data <- NULL

tryCatch({
  # Read the CSV file, expecting standard column names
  file_data <- fread(sample_files, data.table = FALSE)
  
  # Check if file has content
  if(nrow(file_data) == 0) {
    cat("Warning: File is empty:", filenames, "\n")
    next
  }
  
  # Simplify column mapping - expect standard column names
  required_cols <- c("cellID", "UMI", "count")
  
  # Check if all required columns exist
  missing_cols <- setdiff(required_cols, colnames(file_data))
  
  if (length(missing_cols) > 0) {
    cat("Warning: Missing required columns:", paste(missing_cols, collapse=", "), "\n")
    cat("Available columns:", paste(colnames(file_data), collapse=", "), "\n")
    next
  }
  
  # Extract data with the required columns and add category
  extracted_data <- file_data %>%
    select(cellID, UMI, count) %>%
    rename(read = count) %>%  # Rename count to read for consistency with later code
    mutate(category = "KLRB1")
  
}, error = function(e) {
  cat("Error reading file:", filenames[j], "\nLikely bad data file\n")
  cat("Error message:", conditionMessage(e), "\n")
})

# Add to the combined data frame only if we have data
if (!is.null(extracted_data) && nrow(extracted_data) > 0) {
  all_data <- rbind(all_data, extracted_data)
}
# Remove any rows with NA values and unique
all_data <- all_data %>% 
  filter(!is.na(cellID) & !is.na(UMI) & !is.na(read)) %>%
  unique()

# Count reads per UMI
tryCatch({
  umi_read_counts <- all_data %>%
    group_by(cellID, UMI, category) %>%
    summarize(
      read_count = sum(as.numeric(read)),  # Sum the count values
      .groups = 'drop'
    )
  
  cat("Gathered read counts for", nrow(umi_read_counts), "UMIs from", 
      n_distinct(umi_read_counts$cellID), "cells\n")
  
  # Create a wide format with UMI counts per category
  umi_by_category <- umi_read_counts %>%
    group_by(cellID, category) %>%
    summarize(
      category_UMIs = n_distinct(UMI),
      category_reads = sum(read_count),
      .groups = 'drop'
    )
  
  # Use pivot_wider to create a wide format
  umi_by_category_wide <- tidyr::pivot_wider(
    umi_by_category,
    id_cols = cellID,
    names_from = category,
    names_sep = "_",
    values_from = c(category_UMIs, category_reads),
    values_fill = 0)
  
  # Apply raw_cellIDs filtering
    valid_cells <- raw_cellIDs$cellID
    cat("Keeping only cells in", 
        length(valid_cells), "valid cells from 10X data\n")
    
    # Filter the UMI-level data
    filtered_umi_read_counts <- umi_read_counts %>%
      filter(cellID %in% valid_cells)
  
  
  # Save the detailed UMI-level data (both filtered and unfiltered)
  umi_level_file <- file.path(output.dir, "W0_UMI_read_counts_raw.csv")
  write.csv(umi_read_counts, file = umi_level_file, row.names = FALSE)
  
  filtered_umi_level_file <- file.path(output.dir, "W0_UMI_read_counts_full.csv")
  write.csv(filtered_umi_read_counts, file = filtered_umi_level_file, row.names = FALSE)
  
  cat("Successfully processed\n")
  rm(umi_by_category, umi_by_category_wide, umi_read_counts)
}, error = function(e) {
  cat("Error processing data for sample", sample, ":", conditionMessage(e), "\n")
  
  # Try to save the raw data at least
  raw_file <- file.path(output.dir, paste0(sample, "_raw_data.csv"))
  write.csv(all_data, file = raw_file, row.names = FALSE)
  cat("Saved raw data to:", raw_file, "\n")
})

# minimums
input <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/bamsort/reads/KLRB1/W0_UMI_read_counts_full.csv"
output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/bamsort/reads/KLRB1/minimum/" 

W0_min <- set_minimums("KLRB1", input, min_reads = 1, min_umi = 1)
write.csv(W0_min, paste0(output_dir, "W0_minread1_minumi1.csv"))
GEX_KLRB1_W0 <- W0_min %>%
  select(-total) %>%
  mutate(KLRB1 = log1p(KLRB1))

GEX_KLRB1_W0_expressionDF <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_only/expressionDF/W0_KLRB1_raw.csv", row.names = "X")
cat("# cells KLRB1+ from expressionDF: \t",
  sum(GEX_KLRB1_W0_expressionDF$KLRB1 > 0),
  "\n# cells KLRB1+ from bamsort: \t\t",
  sum(W0_min$KLRB1 > 0))
GEX_KLRB1_W0_expressionDF <- GEX_KLRB1_W0_expressionDF %>% select(-KLRB1)
GEX_KLRB1_W0 <- left_join(GEX_KLRB1_W0_expressionDF, GEX_KLRB1_W0, by = "cellID")
GEX_KLRB1_W0[is.na(GEX_KLRB1_W0)] <- 0

max(GEX_KLRB1_W0$KLRB1)
```

SALVE: expressionDF (skip)
```{r}
SALVE_list <- list()
for (sample_name in c("W0", "W2")) {
  folder_path <- paste0("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/SALVE/counts/Mmul_10_mac239v4_", 
                          sample_name, "_KLRB1_PL/outs/filtered_feature_bc_matrix/")
    
  # Process the current sample
  data <- Read10X(data.dir = folder_path)
  seurat_obj <- CreateSeuratObject(counts = data, project = sample_name, min.cells = 3)
  #seurat_obj <- NormalizeData(seurat_obj, verbose = FALSE) #for raw, comment this out
  # Extract viral genes
  sample_df <- targetExpressionDF(seurat_obj, "KLRB1", count_type = "raw") #
  
  # Add sample and target columns to the dataframe
  sample_df$sample <- sample_name
  sample_df$target <- "KLRB1"
  
  # Add to list
  SALVE_list[[length(SALVE_list) + 1]] <- sample_df
}

SALVE_KLRB1 <- data.frame()
SALVE_KLRB1 <- bind_rows(SALVE_list)
SALVE_KLRB1 <- SALVE_KLRB1 %>%
  filter(!(`KLRB1` == 0))
rm(SALVE_list)

output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/SALVE/counts/expressionDF/"
write.csv(SALVE_KLRB1, paste0(output.dir, "SALVE_KLRB1_filtercounts.csv"))

```

SALVE: bamsort
```{r SALVE}
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/SALVE/bamsort/alignment/KLRB1/"
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/SALVE/bamsort/reads/KLRB1/"

raw_cellIDs <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS014/singleCell/raw_cellIDs/Uninfected_raw_cellIDs.csv")

filenames <- "W0_KLRB1_PL_bamsort_alignment_KLRB1.csv"
sample_files <- paste0(input.dir, filenames)

all_data <- data.frame()
extracted_data <- NULL

tryCatch({
  # Read the CSV file
  file_data <- fread(sample_files, data.table = FALSE)
  
  # Check if file has content
  if(nrow(file_data) == 0) {
    cat("Warning: File is empty:", filenames, "\n")
    stop("Empty file")  # Use stop() instead of next
  }
  
  # Check required columns
  required_cols <- c("cellID", "UMI", "count")
  missing_cols <- setdiff(required_cols, colnames(file_data))
  
  if (length(missing_cols) > 0) {
    cat("Warning: Missing required columns:", paste(missing_cols, collapse=", "), "\n")
    cat("Available columns:", paste(colnames(file_data), collapse=", "), "\n")
    stop("Missing columns")  # Use stop() instead of next
  }
  
  # Extract data
  extracted_data <- file_data %>%
    select(cellID, UMI, count) %>%
    rename(read = count) %>%
    mutate(category = "KLRB1")
  
}, error = function(e) {
  cat("Error reading file:", filenames, "\nLikely bad data file\n")
  cat("Error message:", conditionMessage(e), "\n")
})

# Add to combined data frame
if (!is.null(extracted_data) && nrow(extracted_data) > 0) {
  all_data <- rbind(all_data, extracted_data)
}

# Remove rows with NA values and get unique records
all_data <- all_data %>% 
  filter(!is.na(cellID) & !is.na(UMI) & !is.na(read)) %>%
  unique()

# Count reads per UMI
tryCatch({
  umi_read_counts <- all_data %>%
    group_by(cellID, UMI, category) %>%
    summarize(
      read_count = sum(as.numeric(read)),
      .groups = 'drop'
    )
  
  cat("Gathered read counts for", nrow(umi_read_counts), "UMIs from", 
      n_distinct(umi_read_counts$cellID), "cells\n")
  
  # Create wide format with UMI counts per category
  umi_by_category <- umi_read_counts %>%
    group_by(cellID, category) %>%
    summarize(
      category_UMIs = n_distinct(UMI),
      category_reads = sum(read_count),
      .groups = 'drop'
    )
  
  umi_by_category_wide <- tidyr::pivot_wider(
    umi_by_category,
    id_cols = cellID,
    names_from = category,
    names_sep = "_",
    values_from = c(category_UMIs, category_reads),
    values_fill = 0)
  
  # Apply raw_cellIDs filtering
  valid_cells <- raw_cellIDs$cellID
  cat("Keeping only cells in", 
      length(valid_cells), "valid cells from 10X data\n")
  
  filtered_umi_read_counts <- umi_read_counts %>%
    filter(cellID %in% valid_cells)
  
  # Save outputs
  umi_level_file <- file.path(output.dir, "W0_UMI_read_counts_raw.csv")
  write.csv(umi_read_counts, file = umi_level_file, row.names = FALSE)
  
  filtered_umi_level_file <- file.path(output.dir, "W0_UMI_read_counts_full.csv")
  write.csv(filtered_umi_read_counts, file = filtered_umi_level_file, row.names = FALSE)
  
  cat("Successfully processed\n")
  rm(umi_by_category, umi_by_category_wide, umi_read_counts)
  
}, error = function(e) {
  cat("Error processing data:", conditionMessage(e), "\n")
  
  # Save raw data as fallback
  raw_file <- file.path(output.dir, "raw_data.csv")
  write.csv(all_data, file = raw_file, row.names = FALSE)
  cat("Saved raw data to:", raw_file, "\n")
})


# minimums
input <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/SALVE/bamsort/reads/KLRB1/W0_UMI_read_counts_full.csv"
output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/SALVE/bamsort/reads/KLRB1/minimum/" 
W0_min <- set_minimums("KLRB1", input, min_reads = 5, min_umi = 1)
write.csv(W0_min, paste0(output_dir, "SALVE_KLRB1_W0_SALVE_minreads5.csv"))
SALVE_KLRB1_W0 <- W0_min %>%
  select(-total) %>%
  mutate(KLRB1 = log1p(KLRB1))

#max(SALVE_KLRB1_W0$KLRB1)
```

### Saturation
Compare recovery: UMIs and cells
```{r}
input <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/bamsort/reads/KLRB1/W0_UMI_read_counts_full.csv"
GEX_nomin <- read.csv(input)
input <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/SALVE/bamsort/reads/KLRB1/W0_UMI_read_counts_full.csv"
SALVE_nomin <- read.csv(input)
SALVE_nomin <- SALVE_nomin %>%
  filter(read_count >= 5)
SALVE_nomin <- SALVE_nomin %>%
  filter(cellID %in% raw_cellIDs$cellID)

# Compare UMIs
## Create combined identifiers
SALVE_pairs <- paste(SALVE_nomin$cellID, SALVE_nomin$UMI, sep = "_")
GEX_pairs <- paste(GEX_nomin$cellID, GEX_nomin$UMI, sep = "_")
## Find which pairs from SALVE are in GEX
SALVE_in_GEX <- SALVE_pairs %in% GEX_pairs
GEX_in_SALVE <- GEX_pairs %in% SALVE_pairs
## Calculate proportions
prop_SALVE_in_GEX <- sum(SALVE_in_GEX) / length(SALVE_in_GEX)
prop_GEX_in_SALVE <- sum(GEX_in_SALVE) / length(GEX_in_SALVE)

cat("Fraction cellID-UMI pairs from...\nGEX in SALVE: ",
    prop_GEX_in_SALVE,
    "\nSALVE in GEX: ",
    prop_SALVE_in_GEX)

# Compare cells
## Create combined identifiers
SALVE_cells <- unique(SALVE_nomin$cellID)
GEX_cells <- unique(GEX_nomin$cellID)
## Find which cells from SALVE are in GEX
SALVEc_in_GEXc <- SALVE_cells %in% GEX_cells
GEXc_in_SALVEc <- GEX_cells %in% SALVE_cells
## Calculate proportions
prop_cells_SALVE_in_GEX <- sum(SALVEc_in_GEXc) / length(SALVEc_in_GEXc)
prop_cells_GEX_in_SALVE <- sum(GEXc_in_SALVEc) / length(GEXc_in_SALVEc)

cat("Fraction cells from...\nGEX in SALVE: ",
    prop_cells_GEX_in_SALVE,
    "\nSALVE in GEX: ",
    prop_cells_SALVE_in_GEX)

cat("\nNumbers for text\n\nTotal GEX UMI: ",
    length(GEX_pairs),
    "\nNumber UMI GEX only: \t\t",
    length(GEX_pairs) - sum(GEX_in_SALVE),
    "\nFraction UMI GEX only: \t\t",
    1-prop_GEX_in_SALVE,
    "\nNumber cells GEX only: \t\t",
    length(GEX_cells) - sum(GEXc_in_SALVEc),
    "\nFraction cells GEX only: \t",
    1-prop_cells_GEX_in_SALVE)
```

Subsample read-weighted UMI
```{r}
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/SALVE/saturation/sample_UMI/"
input <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/SALVE/bamsort/reads/KLRB1/W0_UMI_read_counts_full.csv"
SALVE_nomin <- read.csv(input) %>%
  rename(reads = read_count)

  
results <- sample_UMI_weighted(SALVE_nomin)
summary <- analyze_UMI_sampling(results, title = "Weighted UMI Saturation: KLRB1 W0")

results_file <- paste0(output.dir, "KLRB1_W0_sample_UMI_results.csv")
summary_file <- paste0(output.dir, "KLRB1_W0_sample_UMI_summary.csv")
write.csv(results, results_file, row.names = FALSE)
write.csv(summary, summary_file, row.names = FALSE)

```

```{r}
model_results <- fit_models(results, target_coverage = 95, coverage_column = "pair_coverage")
model_results <- fit_models(results, target_coverage = 98.9, coverage_column = "pair_coverage")
model_results <- fit_models(results, target_coverage = 100, coverage_column = "pair_coverage")
model_results <- fit_models(results, target_coverage = 120)
```

To sequence more or not to sequence more, also not sure if it's correct
```{r}
decision <- make_sequencing_decision(SALVE_nomin, target_coverage = 80, coverage_column = "pair_coverage")

# Function to extract saturation data from model results
extract_saturation_data <- function(model_results, reads_GEX) {
  
  # Get prediction data
  pred_data <- model_results$predictions
  model_columns <- setdiff(colnames(pred_data), "percentage")
  
  # Calculate total reads at different sampling percentages
  total_reads <- sum(reads_GEX$reads)
  
  # Initialize results dataframe
  saturation_data <- data.frame(
    sampling_percentage = pred_data$percentage,
    reads_millions = (pred_data$percentage / 100) * total_reads / 1000000
  )
  
  # Get coverage data from best model
  valid_coverage <- c()
  for (col in model_columns) {
    if (col %in% colnames(pred_data)) {
      model_data <- pred_data[[col]]
      # Remove infinite, NA, and unrealistic values
      model_data <- model_data[is.finite(model_data) & model_data >= 0 & model_data <= 200]
      
      if (length(model_data) > 0) {
        valid_coverage <- pred_data[[col]]
        break  # Use first valid model
      }
    }
  }
  
  saturation_data$coverage <- valid_coverage
  
  # Calculate sequencing saturation (% of maximum possible coverage achieved)
  max_coverage <- max(saturation_data$coverage, na.rm = TRUE)
  saturation_data$sequencing_saturation <- (saturation_data$coverage / max_coverage) * 100
  
  # Information saturation is essentially the coverage itself
  # (what % of the information/genes/pairs you're capturing)
  saturation_data$information_saturation <- saturation_data$coverage
  
  return(list(
    data = saturation_data,
    max_coverage = max_coverage,
    total_reads = total_reads
  ))
}

# Function to plot sequencing saturation
plot_sequencing_saturation <- function(saturation_data, saturation_target = 90, 
                                      title = "Sequencing Saturation Curve") {
  
  data <- saturation_data$data
  total_reads <- saturation_data$total_reads
  
  # Calculate actual reads from sampling percentage
  data$actual_reads <- (data$sampling_percentage / 100) * total_reads
  
  p1 <- ggplot(data, aes(x = actual_reads, y = sequencing_saturation)) +
    geom_line(color = "blue", size = 1.2) +
    geom_point(color = "blue", size = 2) +
    labs(
      title = title,
      subtitle = "How efficiently you're capturing your library's potential",
      x = "Total Reads Sequenced",
      y = "Sequencing Saturation (%)",
      caption = "100% = you've captured all complexity this library can provide"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 12, color = "gray60"),
      axis.title = element_text(size = 12),
      panel.grid.minor = element_blank()
    ) +
    scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 20)) +
    scale_x_continuous(labels = scales::comma_format()) +
    geom_hline(yintercept = saturation_target, linetype = "dashed", color = "red", alpha = 0.7) +
    annotate("text", x = max(data$actual_reads) * 0.7, y = saturation_target + 2, 
             label = paste0(saturation_target, "% efficiency"), color = "red", size = 3)
  
  return(p1)
}

# Function to plot information saturation
plot_information_saturation <- function(saturation_data, target_coverage = 90, 
                                       title = "Information Saturation Curve") {
  
  data <- saturation_data$data
  
  p2 <- ggplot(data, aes(x = reads_millions, y = information_saturation)) +
    geom_line(color = "darkgreen", size = 1.2) +
    geom_point(color = "darkgreen", size = 2) +
    labs(
      title = title,
      subtitle = "How much biological information you're capturing",
      x = "Sequencing Depth (Million Reads)",
      y = "Information Saturation (%)",
      caption = "% of genes/pairs/features detected in your experiment"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 12, color = "gray60"),
      axis.title = element_text(size = 12),
      panel.grid.minor = element_blank()
    ) +
    scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 20)) +
    geom_hline(yintercept = target_coverage, linetype = "dashed", color = "red", alpha = 0.7) +
    annotate("text", x = max(data$reads_millions) * 0.7, y = target_coverage + 2, 
             label = paste0(target_coverage, "% target"), color = "red", size = 3)
  
  return(p2)
}


sat_data <- extract_saturation_data(decision$model_results, SALVE_nomin)
# Plot sequencing saturation
p1 <- plot_sequencing_saturation(sat_data, saturation_target = 80)
print(p1)

# Plot information saturation  
p2 <- plot_information_saturation(sat_data, target_coverage = 80)
print(p2)


target_saturation <- 90
data <- sat_data$data
total_reads <- sat_data$total_reads
data$actual_reads <- (data$sampling_percentage / 100) * total_reads
closest_idx <- which.min(abs(data$sequencing_saturation - target_saturation))
reads_needed <- data$actual_reads[closest_idx]

cat(sprintf("For %.0f%% sequencing saturation: %s reads\n", 
            target_saturation, scales::comma(round(reads_needed))))
```

Saturation analysis, not sure if it's correct:
```{r}
# Function to analyze sequencing and information saturation
analyze_saturation <- function(df) {
  # Assumes df has columns: cellID, UMI, reads
  
  cat("=== BASIC STATISTICS ===\n")
  cat("Total cells:", length(unique(df$cellID)), "\n")
  cat("Total UMIs:", length(unique(df$UMI)), "\n")
  cat("Total reads:", sum(df$reads), "\n")
  cat("Mean reads per UMI:", round(mean(df$reads), 2), "\n\n")
  
  # 1. SEQUENCING SATURATION (corrected)
  cat("=== SEQUENCING SATURATION ===\n")
  
  cell_stats <- df %>%
    group_by(cellID) %>%
    summarise(
      total_reads = sum(reads),
      unique_umis = n(),
      .groups = 'drop'
    ) %>%
    mutate(
      # CORRECTED: Sequencing saturation = (total_reads - unique_umis) / total_reads
      # This represents the fraction of reads that are duplicates
      seq_saturation = ifelse(total_reads > 0, 
                             (total_reads - unique_umis) / total_reads, 
                             0)
    )
  
  cat("Mean sequencing saturation:", round(mean(cell_stats$seq_saturation), 3), "\n")
  cat("Median sequencing saturation:", round(median(cell_stats$seq_saturation), 3), "\n")
  cat("Range:", round(min(cell_stats$seq_saturation), 3), "-", round(max(cell_stats$seq_saturation), 3), "\n\n")
  
  # 2. INFORMATION SATURATION (corrected approach)
  cat("=== INFORMATION SATURATION ===\n")
  
  # Better approach: Calculate saturation curves per cell, then average
  fractions <- seq(0.1, 1.0, by = 0.1)
  
  # Function to subsample reads for a single cell
  subsample_cell <- function(cell_data, fraction) {
    total_reads <- sum(cell_data$reads)
    n_reads_to_sample <- round(total_reads * fraction)
    
    if (n_reads_to_sample == 0) return(0)
    if (n_reads_to_sample >= total_reads) return(nrow(cell_data))
    
    # Create probability weights for sampling UMIs based on read counts
    probs <- cell_data$reads / total_reads
    
    # Sample UMIs with replacement, weighted by read counts
    sampled_reads <- 0
    detected_umis <- character(0)
    
    while (sampled_reads < n_reads_to_sample) {
      # Sample one UMI based on read probabilities
      sampled_umi_idx <- sample(1:nrow(cell_data), 1, prob = probs)
      sampled_umi <- cell_data$UMI[sampled_umi_idx]
      
      detected_umis <- c(detected_umis, sampled_umi)
      sampled_reads <- sampled_reads + 1
    }
    
    return(length(unique(detected_umis)))
  }
  
  # Perform subsampling for cells with enough reads
  min_reads_threshold <- 50  # Only analyze cells with sufficient reads
  cells_to_analyze <- cell_stats %>% 
    filter(total_reads >= min_reads_threshold) %>% 
    pull(cellID)
  
  if (length(cells_to_analyze) == 0) {
    cat("Warning: No cells have sufficient reads for saturation analysis\n")
    cells_to_analyze <- unique(df$cellID)[1:min(10, length(unique(df$cellID)))]
  }
  
  saturation_curves <- data.frame()
  
  for (cell in cells_to_analyze) {
    cell_data <- df[df$cellID == cell, ]
    
    for (frac in fractions) {
      umis_detected <- subsample_cell(cell_data, frac)
      
      saturation_curves <- rbind(saturation_curves, data.frame(
        cellID = cell,
        fraction = frac,
        umis_detected = umis_detected,
        total_reads_sampled = round(sum(cell_data$reads) * frac)
      ))
    }
  }
  
  # Calculate average saturation curve
  avg_saturation <- saturation_curves %>%
    group_by(fraction) %>%
    summarise(
      mean_umis = mean(umis_detected),
      median_umis = median(umis_detected),
      se_umis = sd(umis_detected) / sqrt(n()),
      .groups = 'drop'
    )
  
  # Calculate information saturation metrics
  max_umis <- avg_saturation$mean_umis[avg_saturation$fraction == 1.0]
  umis_at_90pct <- avg_saturation$mean_umis[avg_saturation$fraction == 0.9]
  umis_at_80pct <- avg_saturation$mean_umis[avg_saturation$fraction == 0.8]
  
  info_saturation_90 <- umis_at_90pct / max_umis
  info_saturation_80 <- umis_at_80pct / max_umis
  
  cat("Information saturation (90% vs 100% reads):", round(info_saturation_90, 3), "\n")
  cat("Information saturation (80% vs 100% reads):", round(info_saturation_80, 3), "\n")
  
  # Calculate slope in the last 20% to assess if plateau is reached
  slope_data <- avg_saturation %>% filter(fraction >= 0.8)
  if (nrow(slope_data) >= 2) {
    slope <- (max(slope_data$mean_umis) - min(slope_data$mean_umis)) / 
             (max(slope_data$fraction) - min(slope_data$fraction))
    cat("UMI detection rate in final 20% of reads:", round(slope, 2), "UMIs per 10% read increase\n")
  }
  cat("\n")
  
  # 3. VISUALIZATION
  
  # Plot 1: Sequencing saturation distribution
  p1 <- ggplot(cell_stats, aes(x = seq_saturation)) +
    geom_histogram(bins = 30, fill = "lightblue", alpha = 0.7, color = "black") +
    labs(title = "Distribution of Sequencing Saturation",
         subtitle = paste("Mean:", round(mean(cell_stats$seq_saturation), 3)),
         x = "Sequencing Saturation (Fraction of Duplicate Reads)", 
         y = "Number of Cells") +
    theme_minimal()
  
  # Plot 2: Information saturation curve with error bars
  p2 <- ggplot(avg_saturation, aes(x = fraction * 100, y = mean_umis)) +
    geom_line(color = "blue", size = 1) +
    geom_point(color = "blue", size = 2) +
    geom_errorbar(aes(ymin = mean_umis - se_umis, ymax = mean_umis + se_umis), 
                  width = 2, color = "blue", alpha = 0.7) +
    labs(title = "Information Saturation Curve",
         subtitle = paste("Based on", length(cells_to_analyze), "cells with ≥", min_reads_threshold, "reads"),
         x = "Percentage of Total Reads (%)",
         y = "Mean UMIs Detected") +
    scale_x_continuous(breaks = seq(10, 100, 10)) +
    theme_minimal()
  
  # Plot 3: Reads vs UMIs per cell (log scale for better visualization)
  p3 <- ggplot(cell_stats, aes(x = total_reads, y = unique_umis)) +
    geom_point(alpha = 0.6, color = "darkgreen") +
    geom_smooth(method = "loess", color = "red", se = TRUE) +
    labs(title = "UMIs vs Total Reads per Cell",
         x = "Total Reads (log scale)",
         y = "Unique UMIs (log scale)") +
    scale_x_log10() +
    scale_y_log10() +
    theme_minimal()
  
  print(p1)
  print(p2)
  print(p3)
  
  # Return summary statistics
  return(list(
    cell_stats = cell_stats,
    saturation_curves = saturation_curves,
    avg_saturation = avg_saturation,
    overall_seq_saturation = mean(cell_stats$seq_saturation),
    info_saturation_90vs100 = info_saturation_90,
    info_saturation_80vs100 = info_saturation_80
  ))
}


results <- analyze_saturation(SALVE_nomin)
```


## SALVE 

Using both EGS016 and EGS018 data
### bamsort
Run this once first to get raw cellIDs:
```{r raw_cellIDs}
# Load and save raw cell IDs from 10X data
raw_cellIDs <- list()
output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/raw_cellIDs" 

# Create output directory if it doesn't exist
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}


samples <- data.frame(
  datasets = c(
    "LP29_D0",
    "LP29_D195",
    "LP29_D83",
    "invitro",
    "P_acute_GEX",
    "W0",
    "W2"
  ),
  samples = c(
    "D0",
    "D195",
    "D83",
    "Invitro",
    "Pacute",
    "W0",
    "W2"
  ),
  folders = c(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/"
  )
)

all_cellIDs <- data.frame(cellID = character(), sample = character(), stringsAsFactors = FALSE)

for (i in 1:nrow(samples)) {
  dataset_name <- samples$datasets[i]
  sample_name <- samples$samples[i]
  rawDataFolder <- paste0(samples$folders[i], "Mmul_10_mac239_", samples$datasets[i], "/outs/raw_feature_bc_matrix/")
  
  tryCatch({
    rawdata <- Read10X(rawDataFolder)
    umi_counts <- colSums(rawdata)
    cell_ids <- names(umi_counts[umi_counts > 100]) # keep only cells with transcriptomes
    raw_cellIDs[[sample_name]] <- cell_ids
    cat("Loaded", length(cell_ids), "raw cellIDs for sample", sample_name, "\n")
    
    # Add to the combined dataframe
    sample_df <- data.frame(
      cellID = cell_ids,
      sample = rep(sample_name, length(cell_ids)),
      stringsAsFactors = FALSE
    )
    all_cellIDs <- rbind(all_cellIDs, sample_df)
    
    # Save individual sample's cell IDs to CSV
    sample_file <- file.path(output_dir, paste0(sample_name, "_raw_cellIDs.csv"))
    write.csv(data.frame(cellID = cell_ids), sample_file, row.names = FALSE)
    cat("Saved", length(cell_ids), "cell IDs to", sample_file, "\n")
    
  }, error = function(e) {
    cat("Error processing", dataset_name, ":", conditionMessage(e), "\n")
  })
  
  if (exists("rawdata")) {
    rm(rawdata)
    gc()
  }
}

# Save the combined cell IDs to a single CSV
combined_file <- file.path(output_dir, "all_raw_cellIDs.csv")
write.csv(all_cellIDs, combined_file, row.names = FALSE)
cat("Saved combined cell IDs to", combined_file, "\n")

# To easily load this data in the future:
# raw_cellIDs_df <- read.csv("path/to/output/directory/all_raw_cellIDs.csv")
# raw_cellIDs <- split(raw_cellIDs_df$cellID, raw_cellIDs_df$sample)
```


Making full and minimum filtered lists:
```{r}
samples <- c(
    "D0",
    "D195",
    "Invitro",
    "Pacute",
    "W0",
    "W2"
)


input.dirs <- c("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/SALVE/bamsort/alignment/v5coordinates/", 
          "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/SALVE/bamsort/alignment/v5coordinates/")
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/SALVE/bamsort/reads/v6/"


raw_cellIDs_df <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/raw_cellIDs/all_raw_cellIDs.csv")
raw_cellIDs <- split(raw_cellIDs_df$cellID, raw_cellIDs_df$sample)

process_bamsortv6(samples, input.dirs, output.dir, raw_cellIDs)

# minimums
input_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/SALVE/bamsort/reads/v6/"
output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/SALVE/bamsort/reads/v6/minimum/" 

viremia <- c(
    "Invitro",
    "Pacute",
    "W2"
  )
ART <- c(
    "D0",
    "D195",
    "W0"
  )
process_all_set_minimumsv6("SALVE", viremia, input_dir, output_dir, min_reads = 5, min_umi = 2)
process_all_set_minimumsv6("SALVE", ART, input_dir, output_dir, min_reads = 2, min_umi = 2)

```

### Direct splicing
Quantifying splicing from actual reads instead of inference
```{r}
# SALVE
samples <- c(
    "D0",
    "D195",
    "Invitro",
    "Pacute",
    "W0",
    "W2"
)
targets <- c(
  "D1_PL",
  "pol_PL",
  "SSenv_PL",
  "env_PL",
  "tat"
)
input_dir <- c("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/SALVE/bamsort/splice/",
               "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/SALVE/bamsort/splice/")

raw_cellIDs_df <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/raw_cellIDs/all_raw_cellIDs.csv")
raw_cellIDs <- split(raw_cellIDs_df$cellID, raw_cellIDs_df$sample)

acceptors <- data.frame(
  Acceptor = c(4658, 5141, 5746, 5818, 5959, 8249),
  AcceptorSite = c("A1", "A2", "A3", "A4", "A5", "A7")
)
donors <- data.frame(
  Donor = c(431, 4730, 5217, 6043),
  DonorSite = c("D1", "D2", "D3", "D4")
)

output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/SALVE/bamsort/splice/combined/"

# GEX
# samples <- list(Invitro = c("invitro"))
# input_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/bamsort/splice/"
# samples <- list(D13= c("JK85_D13"))
# input_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/bamsort/splice/"
# 
# samples <- list(InvitrocDNA= c("cDNA"))
# input_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS007/longRead/bamsort/splice/"


for (sample_name in samples) {
  cat("\nProcessing sample:", sample_name)
  
  # Step 1: Combine data from all files in this sample
  combined_data <- data.frame()
  
  for (target_name in targets) {
    filename <- paste0(sample_name, "_", target_name, "_splicesites.csv")
    data <- NULL
    for (dir in input_dir) {
      filepath <- file.path(dir, filename)
      if (file.exists(filepath)) {
        data <- read.csv(filepath)
        break
      }
    }
    
    if (is.null(data)) {
      cat("  WARNING: File not found:", filename, "\n")
      next
    }
    
    file_data <- data %>%
      filter(CB %in% raw_cellIDs[[sample_name]])
    if (nrow(file_data) == 0) {
      next
    }
        
    file_data <- file_data %>%
      rowwise() %>%
      mutate(
        DonorSite = classify_site(Donor, donors$Donor, donors$DonorSite),
        AcceptorSite = classify_site(Acceptor, acceptors$Acceptor, acceptors$AcceptorSite)) %>%
      ungroup() %>% 
      select(CB, UB, DonorSite, AcceptorSite) %>% 
      distinct(CB, DonorSite, AcceptorSite, UB, .keep_all = TRUE) %>%
      mutate(Target = strsplit(target_name, "_")[[1]][1]) %>%
      mutate(Target = if_else(Target == "tat", "D4", Target)) %>%
      filter(Target != DonorSite)
    
    combined_data <- rbind(combined_data, file_data)
  }
  write.csv(combined_data, paste0(output_dir, sample_name, "_splicesites_filtered.csv"))
  
}


```

Single cell splicing
```{r}
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/splice/mac239/"
samples <- c("D13", "Invitro")
targets <- c("D1_nef", "LTR_tat")

acceptors <- data.frame(
  Acceptor = c(4658, 5141, 5746, 5818, 5959, 8249),
  AcceptorSite = c("A1", "A2", "A3", "A4", "A5", "A7")
)
donors <- data.frame(
  Donor = c(431, 4730, 5217, 6043),
  DonorSite = c("D1", "D2", "D3", "D4")
)

comparison <- data.frame()

classify_site <- function(value, reference_values, reference_sites) {
  distances <- abs(value - reference_values)
  min_dist <- min(distances)
  closest_site <- reference_sites[which.min(distances)]
  
  if (min_dist <= 3) {
    return(as.character(closest_site))
  } else if (min_dist <= 12) {
    return("mnc")
  } else {
    return("nc")
  }
}

for (sample in samples) {
  dataset <- data.frame()
  for (target in targets) {
    file_name <- paste0(input.dir, sample, "_", target, "_splicesites.csv")
    file <- read.csv(file_name)
    dataset <- rbind(dataset, file)
  }
  dataset <- dataset %>%
    rowwise() %>%
    mutate(
      DonorSite = classify_site(Donor, donors$Donor, donors$DonorSite),
      AcceptorSite = classify_site(Acceptor, acceptors$Acceptor, acceptors$AcceptorSite)) %>%
    ungroup() %>% 
    select(-CIGAR, -Read.sequence, -Sequence.after.the.N, -Before_N_M_coords, -After_N_M_coords) %>% 
    distinct(CB, DonorSite, AcceptorSite, UB, .keep_all = TRUE)
  topsplicers <- dataset %>% count(CB) %>% rename(events = n) %>% arrange(desc(events))
  test <- dataset %>%
    filter(DonorSite == "nc" | AcceptorSite == "nc") %>%
    count(CB) %>% rename(nc = n)
  topsplicers <- left_join(topsplicers, test, by = "CB") %>%
    replace(is.na(.), 0) %>%
    mutate(sample = sample)
  
  comparison <- rbind(comparison, topsplicers)
  
  ggplot(topsplicers, aes(x = log1p(events), y = log1p(nc))) +
    geom_point(size = 2) +
    theme_minimal() +
    theme(legend.position = "none") +
    labs(title = paste0(sample, " Splicing Events"), 
         x = "Splicing events (log)", y = "Non-canonical splicing events (log)") + 
    xlim(0,6)
  
  #test <- topsplicers %>% filter(events == nc) %>% arrange(desc(events))
}


```

## GEX
### bamsort
```{r}
samples <- data.frame(
  datasets = c(
    "LP29_D0",
    "LP29_D195",
    "LP29_D83",
    "invitro",
    "P_acute_GEX",
    "W0",
    "W2"
  ),
  samples = c(
    "D0",
    "D195",
    "D83",
    "Invitro",
    "Pacute",
    "W0",
    "W2"
  )
)

# Process
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/bamsort/alignment/v5/"
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/bamsort/reads/v6/"

raw_cellIDs_df <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/raw_cellIDs/all_raw_cellIDs.csv")
raw_cellIDs <- split(raw_cellIDs_df$cellID, raw_cellIDs_df$sample)

process_bamsortv6(samples$samples, input.dir, output.dir, raw_cellIDs)

# Minimums
input_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/bamsort/reads/v6/"
output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/bamsort/reads/v6/minimum/"

process_all_set_minimumsv6("GEX", samples$samples, input_dir, output_dir, min_reads_cell = 2)

```

### UMAP coords and cell size

```{r}
samples <- data.frame(
  datasets = c(
    "LP29_D0",
    "LP29_D195",
    "LP29_D83",
    "invitro",
    "P_acute_combined",
    "W0",
    "W2"
  ),
  samples = c(
    "D0",
    "D195",
    "D83",
    "Invitro",
    "Pacute",
    "W0",
    "W2"
  ),
  folders = c(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239/"
  )
)

output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/Seurat/UMAPcoords/"
if (!dir.exists(output.dir)) {
  dir.create(output.dir, recursive = TRUE)
}

for (i in 1:nrow(samples)) {
  sample_name <- samples$samples[i]
  dataset <- samples$datasets[i]
  folder <- samples$folders[i]
  input.dir <- paste0(folder, "Mmul_10_mac239_", dataset, "/outs/filtered_feature_bc_matrix/")
  
  tryCatch({
    seurat_obj <- SeuratPipeline(input.dir, sample_name, 
                                 output_dir = "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/Seurat/plots/", 
                                 plots = TRUE, rds = TRUE)
    
    # Generate expression data frame without gene expression
    sample_df <- targetExpressionDF(seurat_obj, genes = "")

    # Add sample and target columns to the dataframe
    sample_df$size <- colSums(GetAssayData(seurat_obj, assay = "RNA", slot = "counts"))
    sample_df$sample <- sample_name

    write.csv(sample_df, paste0(output.dir, sample_name, "UMAP_coords.csv"))
    
    cat("Processed sample:", sample_name, "\n")
  }, error = function(e) {
    cat("Error processing sample", sample_name, ":", conditionMessage(e), "\n\n")
  })
}
```

### expressionDF (skip)
```{r expressionDF}
# making expressionDF
samples <- data.frame(
  datasets = c(
    # "LP29_D0",
    # "LP29_D195",
    # "LP29_D83",
    "Invitro_CD4",
    # "P_acute_GEX",
    "HD88_W0",
    "A8R095_W2"
  ),
  samples = c(
    # "D0",
    # "D195",
    # "D83",
    "Invitro",
    # "Pacute",
    "W0",
    "W2"
  ),
  folders = c(
    # "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10/",
    # "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10/",
    # "/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239v4/",
    # "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239v4/",
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239v4/"
  )
)

v4genes <- c(
  "D1-US",
  "D1-S",
  "tat-US",
  "tat-S",
  "LTR-3",
  "LTR-5",
  "nef-3",
  "nef-5"
)
v5genes <- c(
  "LTR-D1",
  "D1-A4",
  "A4-D7",
  "D7-LTR"
)

GEX_list <- list()
# Process each sample
for (i in 1:nrow(samples)) {
  sample_name <- samples$samples[i]
  dataset_name <- samples$datasets[i]
  folder_path <- samples$folders[i]
  
  input.dir <- paste0(folder_path, "Mmul_10_mac239v4_", dataset_name, "/outs/filtered_feature_bc_matrix/")
  
  #cat("Reading from:", input.dir, "\n")
  
  tryCatch({
    # Process the current sample
    seurat_obj <- SeuratPipeline(input.dir, sample_name, plots = FALSE)
    
    # Generate the target expression data frame
    singlecell_df <- targetExpressionDF(seurat_obj, v4genes, count_type = "raw")
    
    # Create expressionDF directory if it doesn't exist
    output_dir <- paste0(folder_path, "expressionDF/")
    dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)
    
    # Write the CSV
    output_filename <- paste0(output_dir, sample_name, "_v4_raw.csv")
    write.csv(singlecell_df, output_filename)
    
    # For isoforms
    singlecell_df$sample <- sample_name
    GEX_list[[length(GEX_list) + 1]] <- singlecell_df
    
    cat("Processed sample:", sample_name, "\n")
    #cat("Saved to:", output_filename, "\n\n")
  }, error = function(e) {
    cat("Error processing sample", sample_name, ":", conditionMessage(e), "\n\n")
  })
}

GEX_combined <- data.frame()
GEX_combined <- bind_rows(GEX_list)
rm(GEX_list)

output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS002/singleCell/counts/Mmul_10_mac239v4/expressionDF/"
write.csv(GEX_combined, paste0(output.dir, "GEX_combined.csv"))

GEX_isoforms <- isoforms_deconvolve(GEX_combined, "GEX")
write.csv(GEX_isoforms, paste0(output.dir, "GEX_isoforms.csv"))

```

### Seurat deep dive

```{r}
calculate_object_diversity <- function(seurat_obj, celltype_col = "seurat_clusters") {
  
  # Check if celltype column exists
  if (!celltype_col %in% colnames(seurat_obj@meta.data)) {
    stop(paste("Column", celltype_col, "not found in metadata. Available columns:", 
               paste(colnames(seurat_obj@meta.data), collapse = ", ")))
  }
  
  # 1. Cell type diversity (Shannon)
  cell_counts <- table(seurat_obj@meta.data[[celltype_col]])
  proportions <- cell_counts / sum(cell_counts)
  
  shannon <- -sum(proportions * log(proportions))
  simpson <- 1 - sum(proportions^2)
  n_celltypes <- length(cell_counts)
  
  # 2. Gene expression variance
  expr_data <- GetAssayData(seurat_obj, slot = "data")
  
  # Calculate coefficient of variation for each gene
  gene_cv <- apply(expr_data, 1, function(x) {
    if(mean(x) == 0) return(0)
    sd(x) / mean(x)
  })
  
  mean_gene_cv <- mean(gene_cv, na.rm = TRUE)
  median_gene_cv <- median(gene_cv, na.rm = TRUE)
  
  # Return results
  return(list(
    shannon_diversity = shannon,
    simpson_diversity = simpson,
    n_celltypes = n_celltypes,
    mean_gene_cv = mean_gene_cv,
    median_gene_cv = median_gene_cv
  ))
}

# Now calculate diversity for each sample
diversity_invitro <- calculate_object_diversity(seurat_df$Invitro)
diversity_pacute <- calculate_object_diversity(seurat_df$Pacute)
print(diversity_invitro)
print(diversity_pacute)




output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/Seurat/plots/"

features <- list(
  CD4 = "CD4",
  CD3 = c("CD3D", "CD3E", "CD3G"),
  CD8 = c("CD8A", "CD8B"),
  Treg = c("FOXP3", "IL2RA"),
  Bcell = c("CD19", "CD20", "CD79A", "CD79B"),
  NK = c("NCAM1", "FCGR3A"),
  Mono = c("CSF1R", "LYZ"),
  DC = c("CD1C", "CLEC9A", "LILRA4", "FCER1A")
)

check_available_genes <- function(seurat_obj, genes) {
  available_genes <- rownames(seurat_obj)
  present_genes <- intersect(genes, available_genes)
  missing_genes <- setdiff(genes, available_genes)
  
  if (length(missing_genes) > 0) {
    cat("Missing genes:", paste(missing_genes, collapse = ", "), "\n")
  }
  
  return(present_genes)
}

# Loop through each sample
for (sample_name in names(seurat_df)) {
  current_obj <- seurat_df[[sample_name]]
  
  cat("Creating plots for sample:", sample_name, "\n")
  
  # Loop through each celltype for this sample
  for (celltype_name in names(features)) {
    genes <- features[[celltype_name]]
    
    cat("  Processing celltype:", celltype_name, "\n")
    
    # Check which genes are available
    available_genes <- check_available_genes(current_obj, genes)
    
    # Skip if no genes are available
    if (length(available_genes) == 0) {
      cat("    Skipping", celltype_name, "for", sample_name, "- no genes found\n")
      next
    }
    
    # Create individual FeaturePlots for each available gene
    gene_plots <- list()
    
    for (gene in available_genes) {
      plot <- FeaturePlot(current_obj, features = gene, pt.size = 0.5) +
        ggtitle(gene) +
        theme(plot.title = element_text(size = 14, hjust = 0.5, face = "bold"),
              axis.text = element_blank(),
              axis.ticks = element_blank(),
              legend.position = "right")
      
      gene_plots[[gene]] <- plot
    }
    
    # Arrange in grid based on number of available genes
    n_genes <- length(gene_plots)
    
    if (n_genes == 1) {
      # Single gene - just use the plot directly
      combined_plot <- gene_plots[[1]]
      width <- 8
      height <- 6
    } else {
      # Multiple genes - arrange in grid
      if (n_genes <= 4) {
        ncol <- 2
        nrow <- 2
      } else if (n_genes <= 6) {
        ncol <- 3
        nrow <- 2
      } else {
        ncol <- 3
        nrow <- ceiling(n_genes / 3)
      }
      
      combined_plot <- plot_grid(plotlist = gene_plots, 
                                ncol = ncol, 
                                nrow = nrow,
                                align = "hv")
      
      width <- ncol * 4
      height <- nrow * 4
    }
    
    # Add overall title
    title_plot <- ggdraw() + 
      draw_label(paste(sample_name, "-", celltype_name, "Markers"), 
                size = 16, fontface = "bold")
    
    final_plot <- plot_grid(title_plot, combined_plot, 
                           ncol = 1, 
                           rel_heights = c(0.1, 0.9))
    
    # Save as SVG - ONE FILE PER CELLTYPE
    filename <- paste0(output.dir, sample_name, "_FeaturePlot_", celltype_name, ".svg")
    
    ggsave(filename, final_plot, 
           width = width, height = height + 1, 
           device = "svg", dpi = 300)
    
    cat("    Saved:", filename, "\n")
  }
}
```

Coexpression of CD4 and CD3s
```{r}
samples <- c(
    "D0",
    "D195",
    "D83",
    "Invitro",
    "Pacute",
    "W0",
    "W2"
)

genes <- c(
  "CD4",
  "CD3D", "CD3E", "CD3G",
  "CD8A", "CD8B"
)

input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/Seurat/RDS/"
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/Seurat/expressionDF/"
if (!dir.exists(output.dir)) {
  dir.create(output.dir, recursive = TRUE)
}
for (i in 1:length(samples)) {
  sample_name <- samples[i]
  input_file <- paste0(input.dir, sample_name, ".rds")
  
  tryCatch({
    seurat_obj <- readRDS(input_file)

    # Generate expression data frame
    sample_df <- targetExpressionDF(seurat_obj, genes = genes)
    sample_df$sample <- sample_name

    write.csv(sample_df, paste0(output.dir, sample_name, "_CD4T.csv"))
    
    cat("Processed sample:", sample_name, "\n")
  }, error = function(e) {
    cat("Error processing sample", sample_name, ":", conditionMessage(e), "\n\n")
  })
}

invitro_coex <- targetExpressionDF(seurat_objects$Invitro, genes = genes)
invitro_coexp <- invitro_coex %>%
  mutate(CD3 = ifelse(CD3D > 0 | CD3E > 0 | CD3G > 0, 1, 0)) %>%
  mutate(CD4 = ifelse(CD4 > 0 , 1, 0)) %>%
  mutate(CD8 = ifelse(CD8A > 0 , 1, 0)) %>%
  select(cellID, CD4, CD3, CD8)

current_df <- joint_data$Invitro
current_df <- left_join(current_df, invitro_coexp)
celltype_df <- current_df %>%
  mutate(GEX = ifelse(CD4 > 0 & CD3 > 0, GEX, 0)) %>% #keep only CD4s
  mutate(SALVE = ifelse(CD4 > 0 & CD3 > 0, SALVE, 0)) %>%
  filter(CD4 == 0 | CD8 == 0)

both <- celltype_df %>% filter(GEX != 0 & SALVE != 0)
onlySingleCell <- celltype_df %>% 
  filter(GEX != 0) %>%
  filter(!(cellID %in% both$cellID))
onlySALVE <- celltype_df %>% 
  filter(SALVE != 0) %>%
  filter(!(cellID %in% both$cellID))
cd4 <- celltype_df %>%
  filter(CD4 != 0 & CD3 != 0)
cd4.8 <- celltype_df %>%
  filter(CD4 != 0 & CD8 != 0)

cat("Sample\tCellType\tIn_type\tTotal_cells\tboth\t10X_only\tSALVE_only\n",
    "Invitro\t",
    "CD4 Ts\t",
    nrow(cd4), "\t",
    nrow(celltype_df), "\t",
    nrow(both), "\t",
    nrow(onlySingleCell), "\t",
    nrow(onlySALVE), "\n")
print(nrow(cd4.8))

```

# Joint Dataset
## Joint

### KLRB1
```{r}
# LOADING
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/SALVE/bamsort/reads/KLRB1/minimum/"
W0_min <- read.csv(paste0(input.dir, "SALVE_KLRB1_W0_SALVE_minreads5.csv"), row.names = "X")
SALVE_KLRB1_W0 <- W0_min %>%
  select(-total) %>%
  mutate(KLRB1 = log1p(KLRB1))

input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/bamsort/reads/KLRB1/minimum/" 
GEX_KLRB1_W0 <- read.csv(paste0(input.dir, "W0_minread1_minumi1.csv"), row.names = "X")
GEX_KLRB1_W0 <- GEX_KLRB1_W0 %>%
  select(-total) %>%
  mutate(KLRB1 = log1p(KLRB1))
GEX_KLRB1_W0_UMAP <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/Seurat/UMAPcoords/W0UMAP_coords.csv", row.names = "X")
GEX_KLRB1_W0_UMAP <- GEX_KLRB1_W0_UMAP %>% select(-sample, -V2)
GEX_KLRB1_W0 <- left_join(GEX_KLRB1_W0_UMAP, GEX_KLRB1_W0, by = "cellID")

# JOINING
# W2_joint <- left_join(GEX_KLRB1_W2, SALVE_KLRB1_W2, by = "cellID") %>%
#   select(-sample, -target) %>%
#   rename(GEX = KLRB1.x, SALVE = KLRB1.y)
# W2_joint[is.na(W2_joint)] <- 0
W0_joint <- left_join(GEX_KLRB1_W0, SALVE_KLRB1_W0, by = "cellID") %>%
  #select(-sample, -target) %>%
  rename(GEX = KLRB1.x, SALVE = KLRB1.y)
W0_joint[is.na(W0_joint)] <- 0

# comparison
cat("\nSample\tTotal_cells\tboth\t10X_only\tSALVE_only\n")
#for (name in c("W2_joint", "W0_joint")) {
  name <- "W0_joint" #comment out for loop
  current_df <- get(name)
  both <- current_df %>% filter(GEX != 0 & SALVE != 0)
  onlySingleCell <- current_df %>% 
    filter(GEX != 0) %>%
    filter(!(cellID %in% both$cellID))
  onlySALVE <- current_df %>% 
    filter(SALVE != 0) %>%
    filter(!(cellID %in% both$cellID))
  
  cat(name, "\t",
      nrow(current_df), "\t",
      nrow(both), "\t",
      nrow(onlySingleCell), "\t",
      nrow(onlySALVE), "\n")
#}


# plotting
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/joint/plots/KLRB1/"
# plotUMAP(W2_joint, colorby = GEX, 
#          "W2 joint KLRB1: GEX", 
#          output.dir, 
#          "KLRB1_W2_GEX.pdf", 
#          comparison = FALSE, color = "gray25")
# plotUMAP(W2_joint, colorby = SALVE, 
#          "W2 joint KLRB1: SALVE (raw)", 
#          output.dir, 
#          "KLRB1_W2_SALVE_raw.pdf", 
#          comparison = FALSE, color = "gray25")

plotUMAP(W0_joint, colorby = GEX,
         "W0 joint KLRB1: GEX (bamsort)",
         output.dir,
         "KLRB1_W0_GEX_bamsort.pdf",
         comparison = FALSE, color = "gray25")
plotUMAP(W0_joint, colorby = SALVE,
         "W0 joint KLRB1: SALVE (bamsort)",
         output.dir,
         "KLRB1_W0_SALVE_bamsort_minreads5.pdf",
         comparison = FALSE, color = "gray25")

output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/joint/dataframes/"
write.csv(both, paste0(output_dir, "KLRB1_both.csv"), row.names = FALSE)
write.csv(onlySingleCell, paste0(output_dir, "KLRB1_onlySingleCell.csv"), row.names = FALSE)
write.csv(onlySALVE, paste0(output_dir, "KLRB1_onlySALVE.csv"), row.names = FALSE)
write.csv(W0_joint, paste0(output_dir, "KLRB1_all.csv"), row.names = FALSE)
```
Correlations
```{r}
either <- W0_joint %>% filter(GEX != 0 | SALVE != 0)
both <- W0_joint %>% filter(GEX != 0 & SALVE != 0)

p <- ggplot(data = W0_joint, aes(x = SALVE, y = GEX)) +
  #geom_smooth(method = "lm", se = TRUE, color = "red", alpha = 0.7) +
  geom_jitter(alpha = 0.6, size = 1.5, width = 0.1, height = 0.1) +
  #geom_abline(intercept = 0, slope = 1, color = "red") +
  labs(
    x = "SALVE",
    y = "GEX",
    title = paste("W0 KLRB1 Correlation: SALVE vs GEX")
  ) +
  theme_minimal() +
  coord_fixed(ratio = 1) +
  xlim(0, 3) +
  ylim(0, 3)
print(p)
p_exclude_zero <- ggplot(data = subset(W0_joint, SALVE > 0 | GEX > 0), aes(x = SALVE, y = GEX)) +
  #geom_abline(intercept = 0, slope = 1, color = "red", linewidth = 1) +
  geom_smooth(method = "lm", se = TRUE, color = "white", alpha = 0.7) +
  geom_bin2d(bins = 18, alpha = 0.8) +
  labs(
    x = "SALVE",
    y = "GEX",
    title = "2D Binning (Excluding 0,0 Point)"
  ) +
  theme_minimal() +
  coord_cartesian(xlim = c(0, 3), ylim = c(0, 3)) +
  scale_fill_viridis_c(name = "Count") +
  theme(aspect.ratio = 1) +
  guides(fill = guide_colorbar(raster = TRUE))
print(p_exclude_zero)
ggsave("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/joint/plots/KLRB1/KLRB1_correlation_jitter.svg", 
       plot = p)
ggsave("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/joint/plots/KLRB1/KLRB1_correlation_2Dbinning.svg", 
       plot = p_exclude_zero)

max(W0_joint$SALVE)

cor(W0_joint$SALVE, W0_joint$GEX)
cor(either$SALVE, either$GEX)
cor(both$SALVE, both$GEX)
```


### bamsort
```{r}
# Loading
samples <-  c(
    "D0",
    "D195",
    "Invitro",
    "Pacute",
    "W0",
    "W2"
)

SALVE.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/SALVE/bamsort/reads/v6/minimum/"
GEX.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/bamsort/reads/v6/minimum/"

joint_data <- list()

for (i in 1:length(samples)) {
  sample_name <- samples[i]
  
  # Read all data files
  salve_file <- paste0(SALVE.dir, sample_name, "_SALVE_filtered.csv")
  gex_file <- paste0(GEX.dir, sample_name, "_GEX_filtered.csv")
  umap_file <- paste0("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/Seurat/UMAPcoords/", 
                      sample_name, "UMAP_coords.csv")
  cd4_file <- paste0("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/Seurat/expressionDF/", 
                     sample_name, "_CD4T.csv")
  
  salve_data <- if(file.exists(salve_file)) read.csv(salve_file) else NULL
  gex_data <- if(file.exists(gex_file)) read.csv(gex_file) else NULL
  umap_data <- if(file.exists(umap_file)) read.csv(umap_file, row.names = "X") else NULL
  cd4_data <- if(file.exists(cd4_file)) read.csv(cd4_file, row.names = "X") else NULL
  
  # Skip if no data at all
  if (is.null(salve_data) && is.null(gex_data) && is.null(umap_data)) {
    cat("Skipping", sample_name, ": no data\n")
    next
  }
  
  # Get cellIDs from Mmul_10 only df
  all_cells <- as.character(umap_data$cellID)
  all_cells <- unique(all_cells)
  
  # Create base dataframe
  result <- data.frame(cellID = all_cells)
  
  # Add UMAP data
  if (!is.null(umap_data)) {
    umap_processed <- umap_data %>%
      select(-V2, -sample)
    result <- left_join(result, umap_processed, by = "cellID")
  }
  
  # Add GEX data
  if (!is.null(gex_data)) {
    gex_processed <- gex_data %>%
      mutate(cellID = as.character(cellID)) %>%
      select(cellID, total, US)
    result <- left_join(result, gex_processed, by = "cellID") %>%
      mutate(GEX = log1p(total)) %>%
      mutate(GEX.US = log1p(US)) %>%
      select(-total, -US)
  } else {
    result$GEX <- 0
  }
  
  # Add SALVE data
  if (!is.null(salve_data)) {
    salve_processed <- salve_data %>%
      #group_by(cellID) %>%
      rename(SALVE = total) %>%
      mutate(cellID = as.character(cellID)) %>%
      select(cellID, SALVE, US, SS, MS)
    result <- left_join(result, salve_processed, by = "cellID") %>%
      mutate(SALVE = log1p(SALVE)) %>%
      mutate(USprop = US / (US+MS+SS)) %>%
      mutate(SSprop = SS / (US+MS+SS)) %>%
      mutate(MSprop = MS / (US+MS+SS)) %>%
      mutate(US = log1p(US)) %>%
      mutate(SS = log1p(SS)) %>%
      mutate(MS = log1p(MS))
  } else {
    result$SALVE <- 0
  }
  
  # Replace NAs with 0
  result[is.na(result)] <- 0
  
  # Cell type filtering
  cd4_data <- cd4_data %>%
    mutate(CD3 = ifelse(CD3D > 0 | CD3E > 0 | CD3G > 0, 1, 0)) %>%
    mutate(CD4 = ifelse(CD4 > 0 , 1, 0)) %>%
    mutate(CD8 = ifelse(CD8A > 0 , 1, 0)) %>%
    select(cellID, CD4, CD3, CD8)
  result <- left_join(result, cd4_data, by = "cellID")
  result <- result %>%
    mutate(across(any_of(c("GEX", "GEX.US")), 
              ~ ifelse(CD4 > 0 & CD3 > 0, .x, 0))) %>% 
    mutate(across(any_of(c("SALVE", "US", "MS", "SS")), 
              ~ ifelse(CD4 > 0 & CD3 > 0, .x, 0))) %>%
    filter(CD4 == 0 | CD8 == 0) %>% # exclude cells CD4+ and CD8+
    select(-size, -CD8, -CD3, -CD4)
  
  joint_data[[sample_name]] <- result
  cat("Processed", sample_name, "\n")
}

```

```{r}
output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/dataframes/"
#cat("\nSample\tTotal_cells\tboth\t10X_only\tSALVE_only\n")

# Process each dataset in the joint_data list
for (sample_name in names(joint_data)) {
  # Get the current dataframe
  current_df <- joint_data[[sample_name]]
  #   mutate(all_spliced = spliced.y + S + SS + MS)
  
  both <- current_df %>% filter(GEX != 0 & SALVE != 0)
  either <- current_df %>% filter(GEX != 0 | SALVE != 0)
  onlySingleCell <- current_df %>% 
    filter(GEX != 0) %>%
    filter(!(cellID %in% both$cellID))
  onlySALVE <- current_df %>% 
    filter(SALVE != 0) %>%
    filter(!(cellID %in% both$cellID))

  # cat(sample_name, "\t",
  #     nrow(current_df), "\t",
  #     nrow(both), "\t",
  #     nrow(onlySingleCell), "\t",
  #     nrow(onlySALVE), "\n")

  # cat(sample_name, "\tCorrelation:", cor(current_df$GEX, current_df$SALVE), "\n",
  #     "\tMax SALVE:", max(current_df$SALVE), "\n",
  #     "\tMax GEX:", max(current_df$GEX), "\n\n")


  # p <- ggplot(data = current_df, aes(x = SALVE, y = GEX)) +
  #   geom_jitter(alpha = 0.6, size = 1.5, width = 0.1, height = 0.1) +
  #   labs(
  #     x = "SALVE",
  #     y = "GEX",
  #     title = paste0(sample_name, " SIV total Correlation")
  #   ) +
  #   theme_minimal() +
  #   coord_fixed(ratio = 1) +
  #   xlim(0, 9.1) +
  #   ylim(0, 9.1)
  # print(p)
  # p_exclude_zero <- ggplot(data = subset(current_df, SALVE > 0 | GEX > 0), aes(x = SALVE, y = GEX)) +
  #   #geom_abline(intercept = 0, slope = 1, color = "red", linewidth = 1) +
  #   geom_smooth(method = "lm", se = TRUE, color = "white", alpha = 0.7) +
  #   geom_bin2d(bins = 30, alpha = 0.8) +
  #   labs(
  #     x = "SALVE",
  #     y = "GEX",
  #     title = paste0(sample_name, " SIV total 2D Binning (Excluding 0,0)")
  #   ) +
  #   theme_minimal() +
  #   coord_cartesian(xlim = c(0, 9.1), ylim = c(0, 9.1)) +
  #   scale_fill_viridis_c(name = "Count") +
  #   theme(aspect.ratio = 1) +
  #   guides(fill = guide_colorbar(raster = TRUE))
  # print(p_exclude_zero)
  # output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/plots/"
  # ggsave(paste0(output.dir, sample_name, "_CD4_correlation_jitter.svg"),
  #        plot = p)
  # ggsave(paste0(output.dir, sample_name, "_CD4_correlation_2Dbinning.svg"),
  #        plot = p_exclude_zero)

  
  # output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/plots/"
  # plotUMAP(current_df, colorby = GEX,
  #        paste0(sample_name, " joint SIV total: GEX (bamsort)"),
  #        output.dir,
  #        paste0(sample_name, "_CD4_GEX_bamsort.pdf"),
  #        comparison = FALSE, color = "red")
  # plotUMAP(current_df, colorby = SALVE,
  #        paste0(sample_name, " joint SIV total: SALVE (bamsort)"),
  #        output.dir,
  #        paste0(sample_name, "_CD4_SALVE_bamsort.pdf"),
  #        comparison = FALSE, color = "red")

  # SKIP this chunk
  # pearson_cor <- cor(current_df$all_spliced, current_df$spliced.x, use = "complete.obs")
  # r_squared <- pearson_cor^2
  # lm_model <- lm(spliced.x ~ all_spliced, data = current_df)
  # slope <- coef(lm_model)[2]
  # p <- ggplot(data = current_df, aes(x = all_spliced, y = spliced.x)) +
  #     geom_point() +
  #   geom_smooth(method = "lm", se = TRUE, color = "red") +
  #     labs(
  #       x = "SALVE spliced",
  #       y = "GEX spliced",
  #       title = paste("Correlation for ", sample_name)
  #     ) +
  #     theme_minimal()# +
  #     # annotate("text",
  #     #      x = -Inf, y = Inf,
  #     #      label = paste("Slope =", round(slope, 3), "\n",
  #     #                   "R² =", round(r_squared, 3), "\n",
  #     #                   "r =", round(pearson_cor, 3)),
  #     #      hjust = -0.1, vjust = 1.2,
  #     #      size = 4, color = "black")
  # print(p)

  
  #Save CSVs
  write.csv(both, paste0(output_dir, sample_name, "_both.csv"), row.names = FALSE)
  write.csv(onlySingleCell, paste0(output_dir, sample_name, "_onlySingleCell.csv"), row.names = FALSE)
  write.csv(onlySALVE, paste0(output_dir, sample_name, "_onlySALVE.csv"), row.names = FALSE)
  write.csv(current_df, paste0(output_dir, sample_name, "_all.csv"), row.names = FALSE)
}

```

Splicing proportions
```{r proportions}
output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/plots/proportions/"
for (sample_name in names(joint_data)) {
  df <- joint_data[[sample_name]]
  
  df_sorted <- df %>%
    filter(SALVE > 0) %>%
    arrange(desc(USprop), desc(SSprop)) %>%
    mutate(cellID_ordered = factor(cellID, levels = cellID))
  df_long <- df_sorted %>%
    pivot_longer(cols = contains("prop"), 
                 names_to = "component", 
                 values_to = "proportion")
  
  p1 <- ggplot(df_long, aes(x = cellID_ordered, y = proportion, fill = component)) +
    geom_bar(stat = "identity", width = 1) +
    scale_y_continuous(expand = c(0, 0)) +
    labs(title = paste0(sample_name, " Isoforms: Stacked Bar Chart"),
         x = "Cell ID",
         y = "Proportion",
         fill = "Component") +
    theme_minimal() +
    theme(axis.text.x = element_blank(),  # Remove x-axis labels for clarity
          axis.ticks.x = element_blank(),
          panel.grid.major.x = element_blank())
  
  ggsave(paste0(output_dir, sample_name, "_proportions_stacked.pdf"), p1, width = 10, height = 6, dpi = 300)
  
  
  
  p4 <- ggplot(df_long, aes(x = component, y = proportion, fill = component)) +
    geom_violin(alpha = 0.6) +
    geom_boxplot(width = 0.3, alpha = 0.8, outlier.alpha = 0.5) +
    labs(title = paste0(sample_name, " Isoforms: Violins"),
         x = "Isoform Proportion",
         y = "Proportion",
         fill = "Component") +
    theme_minimal() +
    theme(legend.position = "none")
  
  ggsave(paste0(output_dir, sample_name, "_proportions_violin.pdf"), p4, width = 8, height = 6, dpi = 300)
}

```

Splicing UMAPS (not updated)
```{r}
## for lightning talk figures
  output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/joint/plots/v5/subset/"
  plotUMAP(current_df, colorby = US,
         paste0(sample_name, " joint SALVE US"),
         output.dir,
         paste0(sample_name, "_umap_SALVE_US.svg"),
         comparison = FALSE, color = "royalblue1")
  plotUMAP(current_df, colorby = spliced,
         paste0(sample_name, " joint SALVE spliced"),
         output.dir,
         paste0(sample_name, "_umap_SALVE_spliced.svg"),
         comparison = FALSE, color = "red")
  plotUMAP(current_df, colorby = SALVE,
         paste0(sample_name, " joint SALVE"),
         output.dir,
         paste0(sample_name, "_umap_SALVE.svg"),
         comparison = FALSE, color = "purple4")
    plotUMAP(current_df, colorby = GEX,
         paste0(sample_name, " joint GEX"),
         output.dir,
         paste0(sample_name, "_umap_GEX.svg"),
         comparison = FALSE, color = "purple4")
```


## Other Joint Analyses
### GEX only - R^2 and JS Divergence

```{r R^2}
samples <- c("Invitro", "Pacute", "KLRB1")
joint.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/"

for (sample in samples) {
  # Load data
  if (sample == "KLRB1") {
    seurat_obj <- readRDS(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/Seurat/RDS/W0.rds")
    cellsList_GEXonly <- read.csv(
    paste0("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/joint/dataframes/", sample, "_onlySingleCell.csv"))
    cellsList_SALVEonly <- read.csv(
    paste0("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/joint/dataframes/", sample, "_onlySALVE.csv"))
    cellsList_both <- read.csv(
    paste0("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/joint/dataframes/", sample, "_both.csv"))
  }
  else {
    seurat_obj <- readRDS(paste0(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/Seurat/RDS/", 
    sample, ".rds"))
    cellsList_GEXonly <- read.csv(
    paste0(joint.dir, "dataframes/", sample, "_onlySingleCell.csv"))
    cellsList_SALVEonly <- read.csv(
    paste0(joint.dir, "dataframes/", sample, "_onlySALVE.csv"))
    cellsList_both <- read.csv(
    paste0(joint.dir, "dataframes/", sample, "_both.csv"))
  }
  
  # Extract expression data once for variable features
  var_features <- VariableFeatures(seurat_obj)
  cells_set1 <- cellsList_GEXonly$cellID
  cells_set2 <- c(cellsList_SALVEonly$cellID, cellsList_both$cellID)
  cells_both <- cellsList_both$cellID
  
  expr1 <- as.matrix(GetAssayData(seurat_obj[, cells_set1], slot = "data")[var_features, ])
  expr2 <- as.matrix(GetAssayData(seurat_obj[, cells_set2], slot = "data")[var_features, ])
  expr_both <- as.matrix(GetAssayData(seurat_obj[, cells_both], slot = "data")[var_features, ])
  
  # GEX vs SALVE
  r_squared_matrix <- cor(expr1, expr2, method = "pearson")^2
  max_r2_set2 <- apply(r_squared_matrix, 1, max)
  
  # SALVE vs SALVE
  r_squared_set2_internal <- cor(expr2, expr2, method = "pearson")^2
  diag(r_squared_set2_internal) <- NA  # Exclude self-correlation
  max_r2_set2_internal <- apply(r_squared_set2_internal, 1, max, na.rm = TRUE)
  
  # GEX vs GEX
  r_squared_gex_internal <- cor(expr1, expr1, method = "pearson")^2
  diag(r_squared_gex_internal) <- NA
  max_r2_gex_internal <- apply(r_squared_gex_internal, 1, max, na.rm = TRUE)
  
  # both vs both
  if (length(cells_both) > 1) {
    r_squared_both_internal <- cor(expr_both, expr_both, method = "pearson")^2
    diag(r_squared_both_internal) <- NA
    max_r2_both_internal <- apply(r_squared_both_internal, 1, max, na.rm = TRUE)
  } else {
    max_r2_both_internal <- numeric(0)
  }
  
  # GEX vs both
  if (length(cells_both) > 0) {
    r_squared_gex_vs_both <- cor(expr1, expr_both, method = "pearson")^2
    max_r2_gex_vs_both <- apply(r_squared_gex_vs_both, 1, max)
  } else {
    max_r2_gex_vs_both <- numeric(0)
  }
  
  # GEX vs random
  n_iterations <- 5
  n_cells_set2 <- length(cells_set1)
  available_cells <- setdiff(
    colnames(seurat_obj), 
    c(cells_set1, cellsList_SALVEonly$cellID, cellsList_both$cellID))
  
  set.seed(123)
  max_r2_per_iteration <- matrix(0, nrow = length(cells_set1), ncol = n_iterations)
  
  for (i in 1:n_iterations) {
    random_cells <- sample(available_cells, n_cells_set2)
    expr_random <- as.matrix(
      GetAssayData(seurat_obj[, random_cells], slot = "data")[var_features, ])
    r2_random <- cor(expr1, expr_random, method = "pearson")^2
    max_r2_per_iteration[, i] <- apply(r2_random, 1, max)
  }
  
  max_r2_random_single <- max_r2_per_iteration[, 1]
  median_r2_random <- apply(max_r2_per_iteration, 1, median)
  
  # Statistical tests comparing each group to GEX vs SALVE (the reference)
  cat("\n\n========== ", sample, " ==========\n")
  cat("\n--- Comparisons vs GEX vs SALVE (reference) ---\n")
  
  # Test 1: GEX vs Random1 (median) vs GEX vs SALVE
  w_rand_med <- wilcox.test(median_r2_random, max_r2_set2, paired = TRUE)
  cat("GEX vs Random1 (median) vs GEX vs SALVE:\t", w_rand_med$p.value, "\n")
  
  # Test 2: GEX vs Random1 (max) vs GEX vs SALVE
  w_rand_max <- wilcox.test(max_r2_random_single, max_r2_set2, paired = TRUE)
  cat("GEX vs Random1 (max) vs GEX vs SALVE:\t\t", w_rand_max$p.value, "\n")
  
  # Test 3: GEX vs GEX vs GEX vs SALVE
  w_gex <- wilcox.test(max_r2_gex_internal, max_r2_set2, paired = TRUE)
  cat("GEX vs GEX vs GEX vs SALVE:\t\t\t", w_gex$p.value, "\n")
  
  # Test 4: GEX vs both vs GEX vs SALVE
  if (length(max_r2_gex_vs_both) > 0) {
    w_both <- wilcox.test(max_r2_gex_vs_both, max_r2_set2, paired = TRUE)
    cat("GEX vs both vs GEX vs SALVE:\t\t\t", w_both$p.value, "\n")
  } else {
    w_both <- list(p.value = NA)
  }
  
  # Test 5: SALVE vs SALVE vs GEX vs SALVE
  w_salve <- wilcox.test(max_r2_set2_internal, max_r2_set2, paired = FALSE)
  cat("SALVE vs SALVE vs GEX vs SALVE:\t\t\t", w_salve$p.value, "\n")
  
  # Test 6: both vs both vs GEX vs SALVE
  if (length(max_r2_both_internal) > 0) {
    w_both_int <- wilcox.test(max_r2_both_internal, max_r2_set2, paired = FALSE)
    cat("both vs both vs GEX vs SALVE:\t\t\t", w_both_int$p.value, "\n")
  } else {
    w_both_int <- list(p.value = NA)
  }
  
  # Function to assign significance stars based on p-value
  get_significance_stars <- function(p_value) {
    if (is.na(p_value)) return("")
    if (p_value < 0.001) return("***")
    if (p_value < 0.01) return("**")
    if (p_value < 0.05) return("*")
    if (p_value < 0.1) return(".")
    return("")
  }
  
  # Store p-values and calculate significance stars
  p_values <- c(w_rand_med$p.value, w_rand_max$p.value, w_gex$p.value,
                w_both$p.value, NA, w_salve$p.value, w_both_int$p.value)
  
  significance_stars <- sapply(p_values, get_significance_stars)
  
  # Extended comparison plot with significance stars
  comparison_extended <- data.frame(
    Comparison = factor(
      rep(c("GEX vs Random1 (median)", "GEX vs Random1 (max)", "GEX vs GEX", 
            "GEX vs both", "GEX vs SALVE", "SALVE vs SALVE", "both vs both"),
          c(length(median_r2_random), length(max_r2_random_single), 
            length(max_r2_gex_internal), length(max_r2_gex_vs_both),
            length(max_r2_set2), length(max_r2_set2_internal), 
            length(max_r2_both_internal))),
      levels = c("GEX vs Random1 (median)", "GEX vs Random1 (max)", "GEX vs GEX",
                 "GEX vs both", "GEX vs SALVE", "SALVE vs SALVE", "both vs both")
    ),
    Max_R2 = c(median_r2_random, max_r2_random_single, max_r2_gex_internal,
               max_r2_gex_vs_both, max_r2_set2, max_r2_set2_internal, 
               max_r2_both_internal)
  )
  
  # Create annotation dataframe for significance stars
  # Position stars above each boxplot at y = 0.58
  star_positions <- data.frame(
    Comparison = levels(comparison_extended$Comparison),
    label = significance_stars,
    y_pos = rep(0.58, 7)
  )
  
  p_extended <- ggplot(comparison_extended, aes(x = Comparison, y = Max_R2, fill = Comparison)) +
    geom_boxplot(outlier.shape = NA) +
    geom_jitter(width = 0.2, alpha = 0.5, size = 1.5) +
    scale_fill_manual(values = rep("lightgray", 7)) +
    geom_text(data = star_positions, aes(x = Comparison, y = y_pos, label = label),
              inherit.aes = FALSE, size = 6, vjust = 0) +
    theme_minimal() +
    theme(legend.position = "none",
          axis.text.x = element_text(size = 10, angle = 25, hjust = 1),
          plot.title = element_text(hjust = 0.5)) +
    labs(title = paste0(sample, " Extended Correlation Comparison"),
         x = "", y = "Maximum R²") +
    ylim(0, 0.6)
  
  ggsave(paste0(joint.dir, "plots/R2/", sample, "_R2_comparison_extended.svg"),
         p_extended, width = 10, height = 6)
}


```

```{r JS divergence}
library(philentropy)

samples <- c("Invitro", "Pacute", "KLRB1")
joint.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/"

for (sample in samples) {
  # Load data
  if (sample == "KLRB1") {
    seurat_obj <- readRDS(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/Seurat/RDS/W0.rds")
    cellsList_GEXonly <- read.csv(
    paste0("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/joint/dataframes/", sample, "_onlySingleCell.csv"))
    cellsList_SALVEonly <- read.csv(
    paste0("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/joint/dataframes/", sample, "_onlySALVE.csv"))
    cellsList_both <- read.csv(
    paste0("/projects/b1042/GoyalLab/egrody/extractedData/EGS016/joint/dataframes/", sample, "_both.csv"))
  }
  else {
    seurat_obj <- readRDS(paste0(
    "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/Seurat/RDS/", 
    sample, ".rds"))
    cellsList_GEXonly <- read.csv(
    paste0(joint.dir, "dataframes/", sample, "_onlySingleCell.csv"))
    cellsList_SALVEonly <- read.csv(
    paste0(joint.dir, "dataframes/", sample, "_onlySALVE.csv"))
    cellsList_both <- read.csv(
    paste0(joint.dir, "dataframes/", sample, "_both.csv"))
  }
  
  # Extract expression data for variable features
  var_features <- VariableFeatures(seurat_obj)
  cells_gex <- cellsList_GEXonly$cellID
  cells_salve <- c(cellsList_SALVEonly$cellID, cellsList_both$cellID)
  cells_both <- cellsList_both$cellID
  
  expr_gex <- as.matrix(GetAssayData(seurat_obj[, cells_gex], slot = "data")[var_features, ])
  expr_salve <- as.matrix(GetAssayData(seurat_obj[, cells_salve], slot = "data")[var_features, ])
  expr_both <- as.matrix(GetAssayData(seurat_obj[, cells_both], slot = "data")[var_features, ])
  
  # Function to calculate JS divergence between two expression profiles
  calculate_js <- function(profile1, profile2) {
    # Convert to probabilities by adding pseudocount and normalizing
    p1 <- (profile1 + 1e-10) / sum(profile1 + 1e-10)
    p2 <- (profile2 + 1e-10) / sum(profile2 + 1e-10)
    
    # Create matrix for philentropy package format
    prob_matrix <- rbind(p1, p2)
    
    # Calculate JS divergence
    js_div <- JSD(prob_matrix, unit = "log2", est.prob = "empirical")
    
    return(js_div)
  }
  
  # Calculate minimum JS divergence for GEX cells vs SALVE cells
  min_js_gex_vs_salve <- numeric(ncol(expr_gex))
  for (i in 1:ncol(expr_gex)) {
    js_values <- apply(expr_salve, 2, function(salve_cell) {
      calculate_js(expr_gex[, i], salve_cell)
    })
    min_js_gex_vs_salve[i] <- min(js_values)
  }
  
  # Calculate minimum JS divergence for GEX cells vs GEX cells (internal)
  min_js_gex_vs_gex <- numeric(ncol(expr_gex))
  for (i in 1:ncol(expr_gex)) {
    js_values <- apply(expr_gex[, -i], 2, function(gex_cell) {
      calculate_js(expr_gex[, i], gex_cell)
    })
    min_js_gex_vs_gex[i] <- min(js_values)
  }
  
  # Calculate minimum JS divergence for GEX cells vs both cells
  if (length(cells_both) > 0) {
    min_js_gex_vs_both <- numeric(ncol(expr_gex))
    for (i in 1:ncol(expr_gex)) {
      js_values <- apply(expr_both, 2, function(both_cell) {
        calculate_js(expr_gex[, i], both_cell)
      })
      min_js_gex_vs_both[i] <- min(js_values)
    }
  } else {
    min_js_gex_vs_both <- numeric(0)
  }
  
  # Calculate minimum JS divergence for SALVE cells vs SALVE cells (internal)
  if (ncol(expr_salve) > 1) {
    min_js_salve_vs_salve <- numeric(ncol(expr_salve))
    for (i in 1:ncol(expr_salve)) {
      js_values <- apply(expr_salve[, -i], 2, function(salve_cell) {
        calculate_js(expr_salve[, i], salve_cell)
      })
      min_js_salve_vs_salve[i] <- min(js_values)
    }
  } else {
    min_js_salve_vs_salve <- numeric(0)
  }
  
  # Calculate minimum JS divergence for both cells vs both cells (internal)
  if (length(cells_both) > 1) {
    min_js_both_vs_both <- numeric(ncol(expr_both))
    for (i in 1:ncol(expr_both)) {
      js_values <- apply(expr_both[, -i], 2, function(both_cell) {
        calculate_js(expr_both[, i], both_cell)
      })
      min_js_both_vs_both[i] <- min(js_values)
    }
  } else {
    min_js_both_vs_both <- numeric(0)
  }
  
  # Random sampling comparison
  n_iterations <- 5
  n_cells_sample <- length(cells_gex)
  available_cells <- setdiff(
    colnames(seurat_obj), 
    c(cells_gex, cellsList_SALVEonly$cellID, cellsList_both$cellID))
  
  set.seed(123)
  min_js_per_iteration <- matrix(0, nrow = length(cells_gex), ncol = n_iterations)
  
  for (iter in 1:n_iterations) {
    random_cells <- sample(available_cells, n_cells_sample)
    expr_random <- as.matrix(
      GetAssayData(seurat_obj[, random_cells], slot = "data")[var_features, ])
    
    for (i in 1:ncol(expr_gex)) {
      js_values <- apply(expr_random, 2, function(random_cell) {
        calculate_js(expr_gex[, i], random_cell)
      })
      min_js_per_iteration[i, iter] <- min(js_values)
    }
  }
  
  min_js_random_single <- min_js_per_iteration[, 1]
  min_js_random_pooled <- apply(min_js_per_iteration, 1, min)
  median_js_random <- apply(min_js_per_iteration, 1, median)
  
  # Statistical tests - comparing all groups to GEX vs both and GEX vs SALVE
  cat("\n\n========== ", sample, " JS Divergence ==========\n")
  
  cat("\n--- Comparisons vs GEX vs both ---\n")
  
  if (length(min_js_gex_vs_both) > 0) {
    # GEX vs Random1 median vs GEX vs both
    w_rand_med_vs_both <- wilcox.test(median_js_random, min_js_gex_vs_both, paired = TRUE)
    cat("GEX vs Random1 (median) vs GEX vs both:\t", w_rand_med_vs_both$p.value, "\n")
    
    # GEX vs Random1 min vs GEX vs both
    w_rand_min_vs_both <- wilcox.test(min_js_random_single, min_js_gex_vs_both, paired = TRUE)
    cat("GEX vs Random1 (min) vs GEX vs both:\t", w_rand_min_vs_both$p.value, "\n")
    
    # GEX vs GEX vs GEX vs both
    w_gex_vs_both <- wilcox.test(min_js_gex_vs_gex, min_js_gex_vs_both, paired = TRUE)
    cat("GEX vs GEX vs GEX vs both:\t\t", w_gex_vs_both$p.value, "\n")
    
    # GEX vs SALVE vs GEX vs both
    w_salve_vs_both <- wilcox.test(min_js_gex_vs_salve, min_js_gex_vs_both, paired = TRUE)
    cat("GEX vs SALVE vs GEX vs both:\t\t", w_salve_vs_both$p.value, "\n")
    
    # SALVE vs SALVE vs GEX vs both
    if (length(min_js_salve_vs_salve) > 0) {
      w_salve_int_vs_both <- wilcox.test(min_js_salve_vs_salve, min_js_gex_vs_both, paired = FALSE)
      cat("SALVE vs SALVE vs GEX vs both:\t\t", w_salve_int_vs_both$p.value, "\n")
    }
    
    # both vs both vs GEX vs both
    if (length(min_js_both_vs_both) > 0) {
      w_both_int_vs_both <- wilcox.test(min_js_both_vs_both, min_js_gex_vs_both, paired = FALSE)
      cat("both vs both vs GEX vs both:\t\t", w_both_int_vs_both$p.value, "\n")
    }
  }
  
  cat("\n--- Comparisons vs GEX vs SALVE ---\n")
  
  # GEX vs Random1 median vs GEX vs SALVE
  w_rand_med_vs_salve <- wilcox.test(median_js_random, min_js_gex_vs_salve, paired = TRUE)
  cat("GEX vs Random1 (median) vs GEX vs SALVE:\t", w_rand_med_vs_salve$p.value, "\n")
  
  # GEX vs Random1 min vs GEX vs SALVE
  w_rand_min_vs_salve <- wilcox.test(min_js_random_single, min_js_gex_vs_salve, paired = TRUE)
  cat("GEX vs Random1 (min) vs GEX vs SALVE:\t\t", w_rand_min_vs_salve$p.value, "\n")
  
  # GEX vs GEX vs GEX vs SALVE
  w_gex_vs_salve <- wilcox.test(min_js_gex_vs_gex, min_js_gex_vs_salve, paired = TRUE)
  cat("GEX vs GEX vs GEX vs SALVE:\t\t\t", w_gex_vs_salve$p.value, "\n")
  
  # GEX vs both vs GEX vs SALVE
  if (length(min_js_gex_vs_both) > 0) {
    w_both_vs_salve <- wilcox.test(min_js_gex_vs_both, min_js_gex_vs_salve, paired = TRUE)
    cat("GEX vs both vs GEX vs SALVE:\t\t\t", w_both_vs_salve$p.value, "\n")
  }
  
  # SALVE vs SALVE vs GEX vs SALVE
  if (length(min_js_salve_vs_salve) > 0) {
    w_salve_int_vs_salve <- wilcox.test(min_js_salve_vs_salve, min_js_gex_vs_salve, paired = FALSE)
    cat("SALVE vs SALVE vs GEX vs SALVE:\t\t\t", w_salve_int_vs_salve$p.value, "\n")
  }
  
  # both vs both vs GEX vs SALVE
  if (length(min_js_both_vs_both) > 0) {
    w_both_int_vs_salve <- wilcox.test(min_js_both_vs_both, min_js_gex_vs_salve, paired = FALSE)
    cat("both vs both vs GEX vs SALVE:\t\t\t", w_both_int_vs_salve$p.value, "\n")
  }
  
  # Create extended comparison plot
  comparison_extended <- data.frame(
    Comparison = factor(
      rep(c("GEX vs Random1 (median)", "GEX vs Random1 (min)", "GEX vs GEX", 
            "GEX vs both", "GEX vs SALVE", "SALVE vs SALVE", "both vs both"),
          c(length(median_js_random), length(min_js_random_single), 
            length(min_js_gex_vs_gex), length(min_js_gex_vs_both),
            length(min_js_gex_vs_salve), length(min_js_salve_vs_salve), 
            length(min_js_both_vs_both))),
      levels = c("GEX vs Random1 (median)", "GEX vs Random1 (min)", "GEX vs GEX",
                 "GEX vs both", "GEX vs SALVE", "SALVE vs SALVE", "both vs both")
    ),
    Min_JS = c(median_js_random, min_js_random_single, min_js_gex_vs_gex,
               min_js_gex_vs_both, min_js_gex_vs_salve, min_js_salve_vs_salve, 
               min_js_both_vs_both)
  )
  
  p_js <- ggplot(comparison_extended, aes(x = Comparison, y = Min_JS, fill = Comparison)) +
    geom_boxplot(outlier.shape = NA) +
    geom_jitter(width = 0.2, alpha = 0.5, size = 1.5) +
    scale_fill_manual(values = rep("lightgray", 7)) +
    theme_minimal() +
    theme(legend.position = "none",
          axis.text.x = element_text(size = 10, angle = 25, hjust = 1),
          plot.title = element_text(hjust = 0.5)) +
    labs(title = paste0(sample, " JS Divergence Comparison"),
         x = "", y = "Minimum JS Divergence") +
    coord_cartesian(ylim = c(0, NA))
  
  ggsave(paste0(joint.dir, "plots/JSdivergence/", sample, "_JS_comparison_extended.svg"),
         p_js, width = 10, height = 6)
  
  # Create histogram of JS divergence distributions
  p_hist_salve <- ggplot(data.frame(JS = min_js_gex_vs_salve), aes(x = JS)) +
    geom_histogram(bins = 30, fill = "gray", color = "black") +
    theme_minimal() +
    labs(title = paste0(sample, " Distribution of Minimum JS Divergence: GEX vs SALVE"),
         x = "Minimum JS Divergence", y = "Count") +
    theme(plot.title = element_text(hjust = 0.5))
  ggsave(paste0(joint.dir, "plots/JSdivergence/", sample, "_JS_GEX_vs_SALVE_distribution.svg"), 
         p_hist_salve, width = 8, height = 6)
  
  if (length(min_js_salve_vs_salve) > 0) {
    p_hist_salve_int <- ggplot(data.frame(JS = min_js_salve_vs_salve), aes(x = JS)) +
      geom_histogram(bins = 30, fill = "gray", color = "black") +
      theme_minimal() +
      labs(title = paste0(sample, " Distribution of Minimum JS Divergence: SALVE vs SALVE"),
           x = "Minimum JS Divergence", y = "Count") +
      theme(plot.title = element_text(hjust = 0.5))
    ggsave(paste0(joint.dir, "plots/JSdivergence/", sample, "_JS_SALVE_vs_SALVE_distribution.svg"), 
           p_hist_salve_int, width = 8, height = 6)
  }
}
```


### Host factors

```{r restrict and depend}
factors_restrict <- c("APOBEC3G", "APOBEC3H", "TRIM5", "SAMHD1", 
                      "BST2", "SERINC5", "SERINC3", "MX2", "IFITM2")
factors_depend <- c("CD4", "CCR5", "PPIA", "PSIP1", "TNPO3", "CPSF6", "NUP153", "RANBP2", 
                    "TSG101", "PDCD6IP", "SP1", "NFKB1", "RELA", "CDK9", "CCNT1", "TNPO1",
                    "XPO1", "DDX3X", "RAN", "RANBP1", "RANGAP1")
cytotox <- c("TBX21", "EOMES", "RUNX3", "IFNG-AS1", "GZMK", "GZMA", "CX3CR1", "PRF1", 
                    "GZMB", "GZMH", 'GNLY', "ZNF683")

# Load all RDS
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS016/singleCell/Seurat/RDS/"
objects <- list()
for (sample_name in names(joint_data)) {
  seurat_obj <- readRDS(paste0(input.dir, sample_name, ".rds"))
  objects[[sample_name]] <- seurat_obj
}


host_virus_correlation(joint_data, objects, factors_restrict, viral_col = "SALVE", 
            output.dir = "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/hostVirus/restrictionFactors/")
host_virus_correlation(joint_data, objects, factors_restrict, viral_col = "USprop", 
            output.dir = "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/hostVirus/restrictionFactors/")
host_virus_correlation(joint_data, objects, factors_restrict, viral_col = "SSprop", 
            output.dir = "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/hostVirus/restrictionFactors/")
host_virus_correlation(joint_data, objects, factors_restrict, viral_col = "MSprop", 
            output.dir = "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/hostVirus/restrictionFactors/")
host_virus_correlation(joint_data, objects, factors_restrict, viral_col = "GEX", 
            output.dir = "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/hostVirus/restrictionFactors/")

host_virus_correlation(joint_data, objects, factors_depend, viral_col = "SALVE", 
            output.dir = "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/hostVirus/dependencyFactors/")
host_virus_correlation(joint_data, objects, factors_depend, viral_col = "USprop", 
            output.dir = "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/hostVirus/dependencyFactors/")
host_virus_correlation(joint_data, objects, factors_depend, viral_col = "SSprop", 
            output.dir = "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/hostVirus/dependencyFactors/")
host_virus_correlation(joint_data, objects, factors_depend, viral_col = "MSprop", 
            output.dir = "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/hostVirus/dependencyFactors/")
host_virus_correlation(joint_data, objects, factors_depend, viral_col = "GEX", 
            output.dir = "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/hostVirus/dependencyFactors/")

# are the trends the same between SALVE and GEX? And the isoforms?
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/hostVirus/dependencyFactors/"
for (sample_name in names(joint_data)) {
  gex_file <- paste0(input.dir, sample_name, "_GEX_correlations.csv")
  salve_file <- paste0(input.dir, sample_name, "_SALVE_correlations.csv")
  
  # Check if both files exist
  if (!file.exists(gex_file) || !file.exists(salve_file)) {
    cat("Skipping", sample_name, "- correlation files not found\n")
    next
  }
  
  file_GEX <- read.csv(gex_file) %>% 
    rename(GEXcor = correlation, GEXpadj = p_adj)
  file_SALVE <- read.csv(salve_file) %>% 
    rename(SALVEcor = correlation, SALVEpadj = p_adj)
  joint_corr <- full_join(file_GEX, file_SALVE, by = "gene") %>%
    select(gene, GEXcor, GEXpadj, SALVEcor, SALVEpadj)
  p1 <- ggplot(joint_corr, aes(x = GEXcor, y = SALVEcor)) +
        geom_point(alpha = 0.3, size = 2) +
        geom_text_repel(aes(label = gene)) +
        labs(title = paste0(sample_name, " GEX vs SALVE Correlations: Dependency Factors"),
             x = "GEX",
             y = "SALVE") +
        theme_minimal() +
        theme(plot.title = element_text(face = "bold", size = 14),
              axis.text = element_text(size = 10))
  ggsave(p1, file = paste0(input.dir, sample_name, "_compare_correlations.pdf"),
         device = "pdf")
}

```

```{r memory cytotox}
# Define cell type markers
memory_cd4_markers <- list(
  CD4 = "CD4",
  memory = c("IL7R", "CCR7", "SELL"),  # Central memory
  exclude_naive = c("CCR7", "SELL"),    # High in naive
  exclude_effector = c("GZMB", "PRF1")  # High in effector
)


subset_memory_cd4 <- function(seurat_obj, min_cd4_expr = 0.5) {
  cd4_expr <- GetAssayData(seurat_obj, slot = "data")["CD4", ]
  il7r_expr <- GetAssayData(seurat_obj, slot = "data")["IL7R", ]
  
  memory_cd4_cells <- names(cd4_expr)[cd4_expr > min_cd4_expr & il7r_expr > 0]
  seurat_subset <- subset(seurat_obj, cells = memory_cd4_cells)
  
  return(seurat_subset)
}

joint_data_memory <- list()
joint_rds_memory <- list()
# Subset both RDS and SALVE data
for (sample_name in names(objects)) {
  seurat_subset <- subset_memory_cd4(objects[[sample_name]])
  cells_keep <- colnames(seurat_subset)
  
  joint_rds_memory[[sample_name]] <- seurat_subset
  joint_data_memory[[sample_name]] <- joint_data[[sample_name]] %>%
    filter(cellID %in% cells_keep)
  
  cat("Sample:", sample_name, 
      "- Original cells:", ncol(seurat_obj),
      "- Memory CD4 cells:", ncol(joint_rds_memory[[sample_name]]), "\n")
}

# Run correlation on subset
host_virus_correlation(
  joint_salve_data = joint_data_memory,
  joint_rds = joint_rds_memory, 
  genes_list = cytotox,
  output.dir = "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/hostVirus/memoryCytotoxic/",
  viral_col = "SALVE"
)
```

```{r metabolic}

calculate_metabolic_scores_macaque <- function(seurat_obj) {
  
  # Check if percent_mito already exists
  if (!"percent_mito" %in% colnames(seurat_obj@meta.data)) {
    stop("percent_mito not found. Run Add_Mito_Ribo() first.")
  }
  
  cat("Using existing percent_mito column\n")
  
  # Define metabolic genes (human names)
  glycolysis_human <- c("HK2", "PFKP", "ALDOA", "GAPDH", "PGK1", 
                        "PGAM1", "ENO1", "PKM")
  oxphos_human <- c("NDUFA1", "NDUFB1", "SDHB", "UQCRB", "COX5A", 
                    "ATP5A1", "ATP5B", "ATP5F1A", "ATP5PB")
  
  # Convert to match your data
  glycolysis_genes <- convert_gene_list(seurat_obj, glycolysis_human)
  oxphos_genes <- convert_gene_list(seurat_obj, oxphos_human)
  
  # Calculate scores
  if (length(glycolysis_genes) > 2) {
    seurat_obj <- AddModuleScore(seurat_obj,
                                 features = list(glycolysis_genes),
                                 name = "glycolysis_score")
    cat("Calculated glycolysis score with", length(glycolysis_genes), "genes\n")
  }
  
  if (length(oxphos_genes) > 2) {
    seurat_obj <- AddModuleScore(seurat_obj,
                                 features = list(oxphos_genes),
                                 name = "oxphos_score")
    cat("Calculated OXPHOS score with", length(oxphos_genes), "genes\n")
  }
  
  # Ribosomal genes (check if percent_ribo also exists from Add_Mito_Ribo)
  if (!"percent_ribo" %in% colnames(seurat_obj@meta.data)) {
    ribo_genes <- unique(c(
      grep("^RPL|^RPS", rownames(seurat_obj), value = TRUE),
      grep("^Rpl|^Rps", rownames(seurat_obj), value = TRUE)
    ))
    
    if (length(ribo_genes) > 10) {
      seurat_obj <- AddModuleScore(seurat_obj,
                                   features = list(ribo_genes),
                                   name = "translation_score")
      cat("Calculated translation score with", length(ribo_genes), "genes\n")
    }
  } else {
    cat("Using existing percent_ribo column\n")
  }
  
  return(seurat_obj)
}
# Function to test all metabolic correlations with viral load
test_metabolic_correlations <- function(joint_salve_data, joint_rds, 
                                       viral_col = "SALVE",
                                       output.dir = NULL) {
  
  all_results <- list()
  
  for (sample_name in names(joint_salve_data)) {
    cat("\n=== SAMPLE:", sample_name, "===\n")
    
    current_df <- joint_salve_data[[sample_name]]
    seurat_obj <- joint_rds[[sample_name]]
    
    # Extract viral measure
    if (!viral_col %in% colnames(current_df)) {
      cat("Column", viral_col, "not found. Skipping.\n")
      next
    }
    viral_measure <- current_df[[viral_col]]
    
    if (sd(viral_measure) == 0) {
      cat(viral_col, "has zero variance. Skipping.\n")
      next
    }
    
    # Calculate metabolic scores if not already done
    if (!"glycolysis_score1" %in% colnames(seurat_obj@meta.data)) {
      seurat_obj <- calculate_metabolic_scores_macaque(seurat_obj)
    }
    
    # Add total UMI/genes if not present
    if (!"total_UMI" %in% colnames(seurat_obj@meta.data)) {
      seurat_obj$total_UMI <- colSums(GetAssayData(seurat_obj, slot = "counts"))
      seurat_obj$total_genes <- colSums(GetAssayData(seurat_obj, slot = "counts") > 0)
    }
    
    # Extract all metabolic metrics
    metabolic_metrics <- c("percent_mito", "total_UMI", "total_genes",
                          "glycolysis_score1", "oxphos_score1")
    
    # Add translation score if exists
    if ("translation_score1" %in% colnames(seurat_obj@meta.data)) {
      metabolic_metrics <- c(metabolic_metrics, "translation_score1")
    }
    
    # Add ribosomal if exists
    if ("percent_ribo" %in% colnames(seurat_obj@meta.data)) {
      metabolic_metrics <- c(metabolic_metrics, "percent_ribo")
    }
    
    # Test correlations
    cat("\n=== METABOLIC CORRELATIONS WITH", viral_col, "===\n")
    cat(sprintf("%-25s %10s %12s %10s %8s\n", 
                "Metric", "Corr", "P-value", "N_cells", "Sig"))
    cat(strrep("-", 70), "\n")
    
    results <- data.frame()
    
    for (metric in metabolic_metrics) {
      if (metric %in% colnames(seurat_obj@meta.data)) {
        metric_values <- seurat_obj@meta.data[[metric]]
        
        # Filter out NA values
        valid_cells <- !is.na(metric_values) & !is.na(viral_measure)
        
        if (sum(valid_cells) > 10) {
          test <- cor.test(metric_values[valid_cells], 
                          viral_measure[valid_cells],
                          method = "spearman", 
                          exact = FALSE)
          
          sig <- if (test$p.value < 0.001) "***" else 
                 if (test$p.value < 0.01) "**" else 
                 if (test$p.value < 0.05) "*" else "ns"
          
          cat(sprintf("%-25s %10.4f %12.2e %10d %8s\n",
                     metric, test$estimate, test$p.value, sum(valid_cells), sig))
          
          results <- rbind(results, data.frame(
            sample = sample_name,
            metric = metric,
            correlation = as.numeric(test$estimate),
            p_value = test$p.value,
            n_cells = sum(valid_cells)
          ))
        }
      }
    }
    
    results$p_adj <- p.adjust(results$p_value, method = "BH")
    all_results[[sample_name]] <- results
    
    cat(strrep("-", 70), "\n\n")
  }
  
  # Combine all results
  combined_results <- do.call(rbind, all_results)
  
  # Save if output directory provided
  if (!is.null(output.dir)) {
    if (!dir.exists(output.dir)) {
      dir.create(output.dir, recursive = TRUE)
    }
    write.csv(combined_results, 
              file.path(output.dir, paste0(viral_col, "_metabolic_correlations.csv")),
              row.names = FALSE)
    cat("Saved results to:", output.dir, "\n")
  }
  
  return(combined_results)
}

# Run analysis
metabolic_results <- test_metabolic_correlations(
  joint_salve_data = joint_data,
  joint_rds = objects,
  viral_col = "SALVE",
  output.dir = "/projects/b1042/GoyalLab/egrody/extractedData/EGS018/joint/hostVirus/metabolic/"
)

# View summary
metabolic_results %>%
  group_by(metric) %>%
  summarise(
    mean_corr = mean(correlation),
    median_corr = median(correlation),
    n_samples = n(),
    n_sig = sum(p_adj < 0.05)
  ) %>%
  arrange(desc(abs(mean_corr)))


```


### Correlation analysis (not updated below here)
Will do it custom for now and update correlation plot function later
```{r}
cat(
  "Correlation between 10X mac239 and SALVE total_lessLTR:\n",
    "  Pearson: ", round(cor(Pacute_paint_umap$mac239, Pacute_paint_umap$total_lessLTR, method="pearson"), 3),
    "\n  Spearman: ", round(cor(Pacute_paint_umap$mac239, Pacute_paint_umap$total_lessLTR, method="spearman"), 3),
    
    "\n\nCorrelation between 10X mac239 and SALVE absolute:\n",
    "  Pearson: ", round(cor(Pacute_paint_umap$mac239, Pacute_paint_umap$absolute, method="pearson"), 3),
    "\n  Spearman: ", round(cor(Pacute_paint_umap$mac239, Pacute_paint_umap$absolute, method="spearman"), 3)
)

# plotting
plot <- ggplot(data = Pacute_paint_umap, aes(x = total_lessLTR, y = mac239)) +
      geom_point() +
      labs(
        x = "SALVE total counts: D1 + tat + nef (filter > 2)",
        y = "SingleCell mac239 counts",
        title = "Pacute joint: total count") +
      theme_minimal() + 
    coord_fixed(ratio = 1)
plot <- ggplot(data = Pacute_paint_umap, aes(x = absolute, y = mac239)) +
      geom_point() +
      labs(
        x = "SALVE absolute (5' LTR) counts (filter > 0)",
        y = "SingleCell mac239 counts",
        title = "Pacute joint: absolute count") +
      theme_minimal() +
    coord_fixed(ratio = 1)
plot + theme(aspect.ratio = 1)
```


## Subset analysis

### Making Mmul10 clusters dataframe (skip)
```{r}
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/Seurat/Mmul_10/"
Pacute <- SeuratPipeline("/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10/Mmul_10_P_acute_GEX/outs/filtered_feature_bc_matrix/", "Pacute", output.dir, plots = TRUE)

output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10/"
SingleCell_Pacute <- targetExpressionDF(Pacute, "CD4")
SingleCell_Pacute_clusters <- SingleCell_Pacute %>% select(-CD4)
write.csv(SingleCell_Pacute_clusters, paste0(output.dir, "Pacute_Mmul10_clusters.csv"))
```

### Loading
Combining the coordinates and clusters from SingleCell aligned to Mmul_10 with the mac239 expression from SingleCell aligned to Mmul_10_mac239
```{r}
SingleCell_Pacute_clusters <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10/Pacute_Mmul10_clusters.csv", row.names = "X")
SingleCell_Pacute_mac239 <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS009/singleCell/counts/Mmul_10_mac239/Pacute_Mmulmac_mac239.csv", row.names = "X")
Pacute_SALVE <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS013/SALVE/bamsort/Pacute_SALVE_filtered.csv", row.names = "X")

SingleCell_Pacute_mac239 <- SingleCell_Pacute_mac239 %>% select(cellID, mac239)
SingleCell_Pacute <- left_join(SingleCell_Pacute_clusters, SingleCell_Pacute_mac239, by = "cellID")

Pacute_paint_umap = left_join(SingleCell_Pacute, Pacute_SALVE, by = "cellID")
Pacute_paint_umap[is.na(Pacute_paint_umap)] <- 0
```


```{r plotting}
# Function to create Seurat-style DimPlot
plot_clusters <- function(data, 
                         label_clusters = TRUE,
                         pt_size = 0.5,
                         label_size = 4) {
  
  # Convert the cluster column to a factor
  data$cluster <- as.factor(data$cluster)
  
  n_clusters <- length(unique(data$cluster))
  cluster_colors <- scales::hue_pal()(n_clusters)
  
  p1 <- ggplot(data, aes(x = UMAP1, y = UMAP2, color = cluster)) +
    geom_point(size = pt_size) +
    scale_color_manual(values = cluster_colors) +
    theme_bw() +
    theme(
      panel.grid = element_blank(),
      axis.title = element_text(size = 12),
      legend.title = element_blank(),
      panel.border = element_rect(colour = "black", fill = NA)
    )
  
  if (label_clusters) {
    cluster_centers <- data %>%
      group_by(cluster) %>%
      summarise(
        UMAP1 = median(UMAP1),
        UMAP2 = median(UMAP2)
      )
    
    p1 <- p1 + geom_text(data = cluster_centers,
                         aes(label = cluster),
                         size = label_size,
                         color = "black")
  }
  
  return(p1)
}

# Function to create Seurat-style FeaturePlot
plot_gene_expression <- function(data,
                               countcolumn,
                               pt_size = 0.5,
                               min_cutoff = NA,
                               max_cutoff = NA) {
  
  plot_data <- data
  if (!is.na(min_cutoff)) {
    plot_data[[countcolumn]][plot_data[[countcolumn]] < min_cutoff] <- min_cutoff
  }
  if (!is.na(max_cutoff)) {
    plot_data[[countcolumn]][plot_data[[countcolumn]] > max_cutoff] <- max_cutoff
  }
  
  p2 <- ggplot(plot_data, aes(x = UMAP1, y = UMAP2)) +
    geom_point(data = subset(plot_data, plot_data[[countcolumn]] <= 0),
               color = "gray93",
               size = pt_size) +
    geom_point(data = subset(plot_data, plot_data[[countcolumn]] > 0),
               aes_string(color = countcolumn),  # Use aes_string instead
               size = pt_size) +
    scale_color_gradient(low = "gray93", high = "darkblue",
                        name = "Expression") +
    theme_bw() +
    theme(
      panel.grid = element_blank(),
      axis.title = element_text(size = 12),
      panel.border = element_rect(colour = "black", fill = NA)
    )
  
  return(p2)
}

cluster_plot <- plot_clusters(Pacute_paint_umap)
xprn_plot_SALVE <- plot_gene_expression(Pacute_paint_umap, "total_lessLTR")
xprn_plot_SingleCell <- plot_gene_expression(Pacute_paint_umap, "mac239")
intersect_umap <- Pacute_paint_umap %>%
  mutate(total_lessLTR = ifelse(mac239 == 0, 0, total_lessLTR))
xprn_plot_intersect <- plot_gene_expression(intersect_umap, "total_lessLTR") #SALVE xprn in cells that are 10X+

output_dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/joint/subset/"
ggsave(cluster_plot, file = paste0(output_dir, "Pacute_umap_cluster.svg"))
ggsave(xprn_plot_SALVE, file = paste0(output_dir, "Pacute_umap_SALVE.svg"))
ggsave(xprn_plot_SingleCell, file = paste0(output_dir, "Pacute_umap_SingleCell.svg"))
ggsave(xprn_plot_intersect, file = paste0(output_dir, "Pacute_umap_intersect.svg"))

cat("SingleCell vRNA+: ", sum(invitro_paint_umap$log2SingleCell != 0, na.rm = TRUE),
    "\nSALVE vRNA+: ", sum(invitro_paint_umap$Count != 0, na.rm = TRUE),
    "\nCells in common: ", sum(intersect_umap$Count != 0, na.rm = TRUE))

write.csv(invitro_paint_umap, paste0(output_dir, "invitro_paint_umap.csv"))


```

Quick correlation plot:
```{r correlation plotting}
innerjoin <- inner_join(SingleCell_Pacute_mac239, Pacute_SALVE, by = "cellID")
Pacute_innerjoin <- left_join(SingleCell_Pacute_clusters, innerjoin, by = "cellID")
Pacute_innerjoin[is.na(Pacute_innerjoin)] <- 0

cat("Correlation of invitro between 10X and SALVE (total_lessLTR):", cor(Pacute_innerjoin$mac239, Pacute_innerjoin$total_lessLTR))
corrplot <- ggplot(data = Pacute_innerjoin, aes(x=total_lessLTR, y=mac239)) +
  geom_point() + 
  xlim(0,10) + 
  ylim(0,10) +
  theme_minimal() + 
  theme(aspect.ratio = 1) + 
  labs(title = "inner_join correlation")
corrplot
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/joint/subset/"
ggsave(corrplot, file = paste0(output.dir, "innerjoin_correlationplot.svg"))
```

### DEG analysis (break point)

```{r}
#D13
D13_Seurat <- SeuratPipeline("/projects/b1042/GoyalLab/egrody/extractedData/EGS004/singleCell/counts/Mmul_10/cellranger_count_D13/outs/filtered_feature_bc_matrix/", "D13", plots = FALSE)

D13 <- joint_data[["D13"]]
list_of_cells <- D13 %>% filter(SALVE != 0) #for SALVE
list_of_cells <- D13 %>% filter(GEX != 0) #for 10X
list_of_cells <- list_of_cells$cellID


results <- analyze_cell_subset(D13_Seurat, list_of_cells)
```

### Saving results
```{r}
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/joint/subset/singleCell/"
save_subset_analysis(results, output_dir = output.dir)
plot_subset_analysis(Pacute, results, list_of_cells, output_dir = paste0(output.dir, "plots/"))
```

### Interpreting results
```{r}
# Create filtered results list
filteredDEG <- lapply(results$cluster_specific, function(df) {
  if (!is.null(df) && nrow(df) > 0) {
    # Filter for significant adjusted p-value and log2FC threshold
    df[df$p_val_adj < 0.05 & abs(df$avg_log2FC) > 0.5, ]
  } else {
    NULL
  }
})

# Remove any empty results
filteredDEG <- filteredDEG[sapply(filteredDEG, function(x) !is.null(x) && nrow(x) > 0)]

# Print summary of how many genes passed filters in each cluster
for (cluster in names(filteredDEG)) {
  cat(sprintf("Cluster %s: %d genes\n", cluster, nrow(filteredDEG[[cluster]])))
}

# Saving
wb <- createWorkbook()
# Add each cluster's results as a separate worksheet
for (cluster_name in names(filteredDEG)) {
    de_results <- filteredDEG[[cluster_name]]
    if (!is.null(de_results) && nrow(de_results) > 0) {
        # Add cluster results as a worksheet
        addWorksheet(wb, cluster_name)
        # Add data with gene names as a column
        de_results$gene <- rownames(de_results)
        writeData(wb, cluster_name, de_results)
    }
}

# Save the workbook
saveWorkbook(wb, paste0(output.dir, "cluster_specific_DE_filtered.xlsx"), overwrite = TRUE)



filteredConserv <- results$conserved_markers %>%
    filter(p_val_adj < 0.05 & abs(avg_log2FC) > 0.5)

# Print summary of how many genes passed filters in each cluster
cat(sprintf("Conserved markers: %d genes\n", nrow(filteredConserv)))

# For each gene in conserved_markers, let's check which clusters show it as significant
check_gene_presence <- function(gene, cluster_results, p_val_thresh = 0.05, log2fc_thresh = 0.5) {
  # Initialize list to store results
  presence <- list()
  
  # Check each cluster
  for(cluster in names(cluster_results)) {
    de_results <- cluster_results[[cluster]]
    if(!is.null(de_results) && gene %in% rownames(de_results)) {
      # Get gene stats for this cluster
      gene_stats <- de_results[gene,]
      # Check if it meets significance criteria
      if(gene_stats$p_val_adj < p_val_thresh && abs(gene_stats$avg_log2FC) > log2fc_thresh) {
        presence[[cluster]] <- c(
          p_val_adj = gene_stats$p_val_adj,
          avg_log2FC = gene_stats$avg_log2FC
        )
      }
    }
  }
  
  # Return number of clusters and which clusters
  return(list(
    n_clusters = length(presence),
    clusters = names(presence),
    details = presence
  ))
}

# First get cluster counts for each gene
cluster_counts <- lapply(rownames(filteredConserv), function(gene) {
  result <- check_gene_presence(gene, results$cluster_specific)
  data.frame(
    gene = gene,
    num_clusters = result$n_clusters,
    clusters = paste(result$clusters, collapse=",")
  )
}) %>% bind_rows()

# Add cluster information to filtered results
filteredConserv <- filteredConserv %>%
  mutate(gene = rownames(.)) %>%
  left_join(cluster_counts, by = "gene") %>%
  arrange(desc(num_clusters), desc(abs(avg_log2FC)))

# Save to Excel
wb <- createWorkbook()
addWorksheet(wb, "filtered_conserved")
writeData(wb, "filtered_conserved", filteredConserv)
saveWorkbook(wb, paste0(output.dir, "conserved_markers_filtered.xlsx"), overwrite = TRUE)
```


## Saturation analysis

Why don't we see those 10X only cells also in SALVE?

### cellID sampling without reads

```{r cellID sampling}
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/split/"
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/saturation/sample_cellID/"

# Process each sample
for (sample in samples$samples) {
  cat("Processing sample:", sample, "\n")
  
  # Read the data files for this sample
  reads_D1_nef <- read.csv(paste0(input.dir, sample, "_D1_nef_bamsort_split_inside.csv"))
  reads_LTR_tat <- read.csv(paste0(input.dir, sample, "_LTR_tat_bamsort_split_inside.csv"))
  
  # Combine all reads and calculate total
  reads_total <- bind_rows(reads_D1_nef, reads_LTR_tat) %>%
    group_by(cellID, UMI) %>%
    summarize(reads = sum(reads), .groups = "drop")
  
  # Create molecule datasets (remove reads column)
  molecules_D1_nef <- reads_D1_nef %>% select(-reads)
  molecules_LTR_tat <- reads_LTR_tat %>% select(-reads)
  molecules_total <- reads_total %>% select(-reads)
  
  # Create samples list
  sample_datasets <- list(
    D1_nef = molecules_D1_nef,
    LTR_tat = molecules_LTR_tat,
    total = molecules_total
  )
  plot_cumulative_distribution(reads_total$reads, sample)
  
  # Process each dataset type
  # for (dataset_name in names(sample_datasets)) {
  #   dataset <- sample_datasets[[dataset_name]]
  #   
  #   results <- sample_cellID(dataset)
  #   summary <- analyze_cellID_sampling(results, title = paste0("cellID Saturation: ", sample, "_", dataset_name))
  #   
  #   # Create output filenames with sample prefix
  #   results_file <- paste0(output.dir, sample, "_", dataset_name, "_sample_cellID_results.csv")
  #   summary_file <- paste0(output.dir, sample, "_", dataset_name, "_sample_cellID_summary.csv")
  #   
  #   write.csv(results, results_file, row.names = FALSE)
  #   write.csv(summary, summary_file, row.names = FALSE)
  # 
  # }
}





plot_cumulative_distribution <- function(data_vector, sample_name) {
    df_plot <- data.frame(values = data_vector)
    
    # Plot 2: Cumulative distribution
    df_sorted <- data.frame(
      rank = 1:length(data_vector),
      value = sort(data_vector),
      cumulative_pct = (1:length(data_vector)) / length(data_vector) * 100
    )
    
    # Calculate percentage above 3
    pct_above_3 <- sum(data_vector >= 3) / length(data_vector) * 100
    
    p <- ggplot(df_sorted, aes(x = value, y = cumulative_pct)) +
      geom_line(color = "red", linewidth = 1) +
      geom_vline(xintercept = 3, color = "blue", linetype = "dashed", linewidth = 1) +
      annotate("text", x = 3, y = 50, 
               label = paste0(round(pct_above_3, 1), "% ≥ 3 reads"), 
               color = "blue", hjust = -0.1, vjust = 0.5, size = 10) +
      labs(title = paste0("Reads/UMI Distribution:", sample_name),
           x = "Reads/UMI", y = "Cumulative Percentage") +
      theme_minimal() +
      theme(
        plot.title = element_text(size = 18),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 14),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 16)
      ) +
      scale_x_log10(
        breaks = c(1, 10, 100, 1000, 10000),
        labels = c("1", "10", "100", "1,000", "10,000")
      )
    
    print(p)
  
  return(p)
}


plot_cumulative_distribution <- function(data_vector, sample_name) {
    df_plot <- data.frame(values = data_vector)
    
    # Plot 2: Cumulative distribution
    df_sorted <- data.frame(
      rank = 1:length(data_vector),
      value = sort(data_vector),
      cumulative_pct = (1:length(data_vector)) / length(data_vector) * 100
    )
    
    # Calculate percentage and count above 3
    count_above_3 <- sum(data_vector >= 3)
    pct_above_3 <- count_above_3 / length(data_vector) * 100
    
    p <- ggplot(df_sorted, aes(x = value, y = cumulative_pct)) +
      geom_line(color = "red", linewidth = 1) +
      geom_vline(xintercept = 3, color = "blue", linetype = "dashed", linewidth = 1) +
      annotate("text", x = 3, y = 50, 
               label = paste0(round(pct_above_3, 1), "% ≥ 3 reads\n(", format(count_above_3, big.mark = ","), " UMIs)"), 
               color = "blue", hjust = -0.1, vjust = 0.5, size = 8) +
      labs(title = paste0("Reads/UMI Distribution:", sample_name),
           x = "Reads/UMI", y = "Cumulative Percentage") +
      theme_minimal() +
      theme(
        plot.title = element_text(size = 18),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 14),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 16)
      ) +
      scale_x_log10(
        breaks = c(1, 10, 100, 1000, 10000),
        labels = c("1", "10", "100", "1,000", "10,000")
      )
  
    print (p)
  return(p)
}

# Example usage:
# freq_results <- plot_cumulative_distribution(reads_total$reads, "Uninfected")
```

```{r model fitting}
model_results <- fit_models(results, target_coverage = 95)
model_results <- fit_models(results, target_coverage = 99)
model_results <- fit_models(results, target_coverage = 100)
model_results <- fit_models(results, target_coverage = 120)
```

### UMI sampling with reads

```{r}
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/bamsort/split/"
output.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS014/SALVE/saturation/sample_UMI/"

# Process each sample
for (sample in samples$samples) {
  cat("Processing sample:", sample, "\n")
  
  # Read the data files for this sample
  reads_D1_nef <- read.csv(paste0(input.dir, sample, "_D1_nef_bamsort_split_inside.csv"))
  reads_LTR_tat <- read.csv(paste0(input.dir, sample, "_LTR_tat_bamsort_split_inside.csv"))
  
  # Combine all reads and calculate total
  reads_total <- bind_rows(reads_D1_nef, reads_LTR_tat) %>%
    group_by(cellID, UMI) %>%
    summarize(reads = sum(reads), .groups = "drop")
  
  # Create samples list
  sample_datasets <- list(
    D1_nef = reads_D1_nef,
    LTR_tat = reads_LTR_tat,
    total = reads_total
  )
  
  # Process each dataset type for this sample
  for (dataset_name in names(sample_datasets)) {
    dataset <- sample_datasets[[dataset_name]]
    
    results <- sample_UMI_weighted(dataset)
    summary <- analyze_UMI_sampling(results, title = paste0("Weighted UMI Saturation: ", sample))
  
    results_file <- paste0(output.dir, sample, "_sample_UMI_results.csv")
    summary_file <- paste0(output.dir, sample, "_sample_UMI_summary.csv")
    write.csv(results, results_file, row.names = FALSE)
    write.csv(summary, summary_file, row.names = FALSE)

  }
}
```

```{r}
model_results <- fit_models(results, target_coverage = 95, coverage_column = "pair_coverage")
model_results <- fit_models(results, target_coverage = 98.9, coverage_column = "pair_coverage")
model_results <- fit_models(results, target_coverage = 100, coverage_column = "pair_coverage")
model_results <- fit_models(results, target_coverage = 120)
```

### SALVE Summary: mac239 vs Mmul_10
```{r loading}
input.dir <- "/projects/b1042/GoyalLab/egrody/extractedData/EGS013/SALVE/bamsort/split/"
reads_summary <- read.csv("/projects/b1042/GoyalLab/egrody/extractedData/EGS013/SALVE/bamsort/split/all_samples_summary.txt", header = TRUE)

sample_names <- reads_summary$Sample
df_numeric <- reads_summary[, -which(names(reads_summary) == "Sample")]
df_transposed <- as.data.frame(t(df_numeric))
colnames(df_transposed) <- sample_names
rownames(df_transposed) <- c("Inside_Rows", "Inside_Total_Reads", "Outside_Rows", "Outside_Total_Reads")
df_transposed <- rbind(df_transposed, Inside_Fraction = round(df_transposed["Inside_Total_Reads",] / df_transposed["Outside_Total_Reads",], 2), Avg_Inside_Reads = round(df_transposed["Inside_Total_Reads",] / df_transposed["Inside_Rows",], 2))

```
